{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchSIZE is 512, Learning Rate is 0.001\n",
      "Found 666 images belonging to 6 classes.\n",
      "Found 104 images belonging to 6 classes.\n",
      "Found 258 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "import os # miscellaneous operating system interfaces\n",
    "import shutil # high-level file operations\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import random\n",
    "from itertools import product\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Conv2D \n",
    "from keras.layers import MaxPooling2D \n",
    "from keras.layers import Flatten \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.applications import MobileNetV2, Xception, DenseNet121,ResNet50V2,NASNetMobile\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "from keras.layers import  Input, Conv2D, Conv2DTranspose, ReLU,AveragePooling2D, MaxPooling2D, Dense, BatchNormalization, GlobalAveragePooling2D, Concatenate\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "base_dir = r'C:\\Users\\1217s\\Desktop\\capstone deeplearning\\images\\man'\n",
    "\n",
    "train_img_dir = r'C:\\Users\\1217s\\Desktop\\capstone deeplearning\\images\\man\\train'\n",
    "\n",
    "test_img_dir = r'C:\\Users\\1217s\\Desktop\\capstone deeplearning\\images\\man\\test'\n",
    "\n",
    "val_img_dir = r'C:\\Users\\1217s\\Desktop\\capstone deeplearning\\images\\man\\val'\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "batch_size = 512\n",
    "\n",
    "\n",
    "\n",
    "print(f'batchSIZE is {batch_size}, Learning Rate is {learning_rate}')\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "categories = ['dog','cat','bear','hamster','horse','wolf']\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(train_img_dir, target_size=(128,128), \n",
    "                                             classes=categories, \n",
    "                                             batch_size=batch_size)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(test_img_dir,\n",
    "                                        target_size=(128,128), \n",
    "                                        classes=categories, \n",
    "                                        batch_size=batch_size)\n",
    "\n",
    "val_set = test_datagen.flow_from_directory(val_img_dir,\n",
    "                                        target_size=(128,128), \n",
    "                                        classes=categories, \n",
    "                                        batch_size=batch_size)\n",
    "\n",
    "x_train, y_train = next(training_set)\n",
    "x_test, y_test = next(test_set)\n",
    "x_val,y_val = next(val_set)   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = Input(shape=(128, 128, 3))\n",
    "    \n",
    "\n",
    "    conv2_1 = Conv2D(32, 3, 1, 'SAME')(inputs)\n",
    "    conv2_2 = Conv2D(32, 3, 1, 'SAME')(conv2_1)\n",
    "    pool2_3 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv2_2)\n",
    "    br1 = BatchNormalization()(pool2_3)\n",
    "    \n",
    "    conv2_1 = Conv2D(32, 3, 1, 'SAME')(br1)\n",
    "    conv2_2 = Conv2D(32, 3, 1, 'SAME')(conv2_1)\n",
    "    pool2_3 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv2_2)\n",
    "    br1 = BatchNormalization()(pool2_3)\n",
    "    \n",
    "    \n",
    "    conv3_1 = Conv2D(64, 3, 1, 'SAME')(br1)\n",
    "    conv3_2 = Conv2D(64, 3, 1, 'SAME')(conv3_1)\n",
    "    pool3_2 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv3_2)\n",
    "    br2 = BatchNormalization()(pool3_2)\n",
    "    \n",
    "    conv3_1 = Conv2D(64, 3, 1, 'SAME')(br2)\n",
    "    conv3_2 = Conv2D(64, 3, 1, 'SAME')(conv3_1)\n",
    "    pool3_2 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv3_2)\n",
    "    br2 = BatchNormalization()(pool3_2)\n",
    "    \n",
    "    \n",
    "    conv4_1 = Conv2D(128, 3, 1, 'SAME')(br2)\n",
    "    conv4_2 = Conv2D(128, 3, 1, 'SAME')(conv4_1)\n",
    "    pool4_2 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv4_2)\n",
    "    br3 = BatchNormalization()(pool4_2)\n",
    "    \n",
    "    conv4_1 = Conv2D(128, 3, 1, 'SAME')(br3)\n",
    "    conv4_2 = Conv2D(128, 3, 1, 'SAME')(conv4_1)\n",
    "    pool4_2 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv4_2)\n",
    "    br3 = BatchNormalization()(pool4_2)\n",
    "    \n",
    "    flatten1 = Flatten()(pool4_2)\n",
    "    dense1 = Dense(units = 512, activation = 'relu')(flatten1)\n",
    "    dense2 = Dense(units = 1024, activation = 'relu')(dense1)\n",
    "    dr1 = Dropout(0.7)(dense2)\n",
    "    dense3 = Dense(units = 5, activation = 'sigmoid')(dr1)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=dense3) \n",
    "def mobile_net():\n",
    "    inputs = Input(shape=(128, 128, 3))\n",
    "    mobileNet = MobileNetV2(weights = \"imagenet\", include_top=False,input_shape = (128,128,3)\n",
    "                            ,input_tensor = inputs)\n",
    "    for layer in mobileNet.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    output = mobileNet.output\n",
    "    pooling = AveragePooling2D(pool_size=(4,4),padding='SAME')(output)\n",
    "    \n",
    "    flatten1 = Flatten()(pooling)\n",
    "    dense1 = Dense(units = 512, activation = 'relu')(flatten1)\n",
    "    dense2 = Dense(units = 1024, activation = 'relu')(dense1)\n",
    "    dr1 = Dropout(0.7)(dense2)\n",
    "    dense3 = Dense(units = 5, activation = 'sigmoid')(dr1)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=dense3)\n",
    "\n",
    "def xception():\n",
    "    inputs = Input(shape=(128, 128, 3))\n",
    "    xception = Xception(weights = \"imagenet\", include_top=False,input_shape = (128,128,3)\n",
    "                            ,input_tensor = inputs)\n",
    "    for layer in xception.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    output = xception.output\n",
    "    pooling = AveragePooling2D(pool_size=(4,4),padding='SAME')(output)\n",
    "    \n",
    "    flatten1 = Flatten()(pooling)\n",
    "    dense1 = Dense(units = 512, activation = 'relu')(flatten1)\n",
    "    dense2 = Dense(units = 1024, activation = 'relu')(dense1)\n",
    "    dr1 = Dropout(0.7)(dense2)\n",
    "    dense3 = Dense(units = 5, activation = 'sigmoid')(dr1)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=dense3)\n",
    "\n",
    "def resnet():\n",
    "    inputs = Input(shape=(128, 128, 3))\n",
    "    resnet = ResNet50V2 (weights = \"imagenet\", include_top=False,input_shape = (128,128,3)\n",
    "                            ,input_tensor = inputs)\n",
    "    for layer in resnet.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    output = resnet.output\n",
    "    pooling = AveragePooling2D(pool_size=(4,4),padding='SAME')(output)\n",
    "    \n",
    "    flatten1 = Flatten()(pooling)\n",
    "    dense1 = Dense(units = 512, activation = 'relu')(flatten1)\n",
    "    dense2 = Dense(units = 1024, activation = 'relu')(dense1)\n",
    "    dr1 = Dropout(0.7)(dense2)\n",
    "    dense3 = Dense(units = 5, activation = 'sigmoid')(dr1)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=dense3)\n",
    "\n",
    "def densenet():\n",
    "    inputs = Input(shape=(128, 128, 3))\n",
    "    densenet = DenseNet121(weights = \"imagenet\", include_top=False,input_shape = (128,128,3)\n",
    "                            ,input_tensor = inputs)\n",
    "    for layer in densenet.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    output = densenet.output\n",
    "    pooling = AveragePooling2D(pool_size=(4,4),padding='SAME')(output)\n",
    "    \n",
    "    flatten1 = Flatten()(pooling)\n",
    "    dense1 = Dense(units = 512, activation = 'relu')(flatten1)\n",
    "    dense2 = Dense(units = 1024, activation = 'relu')(dense1)\n",
    "    dr1 = Dropout(0.7)(dense2)\n",
    "    dense3 = Dense(units = 6, activation = 'sigmoid')(dr1)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=dense3)\n",
    "\n",
    "\n",
    "\n",
    "class ResidualUnit(tf.keras.Model):\n",
    "    def __init__(self, filter_in, filter_out, kernel_size):\n",
    "        super(ResidualUnit, self).__init__()\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filter_out, kernel_size, padding='same')\n",
    "        \n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filter_out, kernel_size, padding='same')\n",
    "        \n",
    "        if filter_in == filter_out:\n",
    "            self.identity = lambda x: x\n",
    "        else:\n",
    "            self.identity = tf.keras.layers.Conv2D(filter_out, (1,1), padding='same')\n",
    "\n",
    "    def call(self, x, training=False, mask=None):\n",
    "        h = self.bn1(x, training=training)\n",
    "        h = tf.nn.relu(h)\n",
    "        h = self.conv1(h)\n",
    "        \n",
    "        h = self.bn2(h, training=training)\n",
    "        h = tf.nn.relu(h)\n",
    "        h = self.conv2(h)\n",
    "        return self.identity(x) + h\n",
    "    \n",
    "class ResnetLayer(tf.keras.Model):\n",
    "    def __init__(self, filter_in, filters, kernel_size):\n",
    "        super(ResnetLayer, self).__init__()\n",
    "        self.sequence = list()\n",
    "        for f_in, f_out in zip([filter_in] + list(filters), filters):\n",
    "            self.sequence.append(ResidualUnit(f_in, f_out, kernel_size))\n",
    "\n",
    "    def call(self, x, training=False, mask=None):\n",
    "        for unit in self.sequence:\n",
    "            x = unit(x, training=training)\n",
    "        return x\n",
    "    \n",
    "class ResNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu') # 28x28x8\n",
    "        \n",
    "        self.res1 = ResnetLayer(64, (16, 16), (3, 3)) # 28x28x16\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D((2, 2)) # 14x14x16\n",
    "        \n",
    "        \n",
    "        self.res2 = ResnetLayer(128, (32, 32), (3, 3)) # 14x14x32\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D((2, 2)) # 7x7x32\n",
    "    \n",
    "        \n",
    "        self.res3 = ResnetLayer(256, (64, 64), (3, 3)) # 7x7x64\n",
    "        self.pool = tf.keras.layers.MaxPool2D((2, 2)) # 7x7x32\n",
    "        \n",
    "        \n",
    "        self.res4 = ResnetLayer(512, (64, 64), (3, 3)) # 7x7x64\n",
    "        self.pool = tf.keras.layers.MaxPool2D((2, 2)) # 7x7x32\n",
    "        \n",
    "        \n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(1024, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(5, activation='softmax')\n",
    "        \n",
    "    def call(self, x, training=False, mask=None):\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        x = self.res1(x, training=training)\n",
    "        x = self.pool1(x)\n",
    "        x = self.res2(x, training=training)\n",
    "        x = self.pool2(x)\n",
    "        x = self.res3(x, training=training)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 58s 3s/step - loss: 0.4376 - accuracy: 0.3848 - precision: 0.4249 - recall: 0.2438 - f1score: 0.2985 - val_loss: 0.7204 - val_accuracy: 0.1628 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: 0.0000e+00\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 57s 3s/step - loss: 0.2689 - accuracy: 0.6328 - precision: 0.7411 - recall: 0.5066 - f1score: 0.5949 - val_loss: 0.5919 - val_accuracy: 0.2597 - val_precision: 0.2846 - val_recall: 0.0972 - val_f1score: 0.1444\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 58s 3s/step - loss: 0.2305 - accuracy: 0.6973 - precision: 0.7688 - recall: 0.6229 - f1score: 0.6862 - val_loss: 0.4044 - val_accuracy: 0.4496 - val_precision: 0.5870 - val_recall: 0.1979 - val_f1score: 0.2928\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 60s 3s/step - loss: 0.1670 - accuracy: 0.8066 - precision: 0.8413 - recall: 0.7436 - f1score: 0.7886 - val_loss: 1.1387 - val_accuracy: 0.3178 - val_precision: 0.3391 - val_recall: 0.2986 - val_f1score: 0.3169\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 58s 3s/step - loss: 0.1565 - accuracy: 0.8301 - precision: 0.8573 - recall: 0.7912 - f1score: 0.8218 - val_loss: 2.4277 - val_accuracy: 0.2054 - val_precision: 0.2236 - val_recall: 0.2153 - val_f1score: 0.2192\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.1621 - accuracy: 0.8125 - precision: 0.8348 - recall: 0.7622 - f1score: 0.7956 - val_loss: 2.9141 - val_accuracy: 0.3140 - val_precision: 0.3240 - val_recall: 0.3333 - val_f1score: 0.3266\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.1423 - accuracy: 0.8633 - precision: 0.8859 - recall: 0.8263 - f1score: 0.8540 - val_loss: 2.7090 - val_accuracy: 0.2829 - val_precision: 0.2609 - val_recall: 0.2535 - val_f1score: 0.2571\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.1346 - accuracy: 0.8672 - precision: 0.8697 - recall: 0.8444 - f1score: 0.8561 - val_loss: 0.7418 - val_accuracy: 0.4302 - val_precision: 0.4454 - val_recall: 0.3785 - val_f1score: 0.4080\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.1081 - accuracy: 0.8926 - precision: 0.9173 - recall: 0.8588 - f1score: 0.8861 - val_loss: 1.0078 - val_accuracy: 0.4767 - val_precision: 0.4540 - val_recall: 0.3785 - val_f1score: 0.4124\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.1028 - accuracy: 0.9004 - precision: 0.9107 - recall: 0.8829 - f1score: 0.8961 - val_loss: 0.8354 - val_accuracy: 0.5078 - val_precision: 0.4884 - val_recall: 0.4583 - val_f1score: 0.4724\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0551 - accuracy: 0.9453 - precision: 0.9519 - recall: 0.9241 - f1score: 0.9374 - val_loss: 0.6073 - val_accuracy: 0.6512 - val_precision: 0.6459 - val_recall: 0.6250 - val_f1score: 0.6351\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0207 - accuracy: 0.9863 - precision: 0.9845 - recall: 0.9827 - f1score: 0.9836 - val_loss: 0.6001 - val_accuracy: 0.6705 - val_precision: 0.6159 - val_recall: 0.5938 - val_f1score: 0.6041\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0199 - accuracy: 0.9805 - precision: 0.9826 - recall: 0.9788 - f1score: 0.9807 - val_loss: 0.3380 - val_accuracy: 0.7597 - val_precision: 0.7947 - val_recall: 0.7188 - val_f1score: 0.7472\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0075 - accuracy: 0.9941 - precision: 0.9925 - recall: 0.9923 - f1score: 0.9923 - val_loss: 0.4100 - val_accuracy: 0.7481 - val_precision: 0.7874 - val_recall: 0.7639 - val_f1score: 0.7754\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0095 - accuracy: 0.9961 - precision: 0.9961 - recall: 0.9923 - f1score: 0.9942 - val_loss: 0.3406 - val_accuracy: 0.7752 - val_precision: 0.8031 - val_recall: 0.7812 - val_f1score: 0.7919\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0098 - accuracy: 0.9902 - precision: 0.9922 - recall: 0.9865 - f1score: 0.9893 - val_loss: 0.6525 - val_accuracy: 0.5736 - val_precision: 0.5377 - val_recall: 0.5243 - val_f1score: 0.5305\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0233 - accuracy: 0.9805 - precision: 0.9791 - recall: 0.9827 - f1score: 0.9809 - val_loss: 0.4907 - val_accuracy: 0.7016 - val_precision: 0.6394 - val_recall: 0.6146 - val_f1score: 0.6266\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0199 - accuracy: 0.9785 - precision: 0.9783 - recall: 0.9780 - f1score: 0.9781 - val_loss: 0.3600 - val_accuracy: 0.7597 - val_precision: 0.8072 - val_recall: 0.7014 - val_f1score: 0.7439\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0113 - accuracy: 0.9902 - precision: 0.9924 - recall: 0.9846 - f1score: 0.9883 - val_loss: 0.3574 - val_accuracy: 0.7364 - val_precision: 0.7710 - val_recall: 0.7431 - val_f1score: 0.7566\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0103 - accuracy: 0.9922 - precision: 0.9923 - recall: 0.9923 - f1score: 0.9923 - val_loss: 0.3585 - val_accuracy: 0.7364 - val_precision: 0.7810 - val_recall: 0.7535 - val_f1score: 0.7667\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0145 - accuracy: 0.9863 - precision: 0.9866 - recall: 0.9865 - f1score: 0.9865 - val_loss: 0.4347 - val_accuracy: 0.7171 - val_precision: 0.7643 - val_recall: 0.7465 - val_f1score: 0.7552\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0114 - accuracy: 0.9902 - precision: 0.9868 - recall: 0.9904 - f1score: 0.9885 - val_loss: 0.3272 - val_accuracy: 0.7481 - val_precision: 0.7988 - val_recall: 0.7674 - val_f1score: 0.7824\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0047 - accuracy: 0.9941 - precision: 0.9962 - recall: 0.9942 - f1score: 0.9951 - val_loss: 0.2929 - val_accuracy: 0.7791 - val_precision: 0.8143 - val_recall: 0.7986 - val_f1score: 0.8062\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0056 - accuracy: 0.9941 - precision: 0.9943 - recall: 0.9962 - f1score: 0.9952 - val_loss: 0.2778 - val_accuracy: 0.7868 - val_precision: 0.8334 - val_recall: 0.8021 - val_f1score: 0.8172\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0026 - accuracy: 0.9961 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 0.2737 - val_accuracy: 0.7868 - val_precision: 0.8215 - val_recall: 0.8021 - val_f1score: 0.8115\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0051 - accuracy: 0.9961 - precision: 0.9962 - recall: 0.9962 - f1score: 0.9962 - val_loss: 0.2949 - val_accuracy: 0.7752 - val_precision: 0.8181 - val_recall: 0.7812 - val_f1score: 0.7987\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 9.5445e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.7907 - val_precision: 0.8317 - val_recall: 0.8056 - val_f1score: 0.8183\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0022 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 0.2732 - val_accuracy: 0.7829 - val_precision: 0.8217 - val_recall: 0.7986 - val_f1score: 0.8098\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0076 - accuracy: 0.9922 - precision: 0.9922 - recall: 0.9923 - f1score: 0.9922 - val_loss: 0.2664 - val_accuracy: 0.7907 - val_precision: 0.8306 - val_recall: 0.8056 - val_f1score: 0.8176\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0027 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 0.3002 - val_accuracy: 0.7636 - val_precision: 0.8062 - val_recall: 0.7847 - val_f1score: 0.7952\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0029 - accuracy: 0.9961 - precision: 0.9981 - recall: 0.9962 - f1score: 0.9971 - val_loss: 0.3069 - val_accuracy: 0.7597 - val_precision: 0.8023 - val_recall: 0.7847 - val_f1score: 0.7933\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 55s 3s/step - loss: 0.0010 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2860 - val_accuracy: 0.7868 - val_precision: 0.8115 - val_recall: 0.7951 - val_f1score: 0.8031\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0018 - accuracy: 0.9980 - precision: 0.9981 - recall: 1.0000 - f1score: 0.9991 - val_loss: 0.2703 - val_accuracy: 0.7946 - val_precision: 0.8210 - val_recall: 0.8056 - val_f1score: 0.8131\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 8.8115e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2687 - val_accuracy: 0.7907 - val_precision: 0.8291 - val_recall: 0.8090 - val_f1score: 0.8188\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 9.8536e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2649 - val_accuracy: 0.8023 - val_precision: 0.8229 - val_recall: 0.8090 - val_f1score: 0.8159\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0026 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 0.2605 - val_accuracy: 0.8023 - val_precision: 0.8441 - val_recall: 0.8194 - val_f1score: 0.8315\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 8.7997e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.8101 - val_precision: 0.8377 - val_recall: 0.8160 - val_f1score: 0.8266\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 5.4959e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.8062 - val_precision: 0.8413 - val_recall: 0.8194 - val_f1score: 0.8301\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 6.0073e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.8023 - val_precision: 0.8377 - val_recall: 0.8160 - val_f1score: 0.8266\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 4.2267e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.7984 - val_precision: 0.8319 - val_recall: 0.8160 - val_f1score: 0.8238\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 5.5728e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.7984 - val_precision: 0.8303 - val_recall: 0.8160 - val_f1score: 0.8230\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 5.0166e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.7984 - val_precision: 0.8294 - val_recall: 0.8160 - val_f1score: 0.8226\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 4.7204e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.7984 - val_precision: 0.8294 - val_recall: 0.8160 - val_f1score: 0.8226\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 4.0161e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.7984 - val_precision: 0.8322 - val_recall: 0.8160 - val_f1score: 0.8239\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 4.6805e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.7984 - val_precision: 0.8272 - val_recall: 0.8160 - val_f1score: 0.8215\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 4.8468e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.7946 - val_precision: 0.8291 - val_recall: 0.8125 - val_f1score: 0.8207\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 6.4133e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.7946 - val_precision: 0.8322 - val_recall: 0.8160 - val_f1score: 0.8239\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0011 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.7946 - val_precision: 0.8306 - val_recall: 0.8229 - val_f1score: 0.8267\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 4.0558e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.7946 - val_precision: 0.8306 - val_recall: 0.8229 - val_f1score: 0.8267\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0011 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.8023 - val_precision: 0.8346 - val_recall: 0.8160 - val_f1score: 0.8250\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 4.0729e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.8023 - val_precision: 0.8346 - val_recall: 0.8160 - val_f1score: 0.8250\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 7.6917e-04 - accuracy: 1.0000 - precision: 0.9981 - recall: 1.0000 - f1score: 0.9991 - val_loss: 0.2523 - val_accuracy: 0.8023 - val_precision: 0.8352 - val_recall: 0.8194 - val_f1score: 0.8271\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 2.5238e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.8023 - val_precision: 0.8352 - val_recall: 0.8194 - val_f1score: 0.8271\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 3.8293e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 4.4810e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 4.1749e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 3.6647e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 3.0606e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 2.7755e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 7.7981e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 3.7332e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 5.3789e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 6.8791e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 6.4209e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2536 - val_accuracy: 0.8023 - val_precision: 0.8357 - val_recall: 0.8194 - val_f1score: 0.8274\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 3.5989e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2529 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 4.6529e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.8023 - val_precision: 0.8357 - val_recall: 0.8194 - val_f1score: 0.8274\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 2.8848e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.8023 - val_precision: 0.8357 - val_recall: 0.8194 - val_f1score: 0.8274\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 3.3417e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.8023 - val_precision: 0.8357 - val_recall: 0.8194 - val_f1score: 0.8274\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 5.1293e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 4.3070e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 5.0853e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 7.9355e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2538 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 3.4328e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 8.9132e-04 - accuracy: 0.9980 - precision: 0.9974 - recall: 1.0000 - f1score: 0.9986 - val_loss: 0.2530 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 3.7347e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 3.5815e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 5.0372e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 2.2113e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2529 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 4.4294e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.8023 - val_precision: 0.8357 - val_recall: 0.8194 - val_f1score: 0.8274\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 5.3517e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2529 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 1.9770e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 7.7067e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2528 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 5.4257e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 4.0326e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.8023 - val_precision: 0.8375 - val_recall: 0.8160 - val_f1score: 0.8265\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0065 - accuracy: 0.9961 - precision: 0.9962 - recall: 0.9962 - f1score: 0.9962 - val_loss: 0.2530 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 2.9469e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0017 - accuracy: 0.9980 - precision: 0.9981 - recall: 1.0000 - f1score: 0.9991 - val_loss: 0.2531 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 2.8719e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.0066 - accuracy: 0.9941 - precision: 0.9926 - recall: 0.9942 - f1score: 0.9934 - val_loss: 0.2525 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 4.5672e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 2.7219e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2520 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 3.8086e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 4.6341e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2514 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 3.7033e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 4.7716e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 2.5153e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 2.5973e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 3.5735e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 55s 3s/step - loss: 2.2095e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 54s 3s/step - loss: 4.2624e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.8023 - val_precision: 0.8381 - val_recall: 0.8194 - val_f1score: 0.8286\n"
     ]
    }
   ],
   "source": [
    "def recall(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
    "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
    "\n",
    "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n",
    "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
    "\n",
    "    # Precision = (True Positive) / (True Positive + False Positive)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1score(y_target, y_pred):\n",
    "    _recall = recall(y_target, y_pred)\n",
    "    _precision = precision(y_target, y_pred)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
    "    \n",
    "    # return a single tensor value\n",
    "    return _f1score\n",
    "\n",
    "\n",
    "\n",
    "#model = create_model()\n",
    "#model = ResNet()\n",
    "#model = mobile_net()\n",
    "#model = xception()\n",
    "model = densenet()\n",
    "#model = resnet()\n",
    "\n",
    "\n",
    "## learning rate scheduing\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,\n",
    "                                                          decay_steps=training_epochs*10,\n",
    "                                                          decay_rate=0.4,\n",
    "                                                          staircase=True)\n",
    "## optimizer는 Adam, loss는 sparse categorical crossentropy 사용\n",
    "## label이 ont-hot으로 encoding 안 된 경우에 sparse categorical corssentropy 및 sparse categorical accuracy 사용\n",
    "model.compile(keras.optimizers.Adam(lr_schedule), loss = 'binary_crossentropy', metrics=['accuracy', precision, recall, f1score])\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss='binary_crossentropy', \n",
    "#     metrics=['acc'],\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Train!\n",
    "history = model.fit(x_train, y_train, steps_per_epoch=training_epochs,\n",
    "         epochs=100, validation_data = (x_val,y_val))\n",
    "model.save('animal_model_man.h5')\n",
    "# epochs = 30\n",
    "# history = model.fit(\n",
    "#     training_set, \n",
    "#     epochs=epochs,\n",
    "#     steps_per_epoch=training_set.samples / epochs, \n",
    "#     validation_data=val_set,\n",
    "#     validation_steps=val_set.samples / epochs,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "index: 0  actual y: 3  answer y: 3  prediction: [1.5474149e-07 2.4123414e-08 9.1952912e-10 9.9999940e-01 1.5011653e-07\n",
      " 4.8682885e-08]\n",
      "index: 1  actual y: 1  answer y: 1  prediction: [1.0547232e-05 9.9996209e-01 4.2709262e-06 1.1699771e-06 5.0833651e-06\n",
      " 7.8374460e-06]\n",
      "index: 2  actual y: 1  answer y: 1  prediction: [6.9464472e-06 9.9542022e-01 6.4951942e-05 1.3563108e-06 1.0745168e-02\n",
      " 1.7051068e-05]\n",
      "index: 3  actual y: 2  answer y: 5  prediction: [1.8370152e-04 2.8604567e-03 5.8298260e-02 1.7043948e-04 2.2003055e-04\n",
      " 9.3774688e-01]\n",
      "index: 4  actual y: 2  answer y: 2  prediction: [2.2686631e-08 2.6080844e-08 9.9999976e-01 2.0437810e-08 9.3145180e-09\n",
      " 9.5256620e-09]\n",
      "index: 5  actual y: 5  answer y: 5  prediction: [3.6896208e-06 9.3202370e-06 2.5195652e-06 3.7605519e-06 4.4055500e-06\n",
      " 9.9998075e-01]\n",
      "index: 6  actual y: 4  answer y: 3  prediction: [5.8934093e-03 1.9367337e-03 3.6194921e-04 5.4547209e-01 3.6946160e-01\n",
      " 3.6017001e-03]\n",
      "index: 7  actual y: 1  answer y: 1  prediction: [1.0382439e-06 9.9999768e-01 7.3749709e-07 1.2445905e-07 4.3630797e-07\n",
      " 2.0423792e-07]\n",
      "index: 8  actual y: 2  answer y: 2  prediction: [2.52474734e-07 9.82639463e-08 9.99998689e-01 3.53317461e-07\n",
      " 2.12871029e-07 1.02891775e-07]\n",
      "index: 9  actual y: 4  answer y: 4  prediction: [4.3421984e-04 2.6860833e-04 1.3491511e-04 2.8887391e-04 9.9893999e-01\n",
      " 4.8875809e-04]\n",
      "index: 10  actual y: 1  answer y: 1  prediction: [3.6381811e-02 9.6622324e-01 1.2888312e-03 7.8082085e-04 1.7079115e-03\n",
      " 7.4404478e-04]\n",
      "index: 11  actual y: 4  answer y: 4  prediction: [1.3005648e-05 1.0845232e-04 1.1739678e-05 6.5599761e-06 9.9960732e-01\n",
      " 3.0514598e-04]\n",
      "index: 12  actual y: 5  answer y: 5  prediction: [0.08453637 0.01330277 0.00708646 0.00457668 0.00481498 0.9202328 ]\n",
      "index: 13  actual y: 1  answer y: 4  prediction: [7.2616339e-04 4.4073763e-01 1.6074479e-03 2.2318959e-04 6.2450415e-01\n",
      " 3.4345090e-03]\n",
      "index: 14  actual y: 2  answer y: 2  prediction: [2.2061691e-08 1.7702199e-08 9.9999982e-01 4.2959790e-08 1.4833062e-08\n",
      " 2.0431145e-08]\n",
      "index: 15  actual y: 2  answer y: 2  prediction: [2.5670964e-08 1.3606747e-09 1.0000000e+00 1.7877385e-08 2.3661280e-09\n",
      " 2.3441218e-09]\n",
      "index: 16  actual y: 3  answer y: 0  prediction: [0.41503736 0.00224423 0.00158346 0.23375466 0.04340938 0.01908797]\n",
      "index: 17  actual y: 3  answer y: 0  prediction: [9.9200577e-01 2.0954907e-03 1.9568205e-04 7.4130297e-04 1.8922985e-03\n",
      " 3.1578541e-04]\n",
      "index: 18  actual y: 4  answer y: 4  prediction: [8.6341538e-07 8.4691652e-07 2.0095322e-07 2.9273480e-07 9.9999702e-01\n",
      " 7.7456605e-07]\n",
      "index: 19  actual y: 1  answer y: 1  prediction: [2.0141715e-01 8.9889479e-01 4.3880939e-04 4.3037534e-04 3.8394332e-04\n",
      " 5.6764483e-04]\n",
      "index: 20  actual y: 0  answer y: 0  prediction: [9.9999070e-01 5.4455080e-07 1.0176814e-07 1.8118453e-06 3.2850437e-07\n",
      " 3.8053497e-07]\n",
      "index: 21  actual y: 0  answer y: 0  prediction: [0.43104607 0.10778913 0.0084275  0.02935818 0.25748235 0.01986414]\n",
      "index: 22  actual y: 0  answer y: 0  prediction: [0.58466375 0.13845819 0.00384015 0.06259966 0.00275627 0.00585058]\n",
      "index: 23  actual y: 0  answer y: 0  prediction: [9.9749482e-01 1.2161732e-03 9.2333110e-05 2.3707747e-04 4.1425228e-04\n",
      " 2.2777915e-04]\n",
      "index: 24  actual y: 4  answer y: 5  prediction: [1.5408695e-03 1.6598701e-03 7.4896216e-04 1.2586695e-01 6.4733028e-03\n",
      " 9.0228939e-01]\n",
      "index: 25  actual y: 4  answer y: 4  prediction: [1.5159845e-03 7.1838498e-04 4.0423870e-04 2.9586852e-03 9.9510086e-01\n",
      " 1.4781058e-03]\n",
      "index: 26  actual y: 1  answer y: 1  prediction: [3.4029172e-06 9.9999154e-01 1.7318089e-06 1.4788782e-06 1.3899507e-06\n",
      " 1.2159909e-06]\n",
      "index: 27  actual y: 3  answer y: 3  prediction: [0.09730887 0.00343347 0.00418442 0.77507687 0.01664463 0.03679496]\n",
      "index: 28  actual y: 4  answer y: 5  prediction: [1.2289222e-04 1.5676022e-04 7.3432209e-05 6.2540174e-04 8.8155270e-04\n",
      " 9.9851739e-01]\n",
      "index: 29  actual y: 0  answer y: 0  prediction: [0.9876965  0.00290862 0.00169933 0.00350398 0.00127062 0.0011479 ]\n",
      "index: 30  actual y: 1  answer y: 1  prediction: [5.9064369e-06 9.9999315e-01 1.0047671e-06 4.4190426e-07 2.5519116e-06\n",
      " 4.1696015e-07]\n",
      "index: 31  actual y: 4  answer y: 0  prediction: [5.6438845e-01 2.3439527e-04 3.3340180e-05 5.2958590e-01 2.1350384e-04\n",
      " 8.6865090e-05]\n",
      "index: 32  actual y: 4  answer y: 3  prediction: [0.18320331 0.00552329 0.00096583 0.70422053 0.01868013 0.00635347]\n",
      "index: 33  actual y: 3  answer y: 3  prediction: [1.7361879e-06 6.5921137e-07 2.9048817e-08 9.9999225e-01 6.2072633e-07\n",
      " 1.3984749e-06]\n",
      "index: 34  actual y: 0  answer y: 0  prediction: [9.9227613e-01 7.5528026e-04 1.9994378e-04 2.3084581e-03 2.3075640e-03\n",
      " 7.1382523e-04]\n",
      "index: 35  actual y: 1  answer y: 1  prediction: [6.4440951e-07 9.9999845e-01 1.7707781e-07 7.2085456e-08 4.0460634e-07\n",
      " 2.3321144e-07]\n",
      "index: 36  actual y: 5  answer y: 5  prediction: [5.6451559e-04 3.1176507e-03 4.8086047e-04 1.1531711e-03 1.7874837e-03\n",
      " 9.9364907e-01]\n",
      "index: 37  actual y: 3  answer y: 3  prediction: [3.0928850e-04 3.6592868e-05 8.7802027e-06 9.9933410e-01 2.3236871e-04\n",
      " 1.2409687e-04]\n",
      "index: 38  actual y: 0  answer y: 4  prediction: [0.06165168 0.04273942 0.01497066 0.00318569 0.78368974 0.00451702]\n",
      "index: 39  actual y: 1  answer y: 1  prediction: [6.5338612e-04 9.9943769e-01 5.6900841e-05 4.2238324e-05 1.6137958e-04\n",
      " 5.2420412e-05]\n",
      "index: 40  actual y: 4  answer y: 0  prediction: [9.7743440e-01 4.6572089e-04 1.9258261e-04 3.3331513e-03 7.6197386e-03\n",
      " 2.3195148e-04]\n",
      "index: 41  actual y: 2  answer y: 2  prediction: [2.2975968e-05 1.0819431e-05 9.9992627e-01 1.7933438e-05 7.5344888e-06\n",
      " 1.0748889e-05]\n",
      "index: 42  actual y: 4  answer y: 4  prediction: [8.4443491e-07 1.2257326e-06 6.7518533e-07 7.3940907e-07 9.9999535e-01\n",
      " 1.0871139e-06]\n",
      "index: 43  actual y: 4  answer y: 4  prediction: [1.3266234e-05 1.8482646e-06 1.3431954e-06 4.8813945e-06 9.9998355e-01\n",
      " 1.8989787e-06]\n",
      "index: 44  actual y: 2  answer y: 2  prediction: [1.4844751e-08 1.1737313e-09 1.0000000e+00 1.1248769e-08 3.3716294e-09\n",
      " 4.1353032e-09]\n",
      "index: 45  actual y: 3  answer y: 3  prediction: [4.3464656e-06 1.1205407e-06 1.8195152e-07 9.9997795e-01 2.4597659e-06\n",
      " 5.3929357e-06]\n",
      "index: 46  actual y: 2  answer y: 2  prediction: [6.26415014e-04 1.94637179e-02 9.70603347e-01 5.12592524e-05\n",
      " 1.01912614e-04 2.86430120e-04]\n",
      "index: 47  actual y: 1  answer y: 1  prediction: [0.0093115  0.8031417  0.00510192 0.02271608 0.03447777 0.05356276]\n",
      "index: 48  actual y: 5  answer y: 4  prediction: [7.1654954e-06 5.1419199e-02 2.0491843e-05 3.4800287e-06 9.7943085e-01\n",
      " 1.8098950e-04]\n",
      "index: 49  actual y: 5  answer y: 5  prediction: [6.4583778e-06 1.4020745e-05 4.2867546e-06 6.5246186e-06 5.6602166e-06\n",
      " 9.9997318e-01]\n",
      "index: 50  actual y: 3  answer y: 0  prediction: [9.9997985e-01 2.4222381e-06 4.7880093e-07 2.9241714e-06 1.0089816e-06\n",
      " 8.6560351e-07]\n",
      "index: 51  actual y: 4  answer y: 4  prediction: [2.2384262e-07 5.1015115e-07 1.8502178e-07 2.7043455e-07 9.9999666e-01\n",
      " 1.4726756e-06]\n",
      "index: 52  actual y: 4  answer y: 4  prediction: [0.07509235 0.0019111  0.00235423 0.0327847  0.8411818  0.00305349]\n",
      "index: 53  actual y: 5  answer y: 5  prediction: [1.0418498e-05 6.4109058e-06 2.3917066e-06 3.3209676e-06 3.4255531e-06\n",
      " 9.9998081e-01]\n",
      "index: 54  actual y: 3  answer y: 3  prediction: [2.7879737e-06 1.4632462e-07 1.0827909e-08 9.9999547e-01 5.4342348e-07\n",
      " 1.7685200e-07]\n",
      "index: 55  actual y: 3  answer y: 3  prediction: [2.0865947e-02 2.2044778e-04 3.1932879e-05 9.8229706e-01 7.6782703e-04\n",
      " 1.4451146e-04]\n",
      "index: 56  actual y: 5  answer y: 5  prediction: [0.00529572 0.00541598 0.00330555 0.01105985 0.00272071 0.9787599 ]\n",
      "index: 57  actual y: 1  answer y: 1  prediction: [4.5854898e-09 1.0000000e+00 2.4530740e-09 5.2970456e-10 3.6560037e-09\n",
      " 8.5429791e-10]\n",
      "index: 58  actual y: 2  answer y: 2  prediction: [2.1107180e-06 2.9734102e-07 9.9999249e-01 1.2796939e-06 1.2196482e-06\n",
      " 2.8686262e-07]\n",
      "index: 59  actual y: 2  answer y: 2  prediction: [2.9858879e-07 4.5380382e-08 9.9999899e-01 1.2146586e-07 2.6265603e-08\n",
      " 2.5095281e-07]\n",
      "index: 60  actual y: 5  answer y: 5  prediction: [6.3308289e-06 7.1067639e-06 3.7941545e-06 1.1604174e-04 1.1737931e-05\n",
      " 9.9988186e-01]\n",
      "index: 61  actual y: 4  answer y: 4  prediction: [0.0163298  0.00970548 0.01523641 0.02546105 0.924222   0.03525355]\n",
      "index: 62  actual y: 3  answer y: 3  prediction: [3.2965869e-02 2.9033124e-03 4.9009919e-04 8.2540190e-01 4.9563557e-02\n",
      " 2.4334192e-03]\n",
      "index: 63  actual y: 2  answer y: 2  prediction: [5.4764901e-11 1.9537644e-11 1.0000000e+00 9.7570535e-11 6.7188234e-11\n",
      " 1.8456212e-11]\n",
      "index: 64  actual y: 4  answer y: 4  prediction: [2.7155876e-04 1.7732382e-04 6.5337379e-05 1.2987554e-03 9.9763930e-01\n",
      " 3.7488341e-04]\n",
      "index: 65  actual y: 0  answer y: 0  prediction: [0.5302198  0.00915682 0.00192907 0.09288985 0.10328746 0.004711  ]\n",
      "index: 66  actual y: 0  answer y: 3  prediction: [4.5748651e-03 4.7796071e-03 5.9798360e-04 9.4091898e-01 1.1278391e-03\n",
      " 3.0168563e-02]\n",
      "index: 67  actual y: 5  answer y: 5  prediction: [0.00352272 0.00377929 0.0010235  0.00356919 0.03704086 0.9617276 ]\n",
      "index: 68  actual y: 0  answer y: 0  prediction: [8.9902401e-01 5.2270293e-04 1.1369066e-04 9.1700554e-02 2.9093027e-04\n",
      " 2.2271276e-04]\n",
      "index: 69  actual y: 4  answer y: 4  prediction: [0.00492778 0.00149903 0.00127634 0.04544196 0.835948   0.02746692]\n",
      "index: 70  actual y: 0  answer y: 3  prediction: [2.7135015e-04 5.2326359e-05 1.0463245e-05 9.9927497e-01 1.0496452e-04\n",
      " 2.8783083e-04]\n",
      "index: 71  actual y: 3  answer y: 5  prediction: [2.6659936e-05 4.2120060e-05 3.0638086e-05 1.9453296e-01 7.4465213e-05\n",
      " 9.3720919e-01]\n",
      "index: 72  actual y: 0  answer y: 1  prediction: [0.06223026 0.9446844  0.00190136 0.00198618 0.00124431 0.00182399]\n",
      "index: 73  actual y: 1  answer y: 1  prediction: [1.2434321e-06 9.9999815e-01 2.6883947e-07 1.4469508e-07 2.9737703e-07\n",
      " 1.4229428e-07]\n",
      "index: 74  actual y: 2  answer y: 2  prediction: [3.1990444e-06 8.6014933e-07 9.9998450e-01 5.5374830e-06 9.3282353e-07\n",
      " 6.3789612e-06]\n",
      "index: 75  actual y: 3  answer y: 3  prediction: [8.8316901e-06 2.5140280e-06 7.0155892e-07 9.9942148e-01 7.3182583e-04\n",
      " 1.8421206e-05]\n",
      "index: 76  actual y: 5  answer y: 5  prediction: [7.5811549e-05 1.0320828e-04 2.9882040e-05 1.5771687e-03 2.6651980e-05\n",
      " 9.9830014e-01]\n",
      "index: 77  actual y: 5  answer y: 0  prediction: [0.25604498 0.00367305 0.02408233 0.16279885 0.00064677 0.0335286 ]\n",
      "index: 78  actual y: 5  answer y: 5  prediction: [0.00748652 0.00324002 0.00159523 0.00857449 0.02373219 0.94358635]\n",
      "index: 79  actual y: 1  answer y: 1  prediction: [1.7012656e-03 9.9763077e-01 6.6679716e-04 1.9317865e-04 2.1150708e-04\n",
      " 1.9368529e-04]\n",
      "index: 80  actual y: 3  answer y: 3  prediction: [2.6956201e-04 2.2056214e-05 1.3853943e-06 9.9966812e-01 1.7287257e-05\n",
      " 9.5021314e-06]\n",
      "index: 81  actual y: 5  answer y: 5  prediction: [4.7180057e-04 6.6527724e-04 2.8342009e-04 7.2676837e-03 7.7240765e-03\n",
      " 9.8334360e-01]\n",
      "index: 82  actual y: 2  answer y: 2  prediction: [3.69369984e-04 4.66244346e-05 9.99466240e-01 3.27043017e-05\n",
      " 1.10126102e-05 1.38466185e-05]\n",
      "index: 83  actual y: 5  answer y: 5  prediction: [0.00433815 0.01910752 0.00437093 0.00120109 0.00197646 0.9745544 ]\n",
      "index: 84  actual y: 1  answer y: 1  prediction: [9.8409591e-06 9.9991035e-01 5.9602030e-06 9.9656484e-07 1.8230081e-04\n",
      " 2.6739085e-06]\n",
      "index: 85  actual y: 0  answer y: 0  prediction: [9.9992657e-01 4.4864264e-06 4.6813699e-07 2.1112646e-05 3.2906296e-06\n",
      " 1.4734104e-06]\n",
      "index: 86  actual y: 4  answer y: 4  prediction: [1.1888805e-05 5.0650688e-06 3.8572057e-06 7.9359597e-06 9.9997187e-01\n",
      " 4.7570120e-06]\n",
      "index: 87  actual y: 2  answer y: 2  prediction: [1.0911814e-08 7.7996605e-09 1.0000000e+00 1.7216108e-08 1.7669715e-08\n",
      " 6.0325043e-09]\n",
      "index: 88  actual y: 5  answer y: 5  prediction: [3.50117683e-04 1.19411372e-04 6.04394154e-05 1.13887836e-04\n",
      " 1.10650210e-04 9.99588490e-01]\n",
      "index: 89  actual y: 3  answer y: 3  prediction: [2.4616718e-03 6.9374997e-05 2.1815711e-06 9.9793744e-01 4.9334340e-05\n",
      " 9.8786559e-06]\n",
      "index: 90  actual y: 2  answer y: 2  prediction: [3.8876802e-08 4.1951985e-08 9.9999964e-01 6.0549517e-08 3.6677815e-08\n",
      " 3.8667665e-08]\n",
      "index: 91  actual y: 1  answer y: 1  prediction: [2.1613450e-06 9.9999750e-01 4.6945141e-07 1.2695602e-07 8.1682310e-07\n",
      " 1.5088614e-07]\n",
      "index: 92  actual y: 5  answer y: 5  prediction: [0.02300736 0.02248347 0.00981063 0.01771727 0.10655048 0.78604925]\n",
      "index: 93  actual y: 2  answer y: 2  prediction: [1.6712884e-09 1.5504134e-09 1.0000000e+00 6.3632992e-09 7.9428828e-09\n",
      " 2.2908948e-09]\n",
      "index: 94  actual y: 2  answer y: 2  prediction: [8.9376142e-09 6.0003047e-09 1.0000000e+00 2.5317600e-08 9.1738013e-09\n",
      " 2.5759791e-08]\n",
      "index: 95  actual y: 0  answer y: 0  prediction: [9.9996102e-01 9.5191654e-06 7.8447556e-07 6.5950976e-06 1.4508523e-06\n",
      " 1.7691601e-06]\n",
      "index: 96  actual y: 0  answer y: 0  prediction: [9.9824470e-01 2.9618212e-05 6.3626903e-06 9.4920397e-04 2.9396913e-05\n",
      " 1.2969184e-05]\n",
      "index: 97  actual y: 0  answer y: 0  prediction: [9.9991727e-01 4.6677796e-06 8.7484534e-07 3.3417658e-05 3.1812770e-06\n",
      " 2.7305709e-06]\n",
      "index: 98  actual y: 2  answer y: 2  prediction: [7.191503e-06 5.219107e-06 9.999178e-01 3.011681e-05 1.376382e-05\n",
      " 3.070378e-05]\n",
      "index: 99  actual y: 2  answer y: 2  prediction: [3.1103946e-09 2.5353541e-09 1.0000000e+00 5.5290155e-09 1.0919746e-08\n",
      " 2.6751006e-09]\n",
      "index: 100  actual y: 1  answer y: 1  prediction: [0.00509459 0.39778054 0.02826169 0.00934842 0.16576001 0.07324883]\n",
      "index: 101  actual y: 0  answer y: 0  prediction: [7.5211066e-01 8.0425411e-02 4.5946240e-04 1.5587717e-02 2.0802915e-03\n",
      " 6.1488152e-04]\n",
      "index: 102  actual y: 5  answer y: 5  prediction: [3.9682411e-05 3.3725271e-05 1.1561937e-05 2.3900091e-05 1.3537425e-05\n",
      " 9.9991918e-01]\n",
      "index: 103  actual y: 3  answer y: 3  prediction: [1.7084479e-03 3.1706691e-04 1.7735362e-04 8.0144930e-01 1.7455554e-01\n",
      " 7.2172284e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 356ms/step - loss: 0.2487 - accuracy: 0.8269 - precision: 0.8642 - recall: 0.8203 - f1score: 0.8411\n",
      "loss: 0.249, accuracy: 0.827, precision: 0.864, recall: 0.820, f1score: 0.841\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# output = classifier.predict_generator(test_set, steps=1)\n",
    "# print(test_set.class_indices)\n",
    "# print(output)\n",
    "size = y_test[:,-1]\n",
    "print(size.size)\n",
    "\n",
    "\n",
    "# predict 10 random hand-writing data\n",
    "y_predicted = model.predict(x_test)\n",
    "for x in range(0,size.size):\n",
    "    \n",
    "    print(\"index:\", x,\n",
    "          \" actual y:\", np.argmax(y_test[x]),\n",
    "          \" answer y:\", np.argmax(y_predicted[x]),\n",
    "            \" prediction:\", np.array(y_predicted[x]))\n",
    "\n",
    "_loss, _acc, _precision, _recall, _f1score = model.evaluate(x_test, y_test)\n",
    "print('loss: {:.3f}, accuracy: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _precision, _recall, _f1score))\n",
    "# print('loss: ', evaluation[0])\n",
    "# print('accuracy', evaluation[1])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 손실 그래프\n",
    "def plot_loss(history):\n",
    "   # 선 그리기\n",
    "    plt.plot(history.history['loss'], 'y', label='train loss')\n",
    "    plt.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "   # 그래프 제목\n",
    "    plt.title('Model Loss')\n",
    "   # x,y축 이름 표시\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "   # 각 라인 표식 표시\n",
    "    plt.legend(['Train','Validation'],loc=0)\n",
    "\n",
    "# 정확도 그래프\n",
    "def plot_acc(history):\n",
    "  # dir(history.history)\n",
    "    plt.plot(history.history['accuracy'], 'b', label='train accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], 'g', label='val accuracy')\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc=0)\n",
    "\n",
    "plot_loss(history)\n",
    "plt.show()\n",
    "plot_acc(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = [512,1024]\n",
    "# learning_rate = [0.001,0.0001,0.00001,0.000001]\n",
    "# for  batch_size, learning_rate in product(batch_size,learning_rate):\n",
    "#     print(f'batchSIZE is {batch_size}, Learning Rate is {learning_rate}')\n",
    "#     train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "#                                    shear_range = 0.2,\n",
    "#                                    zoom_range = 0.2,\n",
    "#                                    horizontal_flip = True)\n",
    "\n",
    "#     test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "#     categories = ['dog','cat','bear','hamster','horse']\n",
    "\n",
    "#     training_set = train_datagen.flow_from_directory(train_img_dir, target_size=(128,128), \n",
    "#                                                  classes=categories, \n",
    "#                                                  batch_size=batch_size)\n",
    "\n",
    "#     test_set = test_datagen.flow_from_directory(test_img_dir,\n",
    "#                                             target_size=(128,128), \n",
    "#                                             classes=categories, \n",
    "#                                             batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "#     x_train, y_train = next(training_set)\n",
    "#     x_test, y_test = next(test_set)\n",
    "#     model = mobile_net()\n",
    "#     ## learning rate scheduing\n",
    "#     lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,\n",
    "#                                                               decay_steps=training_epochs*10,\n",
    "#                                                               decay_rate=0.4,\n",
    "#                                                               staircase=True)\n",
    "#     ## optimizer는 Adam, loss는 sparse categorical crossentropy 사용\n",
    "#     ## label이 ont-hot으로 encoding 안 된 경우에 sparse categorical corssentropy 및 sparse categorical accuracy 사용\n",
    "#     model.compile(keras.optimizers.Adam(lr_schedule), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#     ## Train!\n",
    "#     model.fit(x_train, y_train, steps_per_epoch=training_epochs,\n",
    "#              epochs=20)\n",
    "#     # output = classifier.predict_generator(test_set, steps=1)\n",
    "#     # print(test_set.class_indices)\n",
    "#     # print(output)\n",
    "#     size = y_test[:,-1]\n",
    "#     print(size.size)\n",
    "\n",
    "\n",
    "#     # predict 10 random hand-writing data\n",
    "#     y_predicted = model.predict(x_test)\n",
    "#     for x in range(0,size.size):\n",
    "\n",
    "#         print(\"index:\", x,\n",
    "#               \" actual y:\", np.argmax(y_test[x]),\n",
    "#               \" answer y:\", np.argmax(y_predicted[x]),\n",
    "#                 \" prediction:\", np.array(y_predicted[x]))\n",
    "\n",
    "#     evaluation = model.evaluate(x_test, y_test)\n",
    "#     print('loss: ', evaluation[0])\n",
    "#     print('accuracy', evaluation[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
