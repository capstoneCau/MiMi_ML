{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchSIZE is 512, Learning Rate is 0.001\n",
      "Found 580 images belonging to 5 classes.\n",
      "Found 87 images belonging to 5 classes.\n",
      "Found 213 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "import os # miscellaneous operating system interfaces\n",
    "import shutil # high-level file operations\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import random\n",
    "from itertools import product\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D \n",
    "from keras.layers import MaxPooling2D \n",
    "from keras.layers import Flatten \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "from keras.layers import  Input, Conv2D, Conv2DTranspose, ReLU,AveragePooling2D, MaxPooling2D, Dense, BatchNormalization, GlobalAveragePooling2D, Concatenate\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras import backend as K\n",
    "\n",
    "base_dir = r'C:\\Users\\1217s\\Desktop\\capstone deeplearning\\images\\man'\n",
    "\n",
    "train_img_dir = r'C:\\Users\\1217s\\Desktop\\capstone deeplearning\\images\\man\\train'\n",
    "\n",
    "test_img_dir = r'C:\\Users\\1217s\\Desktop\\capstone deeplearning\\images\\man\\test'\n",
    "\n",
    "val_img_dir = r'C:\\Users\\1217s\\Desktop\\capstone deeplearning\\images\\man\\val'\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "batch_size = 512\n",
    "\n",
    "\n",
    "\n",
    "print(f'batchSIZE is {batch_size}, Learning Rate is {learning_rate}')\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "categories = ['dog','cat','bear','hamster','horse']\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(train_img_dir, target_size=(128,128), \n",
    "                                             classes=categories, \n",
    "                                             batch_size=batch_size)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(test_img_dir,\n",
    "                                        target_size=(128,128), \n",
    "                                        classes=categories, \n",
    "                                        batch_size=batch_size)\n",
    "\n",
    "val_set = test_datagen.flow_from_directory(val_img_dir,\n",
    "                                        target_size=(128,128), \n",
    "                                        classes=categories, \n",
    "                                        batch_size=batch_size)\n",
    "\n",
    "x_train, y_train = next(training_set)\n",
    "x_test, y_test = next(test_set)\n",
    "x_val,y_val = next(val_set)   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = Input(shape=(128, 128, 3))\n",
    "    \n",
    "\n",
    "    conv2_1 = Conv2D(32, 3, 1, 'SAME')(inputs)\n",
    "    conv2_2 = Conv2D(32, 3, 1, 'SAME')(conv2_1)\n",
    "    pool2_3 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv2_2)\n",
    "    br1 = BatchNormalization()(pool2_3)\n",
    "    \n",
    "    conv2_1 = Conv2D(32, 3, 1, 'SAME')(br1)\n",
    "    conv2_2 = Conv2D(32, 3, 1, 'SAME')(conv2_1)\n",
    "    pool2_3 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv2_2)\n",
    "    br1 = BatchNormalization()(pool2_3)\n",
    "    \n",
    "    \n",
    "    conv3_1 = Conv2D(64, 3, 1, 'SAME')(br1)\n",
    "    conv3_2 = Conv2D(64, 3, 1, 'SAME')(conv3_1)\n",
    "    pool3_2 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv3_2)\n",
    "    br2 = BatchNormalization()(pool3_2)\n",
    "    \n",
    "    conv3_1 = Conv2D(64, 3, 1, 'SAME')(br2)\n",
    "    conv3_2 = Conv2D(64, 3, 1, 'SAME')(conv3_1)\n",
    "    pool3_2 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv3_2)\n",
    "    br2 = BatchNormalization()(pool3_2)\n",
    "    \n",
    "    \n",
    "    conv4_1 = Conv2D(128, 3, 1, 'SAME')(br2)\n",
    "    conv4_2 = Conv2D(128, 3, 1, 'SAME')(conv4_1)\n",
    "    pool4_2 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv4_2)\n",
    "    br3 = BatchNormalization()(pool4_2)\n",
    "    \n",
    "    conv4_1 = Conv2D(128, 3, 1, 'SAME')(br3)\n",
    "    conv4_2 = Conv2D(128, 3, 1, 'SAME')(conv4_1)\n",
    "    pool4_2 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv4_2)\n",
    "    br3 = BatchNormalization()(pool4_2)\n",
    "    \n",
    "    flatten1 = Flatten()(pool4_2)\n",
    "    dense1 = Dense(units = 512, activation = 'relu')(flatten1)\n",
    "    dense2 = Dense(units = 1024, activation = 'relu')(dense1)\n",
    "    dr1 = Dropout(0.7)(dense2)\n",
    "    dense3 = Dense(units = 5, activation = 'sigmoid')(dr1)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=dense3) \n",
    "def mobile_net():\n",
    "    inputs = Input(shape=(128, 128, 3))\n",
    "    mobileNet = MobileNetV2(weights = \"imagenet\", include_top=False,input_shape = (128,128,3)\n",
    "                            ,input_tensor = inputs)\n",
    "#     for layer in mobileNet.layers:\n",
    "#         layer.trainable = True\n",
    "        \n",
    "    output = mobileNet.output\n",
    "    pooling = AveragePooling2D(pool_size=(4,4),padding='SAME')(output)\n",
    "    \n",
    "    flatten1 = Flatten()(pooling)\n",
    "    dense1 = Dense(units = 512, activation = 'relu')(flatten1)\n",
    "    dense2 = Dense(units = 1024, activation = 'relu')(dense1)\n",
    "    dr1 = Dropout(0.7)(dense2)\n",
    "    dense3 = Dense(units = 5, activation = 'sigmoid')(dr1)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=dense3)\n",
    "\n",
    "class ResidualUnit(tf.keras.Model):\n",
    "    def __init__(self, filter_in, filter_out, kernel_size):\n",
    "        super(ResidualUnit, self).__init__()\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filter_out, kernel_size, padding='same')\n",
    "        \n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filter_out, kernel_size, padding='same')\n",
    "        \n",
    "        if filter_in == filter_out:\n",
    "            self.identity = lambda x: x\n",
    "        else:\n",
    "            self.identity = tf.keras.layers.Conv2D(filter_out, (1,1), padding='same')\n",
    "\n",
    "    def call(self, x, training=False, mask=None):\n",
    "        h = self.bn1(x, training=training)\n",
    "        h = tf.nn.relu(h)\n",
    "        h = self.conv1(h)\n",
    "        \n",
    "        h = self.bn2(h, training=training)\n",
    "        h = tf.nn.relu(h)\n",
    "        h = self.conv2(h)\n",
    "        return self.identity(x) + h\n",
    "    \n",
    "class ResnetLayer(tf.keras.Model):\n",
    "    def __init__(self, filter_in, filters, kernel_size):\n",
    "        super(ResnetLayer, self).__init__()\n",
    "        self.sequence = list()\n",
    "        for f_in, f_out in zip([filter_in] + list(filters), filters):\n",
    "            self.sequence.append(ResidualUnit(f_in, f_out, kernel_size))\n",
    "\n",
    "    def call(self, x, training=False, mask=None):\n",
    "        for unit in self.sequence:\n",
    "            x = unit(x, training=training)\n",
    "        return x\n",
    "    \n",
    "class ResNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu') # 28x28x8\n",
    "        \n",
    "        self.res1 = ResnetLayer(64, (16, 16), (3, 3)) # 28x28x16\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D((2, 2)) # 14x14x16\n",
    "        \n",
    "        \n",
    "        self.res2 = ResnetLayer(128, (32, 32), (3, 3)) # 14x14x32\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D((2, 2)) # 7x7x32\n",
    "    \n",
    "        \n",
    "        self.res3 = ResnetLayer(256, (64, 64), (3, 3)) # 7x7x64\n",
    "        self.pool = tf.keras.layers.MaxPool2D((2, 2)) # 7x7x32\n",
    "        \n",
    "        \n",
    "        self.res4 = ResnetLayer(512, (64, 64), (3, 3)) # 7x7x64\n",
    "        self.pool = tf.keras.layers.MaxPool2D((2, 2)) # 7x7x32\n",
    "        \n",
    "        \n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(1024, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(5, activation='softmax')\n",
    "        \n",
    "    def call(self, x, training=False, mask=None):\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        x = self.res1(x, training=training)\n",
    "        x = self.pool1(x)\n",
    "        x = self.res2(x, training=training)\n",
    "        x = self.pool2(x)\n",
    "        x = self.res3(x, training=training)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "20/20 [==============================] - 16s 811ms/step - loss: 0.4528 - accuracy: 0.4824 - precision: 0.5910 - recall: 0.3455 - f1score: 0.4072 - val_loss: 0.5812 - val_accuracy: 0.4836 - val_precision: 0.7806 - val_recall: 0.1363 - val_f1score: 0.2230\n",
      "Epoch 2/150\n",
      "20/20 [==============================] - 15s 771ms/step - loss: 0.2821 - accuracy: 0.6855 - precision: 0.7549 - recall: 0.6391 - f1score: 0.6888 - val_loss: 1.2839 - val_accuracy: 0.3239 - val_precision: 0.5930 - val_recall: 0.1388 - val_f1score: 0.2225\n",
      "Epoch 3/150\n",
      "20/20 [==============================] - 16s 779ms/step - loss: 0.1879 - accuracy: 0.8301 - precision: 0.8545 - recall: 0.7861 - f1score: 0.8169 - val_loss: 0.8580 - val_accuracy: 0.5070 - val_precision: 0.8455 - val_recall: 0.2060 - val_f1score: 0.3275\n",
      "Epoch 4/150\n",
      "20/20 [==============================] - 16s 777ms/step - loss: 0.1617 - accuracy: 0.8613 - precision: 0.8938 - recall: 0.8415 - f1score: 0.8662 - val_loss: 1.4603 - val_accuracy: 0.3521 - val_precision: 0.4156 - val_recall: 0.2932 - val_f1score: 0.3430\n",
      "Epoch 5/150\n",
      "20/20 [==============================] - 15s 750ms/step - loss: 0.1754 - accuracy: 0.8672 - precision: 0.8862 - recall: 0.8415 - f1score: 0.8623 - val_loss: 1.0762 - val_accuracy: 0.4038 - val_precision: 0.5325 - val_recall: 0.3467 - val_f1score: 0.4193\n",
      "Epoch 6/150\n",
      "20/20 [==============================] - 15s 747ms/step - loss: 0.0895 - accuracy: 0.9199 - precision: 0.9253 - recall: 0.9126 - f1score: 0.9185 - val_loss: 1.9615 - val_accuracy: 0.2911 - val_precision: 0.3271 - val_recall: 0.2753 - val_f1score: 0.2983\n",
      "Epoch 7/150\n",
      "20/20 [==============================] - 15s 761ms/step - loss: 0.0963 - accuracy: 0.9297 - precision: 0.9373 - recall: 0.9079 - f1score: 0.9221 - val_loss: 3.3268 - val_accuracy: 0.2207 - val_precision: 0.2213 - val_recall: 0.2194 - val_f1score: 0.2203\n",
      "Epoch 8/150\n",
      "20/20 [==============================] - 15s 750ms/step - loss: 0.1064 - accuracy: 0.9062 - precision: 0.9120 - recall: 0.8983 - f1score: 0.9048 - val_loss: 1.2699 - val_accuracy: 0.4695 - val_precision: 0.7897 - val_recall: 0.1813 - val_f1score: 0.2876\n",
      "Epoch 9/150\n",
      "20/20 [==============================] - 15s 765ms/step - loss: 0.1161 - accuracy: 0.9199 - precision: 0.9256 - recall: 0.9098 - f1score: 0.9172 - val_loss: 3.2328 - val_accuracy: 0.1831 - val_precision: 0.1915 - val_recall: 0.1903 - val_f1score: 0.1908\n",
      "Epoch 10/150\n",
      "20/20 [==============================] - 15s 759ms/step - loss: 0.1221 - accuracy: 0.9180 - precision: 0.9269 - recall: 0.8957 - f1score: 0.9100 - val_loss: 0.9844 - val_accuracy: 0.3662 - val_precision: 0.4508 - val_recall: 0.2283 - val_f1score: 0.3021\n",
      "Epoch 11/150\n",
      "20/20 [==============================] - 16s 776ms/step - loss: 0.0734 - accuracy: 0.9531 - precision: 0.9625 - recall: 0.9376 - f1score: 0.9497 - val_loss: 2.5817 - val_accuracy: 0.2207 - val_precision: 0.2275 - val_recall: 0.2239 - val_f1score: 0.2256\n",
      "Epoch 12/150\n",
      "20/20 [==============================] - 15s 767ms/step - loss: 0.0232 - accuracy: 0.9805 - precision: 0.9865 - recall: 0.9712 - f1score: 0.9786 - val_loss: 3.7313 - val_accuracy: 0.2207 - val_precision: 0.2239 - val_recall: 0.2239 - val_f1score: 0.2239\n",
      "Epoch 13/150\n",
      "20/20 [==============================] - 16s 788ms/step - loss: 0.0097 - accuracy: 0.9980 - precision: 0.9944 - recall: 0.9981 - f1score: 0.9962 - val_loss: 2.6708 - val_accuracy: 0.2770 - val_precision: 0.2880 - val_recall: 0.2844 - val_f1score: 0.2861\n",
      "Epoch 14/150\n",
      "20/20 [==============================] - 15s 752ms/step - loss: 0.0097 - accuracy: 0.9941 - precision: 0.9933 - recall: 0.9895 - f1score: 0.9914 - val_loss: 1.8149 - val_accuracy: 0.2958 - val_precision: 0.3335 - val_recall: 0.2800 - val_f1score: 0.3037\n",
      "Epoch 15/150\n",
      "20/20 [==============================] - 15s 750ms/step - loss: 0.0066 - accuracy: 0.9941 - precision: 0.9953 - recall: 0.9915 - f1score: 0.9933 - val_loss: 2.1356 - val_accuracy: 0.2817 - val_precision: 0.3003 - val_recall: 0.2755 - val_f1score: 0.2872\n",
      "Epoch 16/150\n",
      "20/20 [==============================] - 16s 786ms/step - loss: 0.0052 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9962 - f1score: 0.9971 - val_loss: 1.5913 - val_accuracy: 0.3615 - val_precision: 0.4296 - val_recall: 0.3089 - val_f1score: 0.3578\n",
      "Epoch 17/150\n",
      "20/20 [==============================] - 15s 756ms/step - loss: 0.0023 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 1.6682 - val_accuracy: 0.3709 - val_precision: 0.4158 - val_recall: 0.3002 - val_f1score: 0.3464\n",
      "Epoch 18/150\n",
      "20/20 [==============================] - 15s 770ms/step - loss: 0.0102 - accuracy: 0.9922 - precision: 0.9905 - recall: 0.9923 - f1score: 0.9914 - val_loss: 3.9005 - val_accuracy: 0.2254 - val_precision: 0.2360 - val_recall: 0.2283 - val_f1score: 0.2320\n",
      "Epoch 19/150\n",
      "20/20 [==============================] - 16s 778ms/step - loss: 0.0192 - accuracy: 0.9883 - precision: 0.9849 - recall: 0.9868 - f1score: 0.9858 - val_loss: 5.1296 - val_accuracy: 0.2254 - val_precision: 0.2243 - val_recall: 0.2239 - val_f1score: 0.2241\n",
      "Epoch 20/150\n",
      "20/20 [==============================] - 16s 779ms/step - loss: 0.0381 - accuracy: 0.9805 - precision: 0.9815 - recall: 0.9771 - f1score: 0.9793 - val_loss: 1.4617 - val_accuracy: 0.4272 - val_precision: 0.4973 - val_recall: 0.3805 - val_f1score: 0.4298\n",
      "Epoch 21/150\n",
      "20/20 [==============================] - 16s 782ms/step - loss: 0.0234 - accuracy: 0.9785 - precision: 0.9854 - recall: 0.9733 - f1score: 0.9789 - val_loss: 1.3422 - val_accuracy: 0.4319 - val_precision: 0.4876 - val_recall: 0.3829 - val_f1score: 0.4286\n",
      "Epoch 22/150\n",
      "20/20 [==============================] - 16s 776ms/step - loss: 0.0196 - accuracy: 0.9863 - precision: 0.9848 - recall: 0.9885 - f1score: 0.9865 - val_loss: 1.5994 - val_accuracy: 0.4507 - val_precision: 0.4611 - val_recall: 0.3759 - val_f1score: 0.4135\n",
      "Epoch 23/150\n",
      "20/20 [==============================] - 16s 780ms/step - loss: 0.0101 - accuracy: 0.9922 - precision: 0.9923 - recall: 0.9923 - f1score: 0.9923 - val_loss: 1.4739 - val_accuracy: 0.4883 - val_precision: 0.5301 - val_recall: 0.4568 - val_f1score: 0.4900\n",
      "Epoch 24/150\n",
      "20/20 [==============================] - 16s 786ms/step - loss: 0.0067 - accuracy: 0.9961 - precision: 0.9981 - recall: 0.9942 - f1score: 0.9961 - val_loss: 1.6154 - val_accuracy: 0.4930 - val_precision: 0.4963 - val_recall: 0.4341 - val_f1score: 0.4628\n",
      "Epoch 25/150\n",
      "20/20 [==============================] - 16s 789ms/step - loss: 0.0235 - accuracy: 0.9941 - precision: 0.9934 - recall: 0.9934 - f1score: 0.9934 - val_loss: 1.8042 - val_accuracy: 0.4836 - val_precision: 0.4990 - val_recall: 0.4520 - val_f1score: 0.4741\n",
      "Epoch 26/150\n",
      "20/20 [==============================] - 16s 775ms/step - loss: 0.0087 - accuracy: 0.9941 - precision: 0.9924 - recall: 0.9906 - f1score: 0.9915 - val_loss: 1.5663 - val_accuracy: 0.5117 - val_precision: 0.5238 - val_recall: 0.4632 - val_f1score: 0.4913\n",
      "Epoch 27/150\n",
      "20/20 [==============================] - 15s 766ms/step - loss: 0.0051 - accuracy: 0.9961 - precision: 0.9962 - recall: 0.9962 - f1score: 0.9962 - val_loss: 1.1889 - val_accuracy: 0.5399 - val_precision: 0.5834 - val_recall: 0.5217 - val_f1score: 0.5501\n",
      "Epoch 28/150\n",
      "20/20 [==============================] - 15s 763ms/step - loss: 0.0025 - accuracy: 0.9980 - precision: 1.0000 - recall: 0.9981 - f1score: 0.9990 - val_loss: 1.1804 - val_accuracy: 0.5540 - val_precision: 0.6067 - val_recall: 0.5508 - val_f1score: 0.5769\n",
      "Epoch 29/150\n",
      "20/20 [==============================] - 15s 765ms/step - loss: 0.0018 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 1.2154 - val_accuracy: 0.5681 - val_precision: 0.6210 - val_recall: 0.5687 - val_f1score: 0.5933\n",
      "Epoch 30/150\n",
      "20/20 [==============================] - 15s 763ms/step - loss: 0.0038 - accuracy: 0.9961 - precision: 0.9962 - recall: 0.9962 - f1score: 0.9962 - val_loss: 1.1408 - val_accuracy: 0.5634 - val_precision: 0.6329 - val_recall: 0.5642 - val_f1score: 0.5960\n",
      "Epoch 31/150\n",
      "20/20 [==============================] - 15s 763ms/step - loss: 0.0017 - accuracy: 1.0000 - precision: 0.9981 - recall: 1.0000 - f1score: 0.9991 - val_loss: 1.1140 - val_accuracy: 0.5869 - val_precision: 0.6640 - val_recall: 0.5821 - val_f1score: 0.6195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/150\n",
      "20/20 [==============================] - 15s 756ms/step - loss: 0.0012 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 1.1271 - val_accuracy: 0.6103 - val_precision: 0.6507 - val_recall: 0.5821 - val_f1score: 0.6137\n",
      "Epoch 33/150\n",
      "20/20 [==============================] - 15s 761ms/step - loss: 0.0140 - accuracy: 0.9922 - precision: 0.9923 - recall: 0.9904 - f1score: 0.9913 - val_loss: 1.1300 - val_accuracy: 0.6197 - val_precision: 0.6641 - val_recall: 0.6133 - val_f1score: 0.6374\n",
      "Epoch 34/150\n",
      "20/20 [==============================] - 15s 760ms/step - loss: 0.0023 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 1.1292 - val_accuracy: 0.6244 - val_precision: 0.6636 - val_recall: 0.6267 - val_f1score: 0.6442\n",
      "Epoch 35/150\n",
      "20/20 [==============================] - 15s 758ms/step - loss: 0.0036 - accuracy: 0.9980 - precision: 0.9961 - recall: 0.9962 - f1score: 0.9961 - val_loss: 1.1279 - val_accuracy: 0.6291 - val_precision: 0.6561 - val_recall: 0.6267 - val_f1score: 0.6407\n",
      "Epoch 36/150\n",
      "20/20 [==============================] - 15s 768ms/step - loss: 0.0025 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 1.1356 - val_accuracy: 0.6432 - val_precision: 0.6621 - val_recall: 0.6267 - val_f1score: 0.6436\n",
      "Epoch 37/150\n",
      "20/20 [==============================] - 15s 759ms/step - loss: 0.0039 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 1.1678 - val_accuracy: 0.6479 - val_precision: 0.6588 - val_recall: 0.6356 - val_f1score: 0.6466\n",
      "Epoch 38/150\n",
      "20/20 [==============================] - 15s 748ms/step - loss: 0.0015 - accuracy: 0.9980 - precision: 0.9981 - recall: 1.0000 - f1score: 0.9991 - val_loss: 1.1476 - val_accuracy: 0.6432 - val_precision: 0.6672 - val_recall: 0.6401 - val_f1score: 0.6531\n",
      "Epoch 39/150\n",
      "20/20 [==============================] - 15s 746ms/step - loss: 9.7837e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 1.1337 - val_accuracy: 0.6385 - val_precision: 0.6672 - val_recall: 0.6312 - val_f1score: 0.6483\n",
      "Epoch 40/150\n",
      "20/20 [==============================] - 15s 744ms/step - loss: 7.6599e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 1.1203 - val_accuracy: 0.6432 - val_precision: 0.6735 - val_recall: 0.6446 - val_f1score: 0.6582\n",
      "Epoch 41/150\n",
      "20/20 [==============================] - 15s 740ms/step - loss: 4.5693e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 1.1067 - val_accuracy: 0.6432 - val_precision: 0.6732 - val_recall: 0.6490 - val_f1score: 0.6607\n",
      "Epoch 42/150\n",
      "20/20 [==============================] - 15s 745ms/step - loss: 9.4289e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 1.0958 - val_accuracy: 0.6526 - val_precision: 0.6842 - val_recall: 0.6624 - val_f1score: 0.6729\n",
      "Epoch 43/150\n",
      "20/20 [==============================] - 15s 750ms/step - loss: 0.0017 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 1.0602 - val_accuracy: 0.6573 - val_precision: 0.6790 - val_recall: 0.6580 - val_f1score: 0.6680\n",
      "Epoch 44/150\n",
      "20/20 [==============================] - 15s 762ms/step - loss: 6.2511e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 1.0388 - val_accuracy: 0.6714 - val_precision: 0.6858 - val_recall: 0.6535 - val_f1score: 0.6690\n",
      "Epoch 45/150\n",
      "20/20 [==============================] - 15s 745ms/step - loss: 6.2651e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 1.0248 - val_accuracy: 0.6761 - val_precision: 0.6908 - val_recall: 0.6692 - val_f1score: 0.6795\n",
      "Epoch 46/150\n",
      "20/20 [==============================] - 15s 746ms/step - loss: 4.9729e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 1.0131 - val_accuracy: 0.6714 - val_precision: 0.6912 - val_recall: 0.6692 - val_f1score: 0.6796\n",
      "Epoch 47/150\n",
      "20/20 [==============================] - 15s 743ms/step - loss: 8.4683e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9981 - f1score: 0.9990 - val_loss: 1.0139 - val_accuracy: 0.6761 - val_precision: 0.6932 - val_recall: 0.6737 - val_f1score: 0.6829\n",
      "Epoch 48/150\n",
      "20/20 [==============================] - 15s 765ms/step - loss: 0.0017 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 1.0357 - val_accuracy: 0.6808 - val_precision: 0.6878 - val_recall: 0.6737 - val_f1score: 0.6805\n",
      "Epoch 49/150\n",
      "20/20 [==============================] - 15s 763ms/step - loss: 0.0011 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 1.0145 - val_accuracy: 0.6808 - val_precision: 0.6967 - val_recall: 0.6781 - val_f1score: 0.6872\n",
      "Epoch 50/150\n",
      "20/20 [==============================] - 15s 755ms/step - loss: 8.9833e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.9958 - val_accuracy: 0.6854 - val_precision: 0.6967 - val_recall: 0.6781 - val_f1score: 0.6872\n",
      "Epoch 51/150\n",
      "20/20 [==============================] - 15s 746ms/step - loss: 4.3568e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.9731 - val_accuracy: 0.6854 - val_precision: 0.7047 - val_recall: 0.6781 - val_f1score: 0.6909\n",
      "Epoch 52/150\n",
      "20/20 [==============================] - 15s 740ms/step - loss: 7.4367e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.9502 - val_accuracy: 0.6948 - val_precision: 0.7092 - val_recall: 0.6826 - val_f1score: 0.6954\n",
      "Epoch 53/150\n",
      "20/20 [==============================] - 15s 739ms/step - loss: 0.0013 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.9317 - val_accuracy: 0.6995 - val_precision: 0.7124 - val_recall: 0.6960 - val_f1score: 0.7040\n",
      "Epoch 54/150\n",
      "20/20 [==============================] - 15s 744ms/step - loss: 0.0019 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 0.9033 - val_accuracy: 0.7089 - val_precision: 0.7139 - val_recall: 0.7094 - val_f1score: 0.7115\n",
      "Epoch 55/150\n",
      "20/20 [==============================] - 15s 742ms/step - loss: 6.7268e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.8768 - val_accuracy: 0.7136 - val_precision: 0.7230 - val_recall: 0.7183 - val_f1score: 0.7206\n",
      "Epoch 56/150\n",
      "20/20 [==============================] - 15s 741ms/step - loss: 0.0100 - accuracy: 0.9980 - precision: 0.9963 - recall: 0.9981 - f1score: 0.9972 - val_loss: 0.8508 - val_accuracy: 0.7277 - val_precision: 0.7363 - val_recall: 0.7228 - val_f1score: 0.7295\n",
      "Epoch 57/150\n",
      "20/20 [==============================] - 15s 739ms/step - loss: 8.1376e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.8300 - val_accuracy: 0.7371 - val_precision: 0.7497 - val_recall: 0.7451 - val_f1score: 0.7472\n",
      "Epoch 58/150\n",
      "20/20 [==============================] - 15s 739ms/step - loss: 0.0013 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9981 - f1score: 0.9990 - val_loss: 0.8096 - val_accuracy: 0.7559 - val_precision: 0.7589 - val_recall: 0.7540 - val_f1score: 0.7563\n",
      "Epoch 59/150\n",
      "20/20 [==============================] - 15s 738ms/step - loss: 3.8936e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.7914 - val_accuracy: 0.7559 - val_precision: 0.7591 - val_recall: 0.7562 - val_f1score: 0.7576\n",
      "Epoch 60/150\n",
      "20/20 [==============================] - 15s 742ms/step - loss: 0.0015 - accuracy: 0.9980 - precision: 0.9981 - recall: 1.0000 - f1score: 0.9991 - val_loss: 0.7719 - val_accuracy: 0.7606 - val_precision: 0.7658 - val_recall: 0.7562 - val_f1score: 0.7609\n",
      "Epoch 61/150\n",
      "20/20 [==============================] - 15s 744ms/step - loss: 5.0218e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.7514 - val_accuracy: 0.7606 - val_precision: 0.7627 - val_recall: 0.7562 - val_f1score: 0.7593\n",
      "Epoch 62/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 15s 747ms/step - loss: 3.8290e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.7331 - val_accuracy: 0.7606 - val_precision: 0.7627 - val_recall: 0.7562 - val_f1score: 0.7593\n",
      "Epoch 63/150\n",
      "20/20 [==============================] - 15s 747ms/step - loss: 0.0010 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.7173 - val_accuracy: 0.7653 - val_precision: 0.7719 - val_recall: 0.7651 - val_f1score: 0.7684\n",
      "Epoch 64/150\n",
      "20/20 [==============================] - 15s 740ms/step - loss: 4.2262e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.7021 - val_accuracy: 0.7746 - val_precision: 0.7770 - val_recall: 0.7740 - val_f1score: 0.7754\n",
      "Epoch 65/150\n",
      "20/20 [==============================] - 15s 740ms/step - loss: 6.9862e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.6881 - val_accuracy: 0.7746 - val_precision: 0.7792 - val_recall: 0.7696 - val_f1score: 0.7742\n",
      "Epoch 66/150\n",
      "20/20 [==============================] - 15s 740ms/step - loss: 5.4738e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.6747 - val_accuracy: 0.7746 - val_precision: 0.7813 - val_recall: 0.7651 - val_f1score: 0.7730\n",
      "Epoch 67/150\n",
      "20/20 [==============================] - 15s 738ms/step - loss: 8.4550e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.6619 - val_accuracy: 0.7793 - val_precision: 0.7813 - val_recall: 0.7651 - val_f1score: 0.7730\n",
      "Epoch 68/150\n",
      "20/20 [==============================] - 15s 739ms/step - loss: 0.0014 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.6486 - val_accuracy: 0.7887 - val_precision: 0.7837 - val_recall: 0.7740 - val_f1score: 0.7788\n",
      "Epoch 69/150\n",
      "20/20 [==============================] - 15s 741ms/step - loss: 3.7281e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.6366 - val_accuracy: 0.7840 - val_precision: 0.7837 - val_recall: 0.7740 - val_f1score: 0.7788\n",
      "Epoch 70/150\n",
      "20/20 [==============================] - 15s 739ms/step - loss: 0.0085 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 0.6245 - val_accuracy: 0.7840 - val_precision: 0.7903 - val_recall: 0.7740 - val_f1score: 0.7819\n",
      "Epoch 71/150\n",
      "20/20 [==============================] - 15s 741ms/step - loss: 5.3675e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.6139 - val_accuracy: 0.7887 - val_precision: 0.7881 - val_recall: 0.7740 - val_f1score: 0.7809\n",
      "Epoch 72/150\n",
      "20/20 [==============================] - 15s 754ms/step - loss: 3.6172e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.6035 - val_accuracy: 0.7887 - val_precision: 0.7881 - val_recall: 0.7740 - val_f1score: 0.7809\n",
      "Epoch 73/150\n",
      "20/20 [==============================] - 15s 741ms/step - loss: 6.7702e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.5937 - val_accuracy: 0.7840 - val_precision: 0.7933 - val_recall: 0.7830 - val_f1score: 0.7880\n",
      "Epoch 74/150\n",
      "20/20 [==============================] - 15s 740ms/step - loss: 0.0019 - accuracy: 0.9980 - precision: 0.9981 - recall: 1.0000 - f1score: 0.9991 - val_loss: 0.5841 - val_accuracy: 0.7840 - val_precision: 0.7972 - val_recall: 0.7830 - val_f1score: 0.7898\n",
      "Epoch 75/150\n",
      "20/20 [==============================] - 15s 741ms/step - loss: 8.6325e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.5750 - val_accuracy: 0.7887 - val_precision: 0.7972 - val_recall: 0.7830 - val_f1score: 0.7898\n",
      "Epoch 76/150\n",
      "20/20 [==============================] - 15s 740ms/step - loss: 8.0699e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.5662 - val_accuracy: 0.7887 - val_precision: 0.7961 - val_recall: 0.7785 - val_f1score: 0.7869\n",
      "Epoch 77/150\n",
      "20/20 [==============================] - 15s 751ms/step - loss: 3.0987e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.5575 - val_accuracy: 0.7934 - val_precision: 0.8049 - val_recall: 0.7785 - val_f1score: 0.7913\n",
      "Epoch 78/150\n",
      "20/20 [==============================] - 16s 783ms/step - loss: 2.5863e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.5493 - val_accuracy: 0.7887 - val_precision: 0.8039 - val_recall: 0.7740 - val_f1score: 0.7885\n",
      "Epoch 79/150\n",
      "20/20 [==============================] - 15s 740ms/step - loss: 0.0018 - accuracy: 0.9980 - precision: 0.9981 - recall: 1.0000 - f1score: 0.9991 - val_loss: 0.5411 - val_accuracy: 0.7887 - val_precision: 0.8039 - val_recall: 0.7740 - val_f1score: 0.7885\n",
      "Epoch 80/150\n",
      "20/20 [==============================] - 15s 742ms/step - loss: 3.4122e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.5335 - val_accuracy: 0.7934 - val_precision: 0.8039 - val_recall: 0.7740 - val_f1score: 0.7885\n",
      "Epoch 81/150\n",
      "20/20 [==============================] - 15s 737ms/step - loss: 2.0999e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.5259 - val_accuracy: 0.7934 - val_precision: 0.8059 - val_recall: 0.7830 - val_f1score: 0.7942\n",
      "Epoch 82/150\n",
      "20/20 [==============================] - 15s 745ms/step - loss: 4.5303e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.5186 - val_accuracy: 0.7934 - val_precision: 0.8070 - val_recall: 0.7830 - val_f1score: 0.7947\n",
      "Epoch 83/150\n",
      "20/20 [==============================] - 15s 740ms/step - loss: 5.0039e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.5116 - val_accuracy: 0.7981 - val_precision: 0.8072 - val_recall: 0.7874 - val_f1score: 0.7971\n",
      "Epoch 84/150\n",
      "20/20 [==============================] - 15s 742ms/step - loss: 4.2433e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.5046 - val_accuracy: 0.7981 - val_precision: 0.8086 - val_recall: 0.7942 - val_f1score: 0.8012\n",
      "Epoch 85/150\n",
      "20/20 [==============================] - 15s 739ms/step - loss: 0.0014 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9981 - f1score: 0.9990 - val_loss: 0.4978 - val_accuracy: 0.7981 - val_precision: 0.8086 - val_recall: 0.7942 - val_f1score: 0.8012\n",
      "Epoch 86/150\n",
      "20/20 [==============================] - 15s 740ms/step - loss: 0.0039 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9962 - f1score: 0.9971 - val_loss: 0.4913 - val_accuracy: 0.7981 - val_precision: 0.8092 - val_recall: 0.7942 - val_f1score: 0.8016\n",
      "Epoch 87/150\n",
      "20/20 [==============================] - 15s 740ms/step - loss: 5.7329e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4852 - val_accuracy: 0.7981 - val_precision: 0.8092 - val_recall: 0.7942 - val_f1score: 0.8016\n",
      "Epoch 88/150\n",
      "20/20 [==============================] - 15s 738ms/step - loss: 4.4359e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4792 - val_accuracy: 0.8028 - val_precision: 0.8092 - val_recall: 0.7942 - val_f1score: 0.8016\n",
      "Epoch 89/150\n",
      "20/20 [==============================] - 15s 746ms/step - loss: 8.2169e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4733 - val_accuracy: 0.8028 - val_precision: 0.8148 - val_recall: 0.7898 - val_f1score: 0.8020\n",
      "Epoch 90/150\n",
      "20/20 [==============================] - 15s 739ms/step - loss: 9.1357e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4675 - val_accuracy: 0.8028 - val_precision: 0.8148 - val_recall: 0.7898 - val_f1score: 0.8020\n",
      "Epoch 91/150\n",
      "20/20 [==============================] - 15s 745ms/step - loss: 4.8349e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4618 - val_accuracy: 0.8028 - val_precision: 0.8149 - val_recall: 0.7942 - val_f1score: 0.8043\n",
      "Epoch 92/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 15s 744ms/step - loss: 4.2116e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4561 - val_accuracy: 0.8028 - val_precision: 0.8149 - val_recall: 0.7942 - val_f1score: 0.8043\n",
      "Epoch 93/150\n",
      "20/20 [==============================] - 15s 741ms/step - loss: 5.5197e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4508 - val_accuracy: 0.8028 - val_precision: 0.8106 - val_recall: 0.7942 - val_f1score: 0.8022\n",
      "Epoch 94/150\n",
      "20/20 [==============================] - 15s 742ms/step - loss: 8.7505e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4457 - val_accuracy: 0.7981 - val_precision: 0.8106 - val_recall: 0.7942 - val_f1score: 0.8022\n",
      "Epoch 95/150\n",
      "20/20 [==============================] - 15s 740ms/step - loss: 2.7085e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4407 - val_accuracy: 0.7981 - val_precision: 0.8106 - val_recall: 0.7942 - val_f1score: 0.8022\n",
      "Epoch 96/150\n",
      "20/20 [==============================] - 15s 742ms/step - loss: 3.5211e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4358 - val_accuracy: 0.7981 - val_precision: 0.8040 - val_recall: 0.7942 - val_f1score: 0.7990\n",
      "Epoch 97/150\n",
      "20/20 [==============================] - 15s 742ms/step - loss: 0.0013 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4313 - val_accuracy: 0.7981 - val_precision: 0.8040 - val_recall: 0.7942 - val_f1score: 0.7990\n",
      "Epoch 98/150\n",
      "20/20 [==============================] - 15s 741ms/step - loss: 8.7643e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4267 - val_accuracy: 0.7981 - val_precision: 0.8075 - val_recall: 0.7942 - val_f1score: 0.8007\n",
      "Epoch 99/150\n",
      "20/20 [==============================] - 15s 741ms/step - loss: 6.6991e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4225 - val_accuracy: 0.8028 - val_precision: 0.8151 - val_recall: 0.7987 - val_f1score: 0.8066\n",
      "Epoch 100/150\n",
      "20/20 [==============================] - 15s 744ms/step - loss: 5.8993e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4185 - val_accuracy: 0.8075 - val_precision: 0.8151 - val_recall: 0.7987 - val_f1score: 0.8066\n",
      "Epoch 101/150\n",
      "20/20 [==============================] - 15s 739ms/step - loss: 0.0041 - accuracy: 0.9980 - precision: 0.9972 - recall: 0.9972 - f1score: 0.9972 - val_loss: 0.4148 - val_accuracy: 0.8075 - val_precision: 0.8109 - val_recall: 0.7987 - val_f1score: 0.8045\n",
      "Epoch 102/150\n",
      "20/20 [==============================] - 15s 731ms/step - loss: 0.0012 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4112 - val_accuracy: 0.8075 - val_precision: 0.8167 - val_recall: 0.7987 - val_f1score: 0.8073\n",
      "Epoch 103/150\n",
      "20/20 [==============================] - 15s 735ms/step - loss: 6.4042e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4078 - val_accuracy: 0.8028 - val_precision: 0.8177 - val_recall: 0.8031 - val_f1score: 0.8102\n",
      "Epoch 104/150\n",
      "20/20 [==============================] - 15s 733ms/step - loss: 0.0012 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4044 - val_accuracy: 0.8075 - val_precision: 0.8175 - val_recall: 0.7987 - val_f1score: 0.8079\n",
      "Epoch 105/150\n",
      "20/20 [==============================] - 15s 733ms/step - loss: 4.9623e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4013 - val_accuracy: 0.8075 - val_precision: 0.8149 - val_recall: 0.8055 - val_f1score: 0.8101\n",
      "Epoch 106/150\n",
      "20/20 [==============================] - 15s 735ms/step - loss: 0.0015 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9981 - f1score: 0.9990 - val_loss: 0.3983 - val_accuracy: 0.8075 - val_precision: 0.8149 - val_recall: 0.8055 - val_f1score: 0.8101\n",
      "Epoch 107/150\n",
      "20/20 [==============================] - 15s 735ms/step - loss: 5.1952e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3954 - val_accuracy: 0.8075 - val_precision: 0.8149 - val_recall: 0.8055 - val_f1score: 0.8101\n",
      "Epoch 108/150\n",
      "20/20 [==============================] - 15s 732ms/step - loss: 4.4497e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.8075 - val_precision: 0.8149 - val_recall: 0.8055 - val_f1score: 0.8101\n",
      "Epoch 109/150\n",
      "20/20 [==============================] - 15s 735ms/step - loss: 3.6887e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3898 - val_accuracy: 0.8075 - val_precision: 0.8149 - val_recall: 0.8055 - val_f1score: 0.8101\n",
      "Epoch 110/150\n",
      "20/20 [==============================] - 15s 733ms/step - loss: 0.0026 - accuracy: 0.9961 - precision: 0.9962 - recall: 0.9981 - f1score: 0.9971 - val_loss: 0.3872 - val_accuracy: 0.8075 - val_precision: 0.8149 - val_recall: 0.8055 - val_f1score: 0.8101\n",
      "Epoch 111/150\n",
      "20/20 [==============================] - 15s 733ms/step - loss: 4.3890e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3847 - val_accuracy: 0.8075 - val_precision: 0.8149 - val_recall: 0.8055 - val_f1score: 0.8101\n",
      "Epoch 112/150\n",
      "20/20 [==============================] - 15s 732ms/step - loss: 3.6066e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3823 - val_accuracy: 0.8075 - val_precision: 0.8191 - val_recall: 0.8099 - val_f1score: 0.8143\n",
      "Epoch 113/150\n",
      "20/20 [==============================] - 15s 734ms/step - loss: 5.6308e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3801 - val_accuracy: 0.8122 - val_precision: 0.8191 - val_recall: 0.8099 - val_f1score: 0.8143\n",
      "Epoch 114/150\n",
      "20/20 [==============================] - 15s 771ms/step - loss: 0.0068 - accuracy: 0.9980 - precision: 0.9972 - recall: 0.9972 - f1score: 0.9972 - val_loss: 0.3779 - val_accuracy: 0.8122 - val_precision: 0.8226 - val_recall: 0.8099 - val_f1score: 0.8160\n",
      "Epoch 115/150\n",
      "20/20 [==============================] - 15s 739ms/step - loss: 0.0035 - accuracy: 0.9980 - precision: 0.9962 - recall: 0.9981 - f1score: 0.9971 - val_loss: 0.3757 - val_accuracy: 0.8216 - val_precision: 0.8226 - val_recall: 0.8099 - val_f1score: 0.8160\n",
      "Epoch 116/150\n",
      "20/20 [==============================] - 15s 738ms/step - loss: 0.0012 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9981 - f1score: 0.9990 - val_loss: 0.3736 - val_accuracy: 0.8216 - val_precision: 0.8226 - val_recall: 0.8099 - val_f1score: 0.8160\n",
      "Epoch 117/150\n",
      "20/20 [==============================] - 15s 736ms/step - loss: 5.0234e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3716 - val_accuracy: 0.8216 - val_precision: 0.8262 - val_recall: 0.8099 - val_f1score: 0.8176\n",
      "Epoch 118/150\n",
      "20/20 [==============================] - 15s 735ms/step - loss: 7.9111e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3694 - val_accuracy: 0.8216 - val_precision: 0.8276 - val_recall: 0.8144 - val_f1score: 0.8207\n",
      "Epoch 119/150\n",
      "20/20 [==============================] - 15s 736ms/step - loss: 9.8122e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3675 - val_accuracy: 0.8216 - val_precision: 0.8276 - val_recall: 0.8144 - val_f1score: 0.8207\n",
      "Epoch 120/150\n",
      "20/20 [==============================] - 15s 736ms/step - loss: 4.1676e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3656 - val_accuracy: 0.8216 - val_precision: 0.8276 - val_recall: 0.8144 - val_f1score: 0.8207\n",
      "Epoch 121/150\n",
      "20/20 [==============================] - 15s 733ms/step - loss: 0.0049 - accuracy: 0.9980 - precision: 0.9972 - recall: 0.9972 - f1score: 0.9972 - val_loss: 0.3639 - val_accuracy: 0.8216 - val_precision: 0.8276 - val_recall: 0.8144 - val_f1score: 0.8207\n",
      "Epoch 122/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 15s 742ms/step - loss: 4.2969e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3622 - val_accuracy: 0.8263 - val_precision: 0.8276 - val_recall: 0.8144 - val_f1score: 0.8207\n",
      "Epoch 123/150\n",
      "20/20 [==============================] - 15s 734ms/step - loss: 3.4840e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3605 - val_accuracy: 0.8263 - val_precision: 0.8276 - val_recall: 0.8144 - val_f1score: 0.8207\n",
      "Epoch 124/150\n",
      "20/20 [==============================] - 15s 737ms/step - loss: 0.0017 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 0.3589 - val_accuracy: 0.8263 - val_precision: 0.8276 - val_recall: 0.8144 - val_f1score: 0.8207\n",
      "Epoch 125/150\n",
      "20/20 [==============================] - 15s 735ms/step - loss: 4.4534e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3573 - val_accuracy: 0.8263 - val_precision: 0.8276 - val_recall: 0.8144 - val_f1score: 0.8207\n",
      "Epoch 126/150\n",
      "20/20 [==============================] - 15s 736ms/step - loss: 4.8114e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3558 - val_accuracy: 0.8263 - val_precision: 0.8276 - val_recall: 0.8144 - val_f1score: 0.8207\n",
      "Epoch 127/150\n",
      "20/20 [==============================] - 15s 740ms/step - loss: 6.5361e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.8263 - val_precision: 0.8276 - val_recall: 0.8144 - val_f1score: 0.8207\n",
      "Epoch 128/150\n",
      "20/20 [==============================] - 15s 732ms/step - loss: 0.0037 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 0.3527 - val_accuracy: 0.8216 - val_precision: 0.8235 - val_recall: 0.8144 - val_f1score: 0.8187\n",
      "Epoch 129/150\n",
      "20/20 [==============================] - 15s 731ms/step - loss: 8.3253e-04 - accuracy: 1.0000 - precision: 0.9981 - recall: 1.0000 - f1score: 0.9991 - val_loss: 0.3513 - val_accuracy: 0.8216 - val_precision: 0.8231 - val_recall: 0.8099 - val_f1score: 0.8163\n",
      "Epoch 130/150\n",
      "20/20 [==============================] - 15s 733ms/step - loss: 0.0014 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9981 - f1score: 0.9990 - val_loss: 0.3499 - val_accuracy: 0.8216 - val_precision: 0.8292 - val_recall: 0.8099 - val_f1score: 0.8192\n",
      "Epoch 131/150\n",
      "20/20 [==============================] - 15s 736ms/step - loss: 5.7629e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3485 - val_accuracy: 0.8216 - val_precision: 0.8292 - val_recall: 0.8099 - val_f1score: 0.8192\n",
      "Epoch 132/150\n",
      "20/20 [==============================] - 15s 732ms/step - loss: 5.2689e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3471 - val_accuracy: 0.8216 - val_precision: 0.8292 - val_recall: 0.8099 - val_f1score: 0.8192\n",
      "Epoch 133/150\n",
      "20/20 [==============================] - 15s 736ms/step - loss: 3.4113e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3458 - val_accuracy: 0.8216 - val_precision: 0.8327 - val_recall: 0.8099 - val_f1score: 0.8209\n",
      "Epoch 134/150\n",
      "20/20 [==============================] - 15s 735ms/step - loss: 5.7277e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3445 - val_accuracy: 0.8216 - val_precision: 0.8327 - val_recall: 0.8099 - val_f1score: 0.8209\n",
      "Epoch 135/150\n",
      "20/20 [==============================] - 15s 736ms/step - loss: 8.5453e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3433 - val_accuracy: 0.8216 - val_precision: 0.8364 - val_recall: 0.8099 - val_f1score: 0.8227\n",
      "Epoch 136/150\n",
      "20/20 [==============================] - 15s 738ms/step - loss: 4.7221e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3421 - val_accuracy: 0.8216 - val_precision: 0.8364 - val_recall: 0.8099 - val_f1score: 0.8227\n",
      "Epoch 137/150\n",
      "20/20 [==============================] - 15s 734ms/step - loss: 4.3164e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3409 - val_accuracy: 0.8216 - val_precision: 0.8314 - val_recall: 0.8010 - val_f1score: 0.8156\n",
      "Epoch 138/150\n",
      "20/20 [==============================] - 15s 734ms/step - loss: 8.5563e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3397 - val_accuracy: 0.8169 - val_precision: 0.8314 - val_recall: 0.8010 - val_f1score: 0.8156\n",
      "Epoch 139/150\n",
      "20/20 [==============================] - 15s 736ms/step - loss: 7.8906e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3386 - val_accuracy: 0.8169 - val_precision: 0.8314 - val_recall: 0.8010 - val_f1score: 0.8156\n",
      "Epoch 140/150\n",
      "20/20 [==============================] - 15s 739ms/step - loss: 0.0011 - accuracy: 0.9980 - precision: 1.0000 - recall: 0.9981 - f1score: 0.9990 - val_loss: 0.3375 - val_accuracy: 0.8169 - val_precision: 0.8314 - val_recall: 0.8010 - val_f1score: 0.8156\n",
      "Epoch 141/150\n",
      "20/20 [==============================] - 15s 744ms/step - loss: 8.1405e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3365 - val_accuracy: 0.8169 - val_precision: 0.8277 - val_recall: 0.8010 - val_f1score: 0.8138\n",
      "Epoch 142/150\n",
      "20/20 [==============================] - 15s 742ms/step - loss: 8.3898e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3354 - val_accuracy: 0.8216 - val_precision: 0.8272 - val_recall: 0.7966 - val_f1score: 0.8113\n",
      "Epoch 143/150\n",
      "20/20 [==============================] - 15s 770ms/step - loss: 5.0614e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3345 - val_accuracy: 0.8216 - val_precision: 0.8285 - val_recall: 0.8010 - val_f1score: 0.8143\n",
      "Epoch 144/150\n",
      "20/20 [==============================] - 15s 752ms/step - loss: 5.5895e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.8216 - val_precision: 0.8285 - val_recall: 0.8010 - val_f1score: 0.8143\n",
      "Epoch 145/150\n",
      "20/20 [==============================] - 15s 762ms/step - loss: 3.2770e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3324 - val_accuracy: 0.8216 - val_precision: 0.8285 - val_recall: 0.8010 - val_f1score: 0.8143\n",
      "Epoch 146/150\n",
      "20/20 [==============================] - 15s 749ms/step - loss: 0.0016 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 0.3314 - val_accuracy: 0.8216 - val_precision: 0.8285 - val_recall: 0.8010 - val_f1score: 0.8143\n",
      "Epoch 147/150\n",
      "20/20 [==============================] - 15s 742ms/step - loss: 4.9641e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3304 - val_accuracy: 0.8216 - val_precision: 0.8285 - val_recall: 0.8010 - val_f1score: 0.8143\n",
      "Epoch 148/150\n",
      "20/20 [==============================] - 15s 745ms/step - loss: 2.4007e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3294 - val_accuracy: 0.8216 - val_precision: 0.8285 - val_recall: 0.8010 - val_f1score: 0.8143\n",
      "Epoch 149/150\n",
      "20/20 [==============================] - 15s 742ms/step - loss: 0.0014 - accuracy: 0.9980 - precision: 1.0000 - recall: 0.9981 - f1score: 0.9990 - val_loss: 0.3287 - val_accuracy: 0.8216 - val_precision: 0.8285 - val_recall: 0.8010 - val_f1score: 0.8143\n",
      "Epoch 150/150\n",
      "20/20 [==============================] - 15s 747ms/step - loss: 5.9552e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.8216 - val_precision: 0.8285 - val_recall: 0.8010 - val_f1score: 0.8143\n"
     ]
    }
   ],
   "source": [
    "def recall(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
    "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
    "\n",
    "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n",
    "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
    "\n",
    "    # Precision = (True Positive) / (True Positive + False Positive)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1score(y_target, y_pred):\n",
    "    _recall = recall(y_target, y_pred)\n",
    "    _precision = precision(y_target, y_pred)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
    "    \n",
    "    # return a single tensor value\n",
    "    return _f1score\n",
    "\n",
    "\n",
    "\n",
    "#model = create_model()\n",
    "#model = ResNet()\n",
    "model = mobile_net()\n",
    "\n",
    "\n",
    "## learning rate scheduing\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,\n",
    "                                                          decay_steps=training_epochs*10,\n",
    "                                                          decay_rate=0.4,\n",
    "                                                          staircase=True)\n",
    "## optimizer는 Adam, loss는 sparse categorical crossentropy 사용\n",
    "## label이 ont-hot으로 encoding 안 된 경우에 sparse categorical corssentropy 및 sparse categorical accuracy 사용\n",
    "model.compile(keras.optimizers.Adam(lr_schedule), loss = 'binary_crossentropy', metrics=['accuracy', precision, recall, f1score])\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss='binary_crossentropy', \n",
    "#     metrics=['acc'],\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Train!\n",
    "history = model.fit(x_train, y_train, steps_per_epoch=training_epochs,\n",
    "         epochs=150, validation_data = (x_val,y_val))\n",
    "\n",
    "# epochs = 30\n",
    "# history = model.fit(\n",
    "#     training_set, \n",
    "#     epochs=epochs,\n",
    "#     steps_per_epoch=training_set.samples / epochs, \n",
    "#     validation_data=val_set,\n",
    "#     validation_steps=val_set.samples / epochs,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "index: 0  actual y: 1  answer y: 0  prediction: [0.72008985 0.21140423 0.04267049 0.00790787 0.0130344 ]\n",
      "index: 1  actual y: 2  answer y: 2  prediction: [1.8396166e-13 1.0925489e-13 1.0000000e+00 9.1514253e-14 1.7638892e-13]\n",
      "index: 2  actual y: 2  answer y: 2  prediction: [4.5380613e-13 3.6520795e-13 1.0000000e+00 2.7214542e-13 4.6183695e-13]\n",
      "index: 3  actual y: 2  answer y: 2  prediction: [1.1493396e-10 7.8839796e-11 1.0000000e+00 1.0207708e-10 1.4951294e-10]\n",
      "index: 4  actual y: 1  answer y: 1  prediction: [0.05147621 0.9102596  0.00316477 0.01586255 0.00324786]\n",
      "index: 5  actual y: 0  answer y: 0  prediction: [0.39709967 0.01050156 0.01619026 0.0548684  0.33835733]\n",
      "index: 6  actual y: 4  answer y: 4  prediction: [3.1112759e-07 1.0055430e-07 4.6422247e-07 1.0823626e-06 9.9999481e-01]\n",
      "index: 7  actual y: 0  answer y: 0  prediction: [9.8376864e-01 2.9578354e-05 8.8989718e-06 2.2520304e-02 1.6936660e-04]\n",
      "index: 8  actual y: 3  answer y: 4  prediction: [0.00273901 0.00720075 0.07261103 0.01528001 0.8440335 ]\n",
      "index: 9  actual y: 2  answer y: 2  prediction: [3.8180084e-12 1.9445916e-12 1.0000000e+00 3.9717973e-12 5.4933618e-12]\n",
      "index: 10  actual y: 2  answer y: 2  prediction: [0.08433941 0.35307002 0.5945281  0.07814273 0.06671652]\n",
      "index: 11  actual y: 1  answer y: 1  prediction: [3.3253283e-08 9.9999976e-01 7.4915135e-08 1.0189044e-08 4.7061214e-08]\n",
      "index: 12  actual y: 2  answer y: 2  prediction: [9.0309978e-04 1.9720197e-04 9.9876189e-01 1.4609098e-04 1.4463067e-04]\n",
      "index: 13  actual y: 3  answer y: 3  prediction: [1.4168590e-02 2.0024180e-04 1.3182163e-03 9.0275049e-01 5.2144825e-03]\n",
      "index: 14  actual y: 3  answer y: 3  prediction: [2.7248402e-06 2.5313750e-07 3.3637932e-07 9.9999666e-01 1.9412670e-07]\n",
      "index: 15  actual y: 0  answer y: 4  prediction: [0.18070576 0.01547164 0.01815781 0.01736334 0.7269211 ]\n",
      "index: 16  actual y: 4  answer y: 0  prediction: [9.9754775e-01 3.1870604e-04 9.1192589e-05 8.2561374e-04 9.4130635e-04]\n",
      "index: 17  actual y: 0  answer y: 0  prediction: [9.9999273e-01 5.4101071e-07 3.6047865e-08 6.6211783e-07 6.8553675e-07]\n",
      "index: 18  actual y: 3  answer y: 3  prediction: [1.9326240e-02 9.0133770e-05 6.5863831e-05 9.8933375e-01 1.6871095e-04]\n",
      "index: 19  actual y: 3  answer y: 3  prediction: [0.01150665 0.00092092 0.00137234 0.6230755  0.2938669 ]\n",
      "index: 20  actual y: 0  answer y: 0  prediction: [0.97632265 0.00234145 0.00099275 0.0114454  0.0084528 ]\n",
      "index: 21  actual y: 0  answer y: 0  prediction: [9.9997950e-01 3.9113584e-06 1.1614386e-07 1.1950547e-06 2.4114306e-06]\n",
      "index: 22  actual y: 1  answer y: 1  prediction: [1.2190738e-04 9.9970883e-01 7.4073323e-05 4.7537309e-05 3.1755011e-05]\n",
      "index: 23  actual y: 4  answer y: 4  prediction: [0.00365922 0.00109079 0.00137675 0.13965392 0.8993794 ]\n",
      "index: 24  actual y: 4  answer y: 4  prediction: [0.0107474  0.00357932 0.00152627 0.00161037 0.9839219 ]\n",
      "index: 25  actual y: 0  answer y: 0  prediction: [9.9994159e-01 2.6904918e-06 3.9958681e-07 6.4532860e-06 8.1645130e-06]\n",
      "index: 26  actual y: 1  answer y: 1  prediction: [1.7936826e-03 9.9402130e-01 1.1400878e-03 5.5319071e-04 1.8464625e-03]\n",
      "index: 27  actual y: 4  answer y: 4  prediction: [2.6130676e-04 4.8977359e-05 2.5152667e-05 4.1662071e-05 9.9940985e-01]\n",
      "index: 28  actual y: 0  answer y: 0  prediction: [9.9994791e-01 2.1552485e-06 2.1904739e-07 1.0065592e-05 6.8957820e-06]\n",
      "index: 29  actual y: 2  answer y: 2  prediction: [4.6136427e-07 3.6051873e-07 9.9999547e-01 3.1861424e-07 6.1196073e-07]\n",
      "index: 30  actual y: 2  answer y: 2  prediction: [6.544375e-13 5.291070e-13 1.000000e+00 4.919709e-13 8.454025e-13]\n",
      "index: 31  actual y: 3  answer y: 3  prediction: [1.4621019e-06 6.7319050e-08 3.9016381e-08 9.9999869e-01 9.6079617e-08]\n",
      "index: 32  actual y: 4  answer y: 4  prediction: [0.14538705 0.00740647 0.00494418 0.10921428 0.5425716 ]\n",
      "index: 33  actual y: 2  answer y: 2  prediction: [1.7197138e-08 1.4065589e-08 9.9999976e-01 1.5625771e-08 1.6456985e-08]\n",
      "index: 34  actual y: 1  answer y: 0  prediction: [0.45153075 0.38473427 0.00449577 0.00386205 0.03674373]\n",
      "index: 35  actual y: 1  answer y: 1  prediction: [4.3505430e-04 9.9899751e-01 1.9735098e-04 7.5895899e-05 1.3855100e-04]\n",
      "index: 36  actual y: 3  answer y: 3  prediction: [1.7929077e-04 5.2108990e-05 6.1598570e-05 9.9917626e-01 5.0985813e-04]\n",
      "index: 37  actual y: 2  answer y: 2  prediction: [1.9384481e-12 1.9533498e-12 1.0000000e+00 2.3920072e-12 3.1004982e-12]\n",
      "index: 38  actual y: 0  answer y: 0  prediction: [7.7458513e-01 1.4021993e-04 5.9620877e-05 3.3192968e-01 2.2536516e-04]\n",
      "index: 39  actual y: 4  answer y: 4  prediction: [1.1792724e-08 2.0041972e-08 1.0236164e-08 6.8965935e-09 9.9999988e-01]\n",
      "index: 40  actual y: 3  answer y: 3  prediction: [3.6328435e-03 3.8328767e-04 7.4914098e-04 9.8290002e-01 1.1968106e-02]\n",
      "index: 41  actual y: 0  answer y: 0  prediction: [9.7306442e-01 6.5095723e-03 8.4570050e-04 1.0643125e-02 5.8122575e-03]\n",
      "index: 42  actual y: 4  answer y: 4  prediction: [2.1522875e-07 2.4945814e-07 2.7902226e-07 1.9083873e-07 9.9999756e-01]\n",
      "index: 43  actual y: 2  answer y: 2  prediction: [1.02560294e-10 1.60531831e-11 1.00000000e+00 2.95062794e-11\n",
      " 2.26593085e-11]\n",
      "index: 44  actual y: 3  answer y: 3  prediction: [1.7583413e-06 1.6104278e-07 6.3966574e-08 9.9999839e-01 6.8688188e-08]\n",
      "index: 45  actual y: 3  answer y: 3  prediction: [1.9121170e-04 9.2167229e-06 1.5690923e-04 9.8952478e-01 5.6725740e-03]\n",
      "index: 46  actual y: 4  answer y: 4  prediction: [1.5400685e-05 2.1516453e-05 4.9390292e-06 4.3605114e-06 9.9992907e-01]\n",
      "index: 47  actual y: 1  answer y: 1  prediction: [9.579964e-06 9.999598e-01 9.282024e-06 6.676887e-06 5.918752e-06]\n",
      "index: 48  actual y: 4  answer y: 4  prediction: [2.8768182e-04 1.5416741e-04 7.6669455e-04 4.8014522e-04 9.9753457e-01]\n",
      "index: 49  actual y: 2  answer y: 2  prediction: [1.2505798e-07 3.4370881e-08 9.9999881e-01 8.8026468e-08 4.5873378e-08]\n",
      "index: 50  actual y: 4  answer y: 4  prediction: [2.2128224e-04 7.3068324e-05 6.4370011e-05 1.6328692e-04 9.9919766e-01]\n",
      "index: 51  actual y: 1  answer y: 1  prediction: [3.0186051e-05 9.9990141e-01 2.0540701e-05 1.2119268e-05 1.2240009e-05]\n",
      "index: 52  actual y: 0  answer y: 0  prediction: [9.9982125e-01 1.4930785e-05 1.6584762e-06 2.6471369e-05 5.6755543e-05]\n",
      "index: 53  actual y: 0  answer y: 0  prediction: [9.9971712e-01 1.4994127e-05 2.5424451e-06 2.6923361e-05 1.5231967e-04]\n",
      "index: 54  actual y: 1  answer y: 1  prediction: [2.2774600e-06 9.9999195e-01 1.4520551e-06 3.5314162e-07 6.1938044e-07]\n",
      "index: 55  actual y: 2  answer y: 2  prediction: [3.3739400e-12 1.2593866e-12 1.0000000e+00 8.1462533e-13 1.6677512e-12]\n",
      "index: 56  actual y: 2  answer y: 2  prediction: [2.9206831e-11 2.7330206e-11 1.0000000e+00 3.7196916e-11 4.2664046e-11]\n",
      "index: 57  actual y: 3  answer y: 3  prediction: [0.43040836 0.00412634 0.00233778 0.59708405 0.00706455]\n",
      "index: 58  actual y: 4  answer y: 4  prediction: [1.7568377e-06 4.6655833e-07 5.3200761e-06 7.6499437e-06 9.9995875e-01]\n",
      "index: 59  actual y: 4  answer y: 4  prediction: [4.7064516e-01 8.0632584e-05 1.1072389e-04 2.1326542e-04 6.1917579e-01]\n",
      "index: 60  actual y: 3  answer y: 3  prediction: [2.1480849e-01 9.1637114e-05 3.0071262e-05 8.8898683e-01 1.8492341e-04]\n",
      "index: 61  actual y: 0  answer y: 0  prediction: [0.8335347  0.07010722 0.00782081 0.03994796 0.02313748]\n",
      "index: 62  actual y: 0  answer y: 1  prediction: [5.5799484e-03 9.9401832e-01 6.6205859e-04 3.8427114e-04 2.9551983e-04]\n",
      "index: 63  actual y: 4  answer y: 4  prediction: [1.4168024e-04 6.8658432e-05 8.3330859e-05 9.5639851e-05 9.9949789e-01]\n",
      "index: 64  actual y: 3  answer y: 3  prediction: [1.2524262e-01 1.5608370e-03 3.2857060e-04 8.7098604e-01 8.8888407e-04]\n",
      "index: 65  actual y: 1  answer y: 1  prediction: [8.8659647e-07 9.9999571e-01 1.9403462e-06 2.5938007e-07 4.4921225e-07]\n",
      "index: 66  actual y: 4  answer y: 3  prediction: [1.6358793e-03 6.9269538e-04 7.1004033e-04 9.9352717e-01 4.6325028e-03]\n",
      "index: 67  actual y: 1  answer y: 1  prediction: [4.9114595e-05 9.9969256e-01 1.7939357e-05 2.9651205e-06 1.0156062e-04]\n",
      "index: 68  actual y: 2  answer y: 2  prediction: [9.3933172e-10 7.8016055e-10 1.0000000e+00 9.0359809e-10 2.2084878e-09]\n",
      "index: 69  actual y: 0  answer y: 0  prediction: [9.9858844e-01 6.2834282e-05 2.5184303e-05 2.9218197e-04 5.3510070e-04]\n",
      "index: 70  actual y: 1  answer y: 1  prediction: [3.2575915e-06 9.9998689e-01 5.0282742e-06 8.4467172e-07 1.0900062e-06]\n",
      "index: 71  actual y: 1  answer y: 1  prediction: [1.14344196e-07 9.99999166e-01 2.53708379e-07 4.15335961e-08\n",
      " 1.33585189e-07]\n",
      "index: 72  actual y: 3  answer y: 3  prediction: [6.7052031e-05 3.7382965e-06 1.5416063e-06 9.9996048e-01 2.1886501e-06]\n",
      "index: 73  actual y: 2  answer y: 2  prediction: [2.6388223e-12 1.3424754e-12 1.0000000e+00 1.0855804e-12 1.4956755e-12]\n",
      "index: 74  actual y: 1  answer y: 1  prediction: [4.9851224e-07 9.9999714e-01 8.8542453e-07 2.0005986e-07 4.0188365e-07]\n",
      "index: 75  actual y: 4  answer y: 4  prediction: [0.01017201 0.00116086 0.00655583 0.00148878 0.96867806]\n",
      "index: 76  actual y: 2  answer y: 2  prediction: [0.00652587 0.00255278 0.9827175  0.0053539  0.0028111 ]\n",
      "index: 77  actual y: 2  answer y: 2  prediction: [4.2964319e-07 4.1219909e-07 9.9999642e-01 2.1445857e-07 3.9456179e-07]\n",
      "index: 78  actual y: 3  answer y: 3  prediction: [9.3465447e-03 1.0063629e-04 4.8333688e-05 9.9270147e-01 4.7457218e-04]\n",
      "index: 79  actual y: 0  answer y: 0  prediction: [9.9636018e-01 1.0597110e-03 1.1720219e-04 8.3673000e-04 8.6435676e-04]\n",
      "index: 80  actual y: 1  answer y: 1  prediction: [5.4162741e-04 9.9222851e-01 7.4386597e-04 4.2140484e-04 7.1448088e-03]\n",
      "index: 81  actual y: 0  answer y: 3  prediction: [0.25439137 0.00211406 0.00183171 0.7983068  0.00239033]\n",
      "index: 82  actual y: 1  answer y: 1  prediction: [0.07564512 0.51198465 0.05102301 0.04398641 0.41396263]\n",
      "index: 83  actual y: 3  answer y: 3  prediction: [1.6999245e-04 5.8096002e-06 2.1827564e-05 9.9973118e-01 1.9001807e-05]\n",
      "index: 84  actual y: 4  answer y: 3  prediction: [4.6604872e-04 4.7678601e-05 2.0611286e-04 9.0850854e-01 1.2022570e-01]\n",
      "index: 85  actual y: 4  answer y: 4  prediction: [0.02710584 0.00539985 0.00820443 0.4094817  0.5264282 ]\n",
      "index: 86  actual y: 2  answer y: 2  prediction: [4.704066e-12 5.562220e-12 1.000000e+00 4.590322e-12 6.980141e-12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1531 - accuracy: 0.8966 - precision: 0.9028 - recall: 0.8836 - f1score: 0.8930\n",
      "loss: 0.153, accuracy: 0.897, precision: 0.903, recall: 0.884, f1score: 0.893\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3hUZdr48e+dkAYpQOg1qIgUESGiKCp2sLEiu4K6u7q6vCr+LGuvq+y667rY5dXX3lhZu6goKqKI1FAVkKJSAqEFSCC93L8/zpnJJEzCEHIySeb+XNdcmdPvOZmZe57nOed5RFUxxhgTuaLCHYAxxpjwskRgjDERzhKBMcZEOEsExhgT4SwRGGNMhLNEYIwxEc4SgYkIIpImIioizUJY9woRmV0fcRnTEFgiMA2OiKwXkWIRaVNl/lL3yzwtPJEZ0zRZIjAN1a/AWN+EiBwNJIQvnIYhlBKNMQfLEoFpqN4A/hAw/Ufg9cAVRCRFRF4XkR0iskFE7hWRKHdZtIhMFJGdIvILcF6QbV8SkSwR2SwifxeR6FACE5F3RGSriOSIyCwR6RuwLEFEHnXjyRGR2SKS4C4bKiJzRGSPiGwSkSvc+d+IyNUB+6hUNeWWgsaLyFpgrTvvSXcfuSKySERODlg/WkTuFpGfRWSvu7yriEwSkUervJaPReSmUF63abosEZiGah6QLCK93S/oS4A3q6zzNJACHAacipM4rnSX/Rk4HzgWSAdGV9n2NaAUOMJd52zgakLzGdATaAcsBiYHLJsIDAJOBFoDtwPlItLN3e5poC0wAFga4vEAfgMcD/Rxpxe6+2gN/Ad4R0Ti3WV/wSlNnQskA38C8t3XPDYgWbYBzgDeOog4TFOkqvawR4N6AOuBM4F7gX8Cw4EvgWaAAmlANFAE9AnY7n+Ab9znXwPXBCw72922GdDe3TYhYPlYYKb7/ApgdoixtnT3m4Lzw6oAOCbIencBH1Szj2+AqwOmKx3f3f/pB4hjt++4wGpgZDXrrQLOcp9fD0wL9//bHuF/WH2jacjeAGYBPahSLQS0AWKBDQHzNgCd3eedgE1Vlvl0B2KALBHxzYuqsn5QbunkIeC3OL/sywPiiQPigZ+DbNq1mvmhqhSbiNyCU4LphJMokt0YDnSs14DLcRLr5cCThxCTaSKsasg0WKq6AafR+Fzg/SqLdwIlOF/qPt2Aze7zLJwvxMBlPptwSgRtVLWl+0hW1b4c2KXASJwSSwpO6QRA3JgKgcODbLepmvkAeUDzgOkOQdbxdxPstgfcAfwOaKWqLYEcN4YDHetNYKSIHAP0Bj6sZj0TQSwRmIbuKpxqkbzAmapaBrwNPCQiSSLSHadu3NeO8DZwg4h0EZFWwJ0B22YBXwCPikiyiESJyOEicmoI8SThJJFsnC/vfwTstxx4GXhMRDq5jbZDRCQOpx3hTBH5nYg0E5FUERngbroUGCUizUXkCPc1HyiGUmAH0ExE7scpEfi8CPxNRHqKo7+IpLoxZuK0L7wBvKeqBSG8ZtPEWSIwDZqq/qyqGdUs/n84v6Z/AWbjNJq+7C57AZgOLMNp0K1aovgDTtXSSpz69XeBjiGE9DpONdNmd9t5VZbfCvyA82W7C/gXEKWqG3FKNre485cCx7jbPA4UA9twqm4mU7PpOA3Pa9xYCqlcdfQYTiL8AsgFXqLypbevAUfjJANjEFUbmMaYSCIip+CUnNLcUoyJcFYiMCaCiEgMcCPwoiUB42OJwJgIISK9gT04VWBPhDkc04BY1ZAxxkQ4KxEYY0yEa3Q3lLVp00bT0tLCHYYxxjQqixYt2qmqbYMta3SJIC0tjYyM6q4mNMYYE4yIbKhumVUNGWNMhLNEYIwxEc4SgTHGRDhLBMYYE+EsERhjTITzLBGIyMsisl1EfqxmuYjIUyKyTkSWi8hAr2IxxhhTPS9LBK/ijCxVnRE4w/31BMYBz3oYizHGmGp4dh+Bqs4SkbQaVhkJvK5OHxfzRKSliHR0+4pvUsrK4IcfYO5cOPpoGDq07o+RnQ1z5sCaNXDRRXDYYbBpE/znP5CXB3FxcNVV0MEd8qS0FEpKqt9feTmsWuXsc+fO4Ou0awcnngjNm8P338OGaq9SPjjNmsGAAc5j1SpYuhSOOALS0+Hnn2HBAsjPr7xNz54wZIgT69y5sHv3ocWQkgInnAAdO8K8ebB6NQT2xhIfD8cdB716wZIlsGyZc06rio6G/v1h0CBYuxYWLtw/9up07w4nnQQFBc7/Ydu2Q3tNoQo8/z/9BBkZUFhYu32lp8P55zufgffeg5UrKy9v08Z5D/XuDVFRsGWL815at67m/VZ3/mNinLiPOcZ572RkQFFRxXYi0KcPHH+88/mYNw/27q3da6tOSorzXuzQIfh7p6rYWOf90bev8z2xeLHz2az63vn+e7jwQuf11bVw3lDWmcp9qGe68/ZLBCIyDqfUQLdu3aoubhAKC+HYYyEpCW6/3fmyLy2F//4XHn8cNrvjZkVFwUsvwRVXhLZfVZg+3XlDDRrkHCMmBvbscb4cvv/eefz0U8U2vuPPmePEIOLs56WX4MsvnfVvvNHZRygqRnOsHFeo6x6sULq/CjxOsPUPNY4D7TPUY9Y2Ni/Pb22OXZvj+vZz1FFO8tu4cf991fS/rumY1cVYV/+3Q3Gwxwj1tYg4P76aWiIIdmqCvi1U9XngeYD09PQG2Uveq686X8adO8Nvf1t52WmnwcMPO7+ObrgBrrzS+cVz663QsmX1+/ziC7jtNli+vPp1WrVyflH94Q/Or8cuXeC55+CDD+C66+Avf3F+WS5cCCNGQL9+TtIaOtT5pVaTtLSKfQazcaOTVAoKnBh69aqbD1VBgfNLbtky50vk2GOdX0SLFjklnSFDKp+3sjJYscJJlqmpTiwdQxlipgbbtzuJdOtW59fj0Uc7v5R9cnOd461d63wwBw1yfqVWVVTk/MJbvBgOP9wpZdT0P/dRdX5Jzpnj7HfoUKiv30BVz//xxzs/cA5WaSm8+y48+aTz63jSJDj3XOfHkE9mpvMeWr/emW7Vyvn/9u1beb2qAs//Mcc4n634eCf2hQudz0zv3k7siYkV25WUOK9r4ULnfT1kiFMqqUvbtlWU4IK9d6rKy4P5853SUr9+MHiwU8ouKnLe80uWOCXiE05wShte8LT3Ubdq6BNV7Rdk2f8B36jqW+70amDYgaqG0tPTtaF1MVFSAkceCe3bO2/qadOcNzg4xdf09Ip1i4rg6qvhzTedN+gdd8A991T+As3Pd37VT5rkVHncfbdT3bNsmfNmUYWEBOcNc9RRNX9gAq1aBX/6k7OvW25xip7GmMggIotUNT3oQlX17IEzsPeP1Sw7D2e4PQFOABaEss9BgwZpQ/Paa6qgOnVq6NssWaI6apSz3VVXqZaUOPN37FA97jhn/s03qxYUeBOzMSayABlazfeqZyUCEXkLGAa0wRmL9a9AjJt8nhMRAZ7BubIoH7hSqx+b1q+hlQhUnWJsTIzTqHkwVSOq8Ne/wt/+5hRRzz3Xadz95RenbWHkSO/iNsZElppKBF5eNTT2AMsVGO/V8evLsmVOlcvzzx98/bgITJjgtCs8/TTcd59TFzt9Opx6qjfxGmNMVY2uG+qG5qOPnC/0Cy+s/T7+53+cx65dTqNScnLdxWeMMQdiieAQffSRU63Tvv2h76t160PfhzHGHCzra+gQbNjgXNpldfnGmMbMEsEhmDrV+WuJwBjTmFkiOAQffeTcRNWrV7gjMcaY2rNEUEt798K331ppwBjT+FkiqKW5c51b6M84I9yRGGPMobFEUEuzZjldNAwZEu5IjDHm0FgiqKXvvqvobdQYYxozSwS1UFTk9BZ4yinhjsQYYw6dJYJqFBY6PYQGDmrhs3ChM//kk+s/LmOMqWuWCIIoL3fGDPj9752+/auaNcv568VIY8YYU98sEQRx770wZQq0aOGUCnz27HEGQfnuO2e4u7oe0MIYY8LB+hqqYvFi+Oc/4c9/dgZ9ueUWZ+SxggJnhCDfKEhXXRXuSI0xpm5YIqjCN9TB3Xc7A77fdhu8/jp89ZUzxOCoUU7X05dfHt44jTGmrniaCERkOPAkEA28qKoPV1neHXgZaAvsAi5X1UwvYzqQVauc8UK7dXOGgDzzTPj3v52bxyZPhksvDWd0xhhT9zxrIxCRaGASMALoA4wVkT5VVpsIvK6q/YEJwD+9iidUq1Y5fQf5xgG+/PKKO4jH1jjUjjHGNE5eNhYPBtap6i+qWgxMAar2zNMHmOE+nxlkeb1btQp6966YHj0arr8eXnjh4EcgM8aYxsDLRNAZ2BQwnenOC7QMuNh9fhGQJCKpVXckIuNEJENEMnbs2OFJsAD79sHGjZUTQUKCM4xkjx6eHdYYY8LKy0QQ7PezVpm+FThVRJYApwKbgdL9NlJ9XlXTVTW9bdu2dR+pa/Vq529gIjDGmKbOy8biTKBrwHQXYEvgCqq6BRgFICKJwMWqmuNhTDVatcr5a4nAGBNJvCwRLAR6ikgPEYkFxgBTA1cQkTYi4ovhLpwriMJm1SqnR9EjjghnFMYYU788SwSqWgpcD0wHVgFvq+oKEZkgIhe6qw0DVovIGqA98JBX8YRi1SonCcTGhjMKY4ypX57eR6Cq04BpVebdH/D8XeBdL2M4GFWvGDLGmEhgfQ25Skpg3TpLBMaYyGOJwLVunXPjmCUCY0yksUSA09Hc6NHODWPHHRfuaIwxpn5FfCJYsACOP97pYvrzz50eR40xJpJEfO+j//2v06/QsmU2voAxJjJFfIngyy+dkcYsCRhjIlVEJ4KtW+GHH+Css8IdiTHGhE9EJ4KvvnL+nn12eOMwxphwiuhE8OWXTpXQgAHhjsQYY8InYhOBqpMIzjijYhAaY4yJRBH7FbhyJWRlWfuAMcZE7OWjCxY4f085JbxxGGMOTdbeLN768S2KSosOuG50VDQXHXURPVN71kNkjUfEJoLdu52/Ho5zY4w5CNn52Xz969fofuNXVe/H7T/y2NzHyCvJC3mbe76+h2vTr2Vot6G1CXM/R7Q+goEdB9a4zu6C3Xz969eUadkhHWtQx0Ec3vrwQ9pHMBGbCHLc4W+SksIbhzEGduTtYOgrQ1mTveagtx3dZzQPnf4Q3VO6H3Ddnfk7mfDtBCYtnMTTC56uTajVxnDj8TeS0Cxhv2XfbfyOCd9OYHfh7kM+zrPnPWuJoC7l5DhJIDo63JEYE5lUlZyiHIpKi7hwyoVszNnI1DFTD+qLLjE2kW4p3UJev3NyZ/7vgv/jwdMeZFfBrtqEXYmq8t6q93jk+0d4d2X1PeqfffjZ3HvyvaQ2329I9oPSIbHDIW1fHU8TgYgMB54EooEXVfXhKsu7Aa8BLd117nTHMPBcTg6kpNTHkYwxgVSVT9Z8wu1f3c5PO38CIEqieP9373NBrwvqJYYOiR3q7Eu1b7u+/M+g/2HB5gVBl7dPbM/gzoPr5Fhe8SwRiEg0MAk4C2f84oUiMlVVVwasdi/OyGXPikgfnEFs0ryKKVBuriUCYwIVlBTw5PwneWbBM+SX5Pvnx0TH8If+f+Cuk+9i6uqp/OO7f7Azf2etj1Ou5eQU5XBk6pH868x/ERsdy8COAzmle+O9cqN9Yvt6S2Je8LJEMBhYp6q/AIjIFGAkEJgIFEh2n6dQZXB7L1mJwDQ2m3M38+C3D7Jk65KQ1u+U1In7T7mfQZ0G1bheuZbznx/+w90z7mZT7iaGHzGcnq0rrqrJ2pfFo3Mf5fF5j1OmZQzuPJjhRww/pNfSr10/rhxwJTHRMYe0H1M3vEwEnYFNAdOZwPFV1nkA+EJE/h/QAjjTw3gqycmxK4ZMw5C1N4uJcyayee/matcpLS9l2tpplGkZp6WdRnTUgRu35myaQ/oL6Zxz+Dm0jG9Z7Xo/7fyJZduWMajjIF6/6HWGpQ3bb52lW5fyXMZzDEsbxiV9L0FEQnptpnHwMhEEe6dUvS5sLPCqqj4qIkOAN0Skn6qWV9qRyDhgHEC3bqE3DNUkJ8cZqN6Yupa1N4v3V73PeUeeR1rLNP/8PYV7eHHxi+wuqLh6JKcoh1eXvkpxWTGHtTqsxv2O6j2Kv532N3q06hFSHDmFOTw8+2E+Wv0R6/esr3a9xNhE3rjoDS49+lKiJPg9pgM6DOC5858L6bim8RHV0K/ZPagdO1/sD6jqOe70XQCq+s+AdVYAw1V1kzv9C3CCqm6vbr/p6emakZFxyPG1bw8XXQTP2XvbuDJzM1m3ax2ndj+10i/eLXu38MXPX1Cu5bROaM35R55Ps6iK31C5Rbl8vPpjisqK+HnXzzwx/wnyS/KJjY5l/HHj6deuH1v3beWxuY+RXZBdadsoieKCIy/g4TMf5ojW9svEeEdEFqlqerBlXpYIFgI9RaQHsBkYA1xaZZ2NwBnAqyLSG4gHdngYk5+1EZhAW/Zu4aSXT2JjzkaGpQ3j1iG30iK2BTN/ncnEuRMrNZ72bduX+065j/aJ7flx+49M+HYCO/Ir3ra/7fNbbjz+Rl5c8iJPzHvCf4PU6T1OZ+JZEzm247H1/vqMqYlniUBVS0XkemA6zqWhL6vqChGZAGSo6lTgFuAFEbkZp9roCvWqiBKgqMh5WCIw4FTZDH9zOLsKdvHXU//KpIWTOP+t8/3LL+l7CXeffDct41uyYPMC7ppxF2PeG+Nffkr3U3j/9PfpltKN+GbxtGvRDoCTup3ExLMmkleSR7OoZnRM7Gh166ZB8qxqyCt1UTW0fbtTNfTMMzB+fB0FZhod381Ad3x1B5tyNvHppZ9y1uFnkVuUy5KsJShKh8QOHNWm8kDWxWXFLNi8gNLyUpJikxjYcaB9wZsGL1xVQw2Wr3uJ5OSa1zNNR2FpIaPfHs0XP3/hn6copeWl9GvXj+mXT+e0HqcBkByXzKlpp1a7r9jo2Drrp8aYhiCiE4FVDUWGsvIyfv/B7/l07adcl34dKfEV//ij2hzFZUdfFtLlmMY0VZYITJO2M38nN0+/mXdXvsvj5zzOTSfcFO6QjGlwLBGYJmFf8T6ey3iOTTkV9zAWlRUx5ccp7C3eywOnPmBJwJhqWCIwjdaHP33Ihj0b2Fu8l2cWPMO2vG2kxKVUarg9pfspPHzmw/Rp2yeMkRrTsFkiMI3Ssq3LuOi/F/mnT+x6Ih+O+ZATupwQxqiMaZwiOhHYVUON12PzHqNFTAtWjl9JclzyfiUBY0zoIjYRtGgBzSLy1Td+W/Zu4a0f3uLa9GsPalASY0xwwXuYauKse4nG7en5T1OmZdb4a0wdsURgGpVNOZt4btFzjOo9KuReOI0xNbNEYBqNXQW7GD55OOVazoRhE8IdjjFNRkTWkufkQOvW4Y7CHIySshJGThnJul3rmH75dHq37R3ukIxpMqxEYBqFJ+c/yeyNs3ll5CtBR9AyxtReRCYCG7i+cdmcu5kHvnmA8488n0uPrjqkhTHmUEVkIsjJsXsIGpNbv7yV0vJSnhz+ZLhDMaZJirhEUFICBQVWImgMVmxfwbmTz2XKj1O4c+idBxzT1xhTO542FovIcOBJnBHKXlTVh6ssfxw4zZ1sDrRT1ZZexmTdSzQOH/30ERe/fTGJsYk8cuYj3Dzk5nCHZEyT5VkiEJFoYBJwFpAJLBSRqaq60reOqt4csP7/AzwfzNUSQcP3/cbvGfPeGAZ1GsSnl35Km+Ztwh2SMU2al1VDg4F1qvqLqhYDU4CRNaw/FnjLw3gASwQNWbmW89YPb3HBWxfQLaWbJQFj6omXiaAzsClgOtOdtx8R6Q70AL6uZvk4EckQkYwdO3YcUlCWCBqmjTkbGfLSEC59/1K6t+zO55d9bknAmHriZSII1hWkVrPuGOBdVS0LtlBVn1fVdFVNb9u27SEFZYmg4cnOz+acN89h9c7VvDryVRaNW2TdRxhTj7xsLM4EugZMdwG2VLPuGGC8h7H4WSJoGHbm7+STNZ9QWl7KS0te4tfdv/LF77/glO6nhDs0YyKOl4lgIdBTRHoAm3G+7Pe7G0hEegGtgLkexuKXm+v8tfsI6ldBSQELNi+gXMvJ2JLBQ989RE6Rk5VjomKYMnqKJQFjwsSzRKCqpSJyPTAd5/LRl1V1hYhMADJUdaq76lhgiqpWV21Up/LynL8tWtTH0SJPuZZTruU0i2rmn568fDJ3f303mbmZ/vVGHDGCCadNoENiBxJjE2kZ7+lVw8aYGnh6H4GqTgOmVZl3f5XpB7yMoar8fOdvQkJ9HrXpU1U+Xfspt315G5tyNnHHSXcwuPNg7ppxF0u2LiG9UzpPDX+K1gmtaZXQiv7t+4c7ZGOM64CJwP1VP1lVd9dDPJ7Ly4PmzcFGNaxbt315G4/OfZReqb0487Azuf8bJ993S+nG5FGTGdNvDFEScTeyG9MohFIi6IBzM9hi4GVgen1V43ghL8+qheraoi2LeGzuY1x17FU8e96zxETHMGfTHNZkr2FMvzHEN4sPd4jGmBoc8Ceaqt4L9AReAq4A1orIP0TkcI9j80R+viWCulSu5YyfNp52Ldrx6NmPEhMdA8CJXU/kigFXWBIwphEIqazulgC2uo9SnKt83hWRRzyMzRO+qiFz6Mq1nEe+f4T5m+fzyFmPkBJv1+Qa0xiF0kZwA/BHYCfwInCbqpaISBSwFrjd2xDrlpUI6sbCzQu59tNrWZS1iOFHDOf3/X8f7pCMMbUUShtBG2CUqm4InKmq5SJyvjdhecfaCGq2eudqWie0pm2L6u/gXpK1hNNfP52W8S1546I3uPToSxFrfTem0QolEUwDdvkmRCQJ6KOq81V1lWeReSQvDzp0CHcUDc+6Xeu446s7eH/V+yTGJnLHSXfwlyF/oXmMU4+WU5hDZm4mewr3cPHbF9MqvhVzr5pL5+Sg3UcZYxqRUBLBs8DAgOm8IPMaDasa2l/W3izSn0+ntLyU+065jxU7VnDfzPt4LuM5/nba39iet51/zP4HuUXObdmtE1oz848zLQkY00SEkggk8HJRt0rI0xvRvGRVQ/u7/avbKSgtYNk1yziqzVEAfLfhO2754hb+NPVPAFxw5AVcdvRlREkUgzsPpnvL7uEM2RhTh0L5Qv/FbTB+1p2+DvjFu5C8ZVcNVTZrwyzeXP4m9558rz8JAJzc/WTmXT2Pz9Z+Rkp8CkO7DQ1jlMYYL4WSCK4BngLuxelGegYwzsugvGRVQxWWbl3KuI/H0T2lO3edfNd+y6MkivOOPC8MkRlj6tMBE4GqbsfpObTRKyuDwkJLBJtzN3PvzHt5belrtEpoxduj3/Y3ChtjIk8o9xHEA1cBfQH/baKq+icP4/KEr8O5SK0aKtdy/vbt3/jX9/+iTMu49cRbufvku63nT2MiXCh3Fr+B09/QOcC3OAPM7PUyKK/4EkEklghUlZs/v5kHvn2AC3pdwE/jf+KRsx6xJGCMCSkRHKGq9wF5qvoacB5wtLdhecM3FkEklgj+PeffPLXgKW4+4WamXDzFhoI0xviFkghK3L97RKQfkAKkhbJzERkuIqtFZJ2I3FnNOr8TkZUiskJE/hNS1LUUqYPSrNi+gju+uoNL+l7CxLMn2l3AxphKQrlq6HkRaYVz1dBUIBG470AbiUg0MAk4C2f84oUiMlVVVwas0xO4CzhJVXeLSLtavIaQRWrV0BvL3yBaonlqxFM2JoAxZj81JgK3Y7lcd1CaWcBhB7HvwcA6Vf3F3dcUYCSwMmCdPwOTfIPeuFcoeSYSq4bKtZzJP0zmnCPOoV0LT/OsMaaRqvHnoaqWA9fXct+dgU0B05nuvEBHAkeKyPciMk9EhgfbkYiME5EMEcnYsWNHLcOJzBLBrA2zyMzN5PKjLw93KMaYBiqUeoIvReRWEekqIq19jxC2C1YRXXVks2Y4g94MwxnE/kUR2e8yFlV9XlXTVTW9bdvqe8U8kEhsI3hz+ZskxiYy8qiR4Q7FGNNAhdJG4LtfYHzAPOXA1USZQNeA6S7AliDrzFPVEuBXEVmNkxgWhhDXQYu0qqHC0kLeWfkOo3qPshvGjDHVCuXO4tpeZ7gQ6CkiPYDNOHcnX1plnQ9xSgKvikgbnKoiz/oxirSqoU/WfEJuUa5VCxljahTKncV/CDZfVV+vaTtVLRWR64HpQDTwsqquEJEJQIaqTnWXnS0iK4EynNHPsg/2RYQq0qqG3lz+Jh0TO3J6j9PDHYoxpgELpWrouIDn8cAZwGKgxkQAoKrTcAa2CZx3f8BzBf7iPjznSwTxETCeenZ+NtPWTuOG428gOio63OEYYxqwUKqG/l/gtIik4HQ70ejk5zvtA1ERcCn9OyvfoaS8hMv7W7WQMaZmtRlgJh+nQbfRaeqD0szdNJeL376Yy/tfzjfrv6Fv274c0/6YcIdljGngQmkj+JiKyz6jgD7A214G5ZWmPChNaXkp13x6DfuK9zFxzkQU5Z9n/NO6kzDGHFAoJYKJAc9LgQ2qmulRPJ5qyoPS/O/C/2X5tuW897v36NGyB5N/mMy4QY12/CBjTD0KJRFsBLJUtRBARBJEJE1V13samQeaaolg275t3DfzPs45/BwuOuoiRIRjOx4b7rCMMY1EKM2m7wDlAdNl7rxGp6mWCG7/6nYKSgp4asRTVhVkjDlooSSCZqpa7Jtwn8d6F5J3mmJj8eyNs3l92evcduJtHJl6ZLjDMcY0QqEkgh0icqFvQkRGAju9C8k7Ta1qqLS8lPHTxtM1uSt3n3x3uMMxxjRSobQRXANMFpFn3OlMIOjdxg1dU6saemfFOyzftpx3fvsOLWKb0AszxtSrUG4o+xk4QUQSAVHVRjleMTS9qqEPV39Ih8QOjOo9KtyhGGMasQNWDYnIP0SkparuU9W9ItJKRP5eH8HVtaZUNVRcVszn6z7nvJ7n2ahjxphDEso3yAhV3eObcEcTO9e7kLxRXg6FhU2nRPDdhu/ILcrlgiMvCHcoxphGLpREEC0icb4JEUkA4mpYv0Fqal1Qf7LmE+Ki4zjzsDPDHYoxppELpbH4TWCGiLziTl8JvOZdSN5oSoPSqCofr/mY03ucbo3ExphDdsASgao+Avwd6I3TzycqvG0AAB1+SURBVNDnQHeP46pzTalEsDp7NT/v/tmqhYwxdSLUVsatOHcXX4wzHsGqUDYSkeEislpE1onInUGWXyEiO0Rkqfu4OuTID1LVQWlUlS17q46c2Th8vPpjAM4/8vwwR2KMaQqqTQQicqSI3C8iq4BngE04l4+epqrPVLddwPbRwCRgBE5JYqyI9Amy6n9VdYD7eLF2L+PAfCUCX9XQx2s+Ju2JNLbt2+bVIT3z8ZqPGdBhAF1Tuh54ZWOMOYCaSgQ/4fz6v0BVh6rq0zj9DIVqMLBOVX9xu6WYAoysfaiHpmqJYFPOJkrKS9i6b2u4QqqVXQW7+H7T95zf00oDxpi6UVMiuBinSmimiLwgImcAB9OjWWecUoRPpjtvv+OIyHIReVdEgv7EFZFxIpIhIhk7duw4iBAqVG0s3le8D4Dcotxa7S9cPlv7GeVazgW9rH3AGFM3qk0EqvqBql4CHAV8A9wMtBeRZ0Xk7BD2HSxpaJXpj4E0Ve0PfEU1VyOp6vOqmq6q6W3btg3h0Pur2ljsSwR7ixv2jdJ5xXlM+HYCF/33InYX7ObjNR/TvkV70julhzs0Y0wTEUoXE3nAZJz+hloDvwXuBL44wKaZQOAv/C5ApdZZVc0OmHwB+FcIMddK1aqhxlAiWLh5Ib/572/YsncL0RLNyCkjWb5tORf3vtjuJjbG1JmD+jZR1V2q+n+qenoIqy8EeopIDxGJBcYAUwNXEJGOAZMXEuLVSLWxdM83cM5fiIt3mjkaQyJ4asFTFJQUMPvK2UweNZnZG2eTU5Rj1ULGmDpVm8HrQ6KqpSJyPTAdiAZeVtUVIjIByFDVqcANbhfXpcAu4Aqv4vk5fzEMeRyN/SuQQl6JU0RoyIlg7qa5DEsbxkndTgJgd+FuXl36KmcddlaYIzPGNCWeJQIAVZ0GTKsy7/6A53cBd3kZg88pJyTx6WwokVwgpcGXCLbnbefn3T9zTfo1/nnXpF9TadoYY+pCxFQ0d2+fDEBeqdM4fDCJoKi0yLvAqjF301wAhnQZUu/HNsZElohJBElxSUDFF3+oiWDbvm2kPJzCrA2zvA2wijmb5hATFcOgToPq9bjGmMgTMYkgOc4pEewtOrgSwZa9WygqK+LX3b96G2AVczPnMrDjQOKbxdfrcY0xkSdiEkFSbOUSQaiNxYWlhQAUldVf9VBxWTELtyzkxK4n1tsxjTGRK2ISga9EcLBVQwWlBUBFQqgPy7Yuo7C00NoHjDH1IuISge9O4pATQYmTCOqzwXjOpjkADOlqicAY472ISQSBjcXFZcUUlxX7p2viKwnUV4lAVZn8w2R6pfaiS3KXejmmMSayRUwiiI2OJS46jr1Fe8krdtoHoiQq5Kqh+mojmL1xNgu3LOTG42+sl+MZY0zEJAJwSgW5Rbn+huIOiR3YV7yPci2vdhtf1VB9lQgenfsoqQmp/HHAH+vleMYYE1GJIDkumb3Fe/3tAx0TO6Kov4QQjP+qoXpoI1ibvZapq6dybfq1NI9pAoMrG2MahYhKBEmxTonAlwg6JXUCam4nqK+rhmZtmMXv3v0dMdExjB883tNjGWNMoIhKBFVLBCElghLv2wienv80p756KjvzdzLl4il0SOzg2bGMMaYqTzuda2iS4pLYum9rgysRfLPhG3q07MGP1/1oVULGmHoXeSWCgKuGQkkE9XH5aF5xHm1btLUkYIwJi4hKBFXbCDomOuPihLtqKK8kjxYxLTzbvzHG1MTTRCAiw0VktYisE5E7a1hvtIioiHg6EG+t2gjqoWoovyTfSgPGmLDxLBGISDQwCRgB9AHGikifIOslATcA872KxScpNon8knxyinIA6JhUuUSwKWfTftvUx+WjecV5tIi1EoExJjy8LBEMBtap6i+qWgxMAUYGWe9vwCOA53ds+fob2rpvKzFRMaQmpAJOIvhm/Td0e6Ibq3ZUHja5PkoEVjVkjAknLxNBZyDwJ3amO89PRI4FuqrqJzXtSETGiUiGiGTs2LGj1gH5EsGWvVtIjE0kJjqGhGYJ5BblsmDzAgB+3VN53IH6aCPIL8m3RGCMCRsvE4EEmaf+hSJRwOPALQfakao+r6rpqpretm3bWgfk63gua1+WvyomOS6Z3KJcVu10SgLZ+dmVtqmvq4asjcAYEy5e3keQCXQNmO4CbAmYTgL6Ad+ICEAHYKqIXKiqGV4EVLVE4JuXW5zLL7t/ASC7oHIi8Hc651EbQVl5GUVlRdZGYIwJGy9LBAuBniLSQ0RigTHAVN9CVc1R1TaqmqaqacA8wLMkABWjlG3dt7VyIijKZeWOlcD+JQKvO53zdYBnVUPGmHDxLBGoailwPTAdWAW8raorRGSCiFzo1XFr4isRlJaXVkoEK3es9F9SujN/Z6VtvB6qMr8kH8CqhowxYeNpFxOqOg2YVmXe/dWsO8zLWKCijQColAjW71nvn19d1ZBnJQL3LmerGjLGhEtE3VnsKxFARVVM4LyerXvunwjcqqFyLae0vPSQjp+1N4vtedsrzbOqIWNMuEVUIvC1EUDlEgFAm+Zt6N22d9CrhqIl2v8cnOSgqhyMtdlr6f9cf/788Z8rzbeqIWNMuEVUIoiJjiG+WTywfyLo07YPqQmplUoE5VpOUVkRKfEpgJMI8kvy6fhoR95d+W7Ix926byvnvHkOO/N3krU3q9IyqxoyxoRbRCUCqCgV7JcI2jiJILCx2FcCaBnfEnAuId2Zv5OcohzWZK8J+ZhXTb2KbXnbOLrd0f7uLXysasgYE24Rlwh8X/xBSwTNU/2/+qEiEbSKb+Wf9v2Cr/qFXpPFWYsZ228sJ3Q5Yb8O7nzHshKBMSZcIi4R+K4cqtpY7Ksagop7CXwNxf4SQVmR/zLTnMLQEkFJWQnb9m2jS3IXUuJS9tvOl1isjcAYEy4RlwiqlgiGpQ3jsqMv44QuJ5Da3E0EbjuB79JRXyIoLC30J4Lc4uq7rg6UtS8LRemc1JnkuGQKSgsoKSvxL7eqIWNMuEV8IuiS3IU3R71Ji9gWtGneBti/ROCrGioqPfgSwebczQB0Tu7sb3QOrFayxmJjTLhFXCKo2lgcyF815JYIqjYWB5YIQm0j2LzXTQRJnUmJcxNBQBLJL8lHEOKi4w76tRhjTF2IuERQtUQQyFc15LtyqGrVUFFZkb8qp85KBCXOoDRux3vGGFPvIi4R+EoEwapiWie0BqpvLK5tiSAuOo7UhFR/iSDwyqG8YhuUxhgTXhGXCGoqEcRGx5IUm1Rt1VCt2gj2bqZTUidEpKJEEFg1VGrjFRtjwiviEoHvyzhYIgCnq4lQrhraW7yXsvKyAx5vc+5mOic7A7P5klDVxmJrKDbGhJOnvY82RJf0vYRoiaZjYsegy1Obp+5/1VBCxQ1lvkQAsK94nz+xVGfz3s0M6jgIIGhjsY1XbIwJt4grEbRPbM/4weOrbZwN7GZiv6qhgMZiOHA7gao6JYIkp0QQrLE4v8Sqhowx4eVpIhCR4SKyWkTWicidQZZfIyI/iMhSEZktIn28jCcUqc1TQ6oaggO3E+wp3ENBaYG/aig2Opb4ZvGVSwRWNWSMCTPPEoGIRAOTgBFAH2BskC/6/6jq0ao6AHgEeMyreEKVmhCkaijIDWVw4BJB4D0EPilxKZWvGrKqIWNMmHlZIhgMrFPVX1S1GJgCjAxcQVUD+2loARxcJ/8eaNO8DTlFOZSWl1JYWkiURBHfLJ5oifaXCHxf3AcqEfjuIeiS3MU/LyU+Zf/GYksExpgw8jIRdAY2BUxnuvMqEZHxIvIzTongBg/jCYnv7uJdBbsoKC0gvlk8IkJcszh/p3O+qp7qSgTFZcWUa3lFiSC54mUnxyVbG4ExpkHx8qqhYK2x+/3iV9VJwCQRuRS4F/jjfjsSGQeMA+jWrVsdh1lZ4N3FBSUFJDRLACC+Wby/G+ouyV1Yk70maImguKyYvv/bl1O7n0r3lO4AdErq5F9etQdS353FxkSikpISMjMzKSz0ZkzwSBQfH0+XLl2IiYkJeRsvE0Em0DVguguwpYb1pwDPBlugqs8DzwOkp6d7Wn3kKxHszN9JYWkhCTFOIoiLjvO3Efi+2IOVCN5e8Tbrdq1j3a51DOgwgLbN2xIbHetfnhKfQtY+Z5Sy0vJSisuKrWrIRKzMzEySkpJIS0uzblbqgKqSnZ1NZmYmPXr0CHk7L6uGFgI9RaSHiMQCY4CpgSuISM+AyfOAtR7GExJfNc7m3M3+qiFwSwRlThtB2+ZtiZbo/QaZUVUenfsovVJ70S2lG0u3Lq1ULQSVSwQ2XrGJdIWFhaSmploSqCMiQmpq6kGXsDwrEahqqYhcD0wHooGXVXWFiEwAMlR1KnC9iJwJlAC7CVItVN+6pThVTxtyNlBQun/V0L7ifSTFJTmNvlWqhmaun8nSrUt54YIXaBXfitHvjK50xRC4icAtSVgX1MZgSaCO1eZ8enpnsapOA6ZVmXd/wPMbvTx+bSTGJtI6oTUbczZWrhpqFseewj0oSmJsYqUvdJ9H5z5KuxbtuLz/5cRFx3HD4Bs4rvNxldZJiU9hX/E+ysrLbFAaY0yDEHFdTISie0p3p0RQUrlqyHd/QYuYFvtdBlpcVsz0ddO5+YSb/ds8OeLJ/fbt62Zib/FeqxoyJoyys7M544wzANi6dSvR0dG0bdsWgAULFhAbG1vT5gBceeWV3HnnnfTq1cvTWL1miSCIbindWLdrHS1iW/hvJouLjvPfF+AvEQRUDf26+1fKtIyj2x9d4779Hc8V5ljVkDFhlJqaytKlSwF44IEHSExM5NZbb620jqqiqkRFBW9OfeWVVzyPsz5YIgiie0p3Zvw6gx4te/ivEIpvFu/vgygxNpGU+BTW71nv32ZN9hoAjkw9ssZ9B/Y3ZFVDxlS46SZwv5frzIAB8MQTB7fNunXr+M1vfsPQoUOZP38+n3zyCQ8++CCLFy+moKCASy65hPvvd2q4hw4dyjPPPEO/fv1o06YN11xzDZ999hnNmzfno48+ol27dnX7gjwScZ3OhaJ7y+7sK95H1r4sfzVPXLM4f99DwUoEq7NXAyEkgoAeSK1EYEzDtHLlSq666iqWLFlC586defjhh8nIyGDZsmV8+eWXrFy5cr9tcnJyOPXUU1m2bBlDhgzh5ZdfDkPktWMlgiB8Vw7tzN9Z6aohH18iCLx8dE32Gto0b+Mf5aw6gSUCayMwpsLB/nL30uGHH85xx1Vc6PHWW2/x0ksvUVpaypYtW1i5ciV9+lTuOi0hIYERI0YAMGjQIL777rt6jflQWCIIwndHMOBPBIGDy7eIbUFyXDK5RbmoKiLCmuw19Eo9cINR4HCVvkRgVUPGNCwtWlR8JteuXcuTTz7JggULaNmyJZdffnnQ6/QDG5ejo6MpLS2tl1jrglUNBdG9ZUUiCLxqyMfXRlCmFZeArs5efcBqIaDScJVWNWRMw5ebm0tSUhLJyclkZWUxffr0cIdU56xEEETb5m39N5D57iMIVjUEzhd6uZazdd/WkBJB4HCVqk5vGVY1ZEzDNXDgQPr06UO/fv047LDDOOmkk8IdUp2zRBCEiNAtpRtrstcErRrylQjA+ULfum8rQEhVQwnNEmgW1Yycwhyio6KJkqhK+zbG1L8HHnjA//yII47wX1YKzvfBG2+8EXS72bNn+5/v2bPH/3zMmDGMGTOm7gP1iFUNVcPXThCsaqh5TPNKJYJQrxgC503luyvZNxaB3WJvjAknSwTV8F05FNjFBDhJIEqiKpUI1mSvQRAOb314SPv23ZVsYxEYYxoCqxqqhq9EUPXy0cTYRKDy1T9rsteQ1jKtUqmhJilxKWTnZ1MaX2oNxcaYsLNEUA3flUP+G8rcenx/IoivXDUUSrWQT2rzVKb/7Fx5MKDDgDqL2RhjasMSQTV8JQJf1U3VEkHL+JYA3DT9JgpKCrh+8PUh73viWRP5+tevARjSdUidxWyMMbVhiaAaJ3U7iX+f9W/OOvwsYP9EkBibyGNnP8bPu38mSqK47rjrQt73MR2O4ZgOx9R90MYYUwvWWFyNZlHNuPXEW/0lAl9jceBdwDcPuZlnzn2Gp0Y8xVFtjgpLnMaY2hs2bNh+N4g98cQTXHdd9T/sEhOdH4Nbtmxh9OjR1e43IyOjxmM/8cQT5Ofn+6fPPffcSpeg1idPE4GIDBeR1SKyTkTuDLL8LyKyUkSWi8gMEekebD8NQdUSgTGm8Rs7dixTpkypNG/KlCmMHTv2gNt26tSJd999t9bHrpoIpk2bRsuWLWu9v0PhWdWQiEQDk4CzcAayXygiU1U1sNu+JUC6quaLyLXAI8AlXsV0KKo2Fhtj6tZNn9/E0q112w/1gA4DeGJ49b3ZjR49mnvvvZeioiLi4uJYv349W7ZsYcCAAZxxxhns3r2bkpIS/v73vzNy5MhK265fv57zzz+fH3/8kYKCAq688kpWrlxJ7969KSgo8K937bXXsnDhQgoKChg9ejQPPvggTz31FFu2bOG0006jTZs2zJw5k7S0NDIyMmjTpg2PPfaYv/fSq6++mptuuon169czYsQIhg4dypw5c+jcuTMfffQRCQkJh3yevCwRDAbWqeovqloMTAEqnUlVnamqvpQ4D+jiYTyHxEoExjQ9qampDB48mM8//xxwSgOXXHIJCQkJfPDBByxevJiZM2dyyy23+LuECebZZ5+lefPmLF++nHvuuYdFixb5lz300ENkZGSwfPlyvv32W5YvX84NN9xAp06dmDlzJjNnzqy0r0WLFvHKK68wf/585s2bxwsvvMCSJUsApwO88ePHs2LFClq2bMl7771XJ+fBy8bizsCmgOlM4Pga1r8K+CzYAhEZB4wD6NatW13Fd1B8bQSWCIzxRk2/3L3kqx4aOXIkU6ZM4eWXX0ZVufvuu5k1axZRUVFs3ryZbdu20aFDh6D7mDVrFjfccAMA/fv3p3///v5lb7/9Ns8//zylpaVkZWWxcuXKSsurmj17NhdddJG/B9RRo0bx3XffceGFF9KjRw8GDHAuOR80aBDr16+vk3PgZYkgWL8JQVOqiFwOpAP/DrZcVZ9X1XRVTfeNKVrffCUC6zLamKblN7/5DTNmzPCPQDZw4EAmT57Mjh07WLRoEUuXLqV9+/ZBu54OFKyrmF9//ZWJEycyY8YMli9fznnnnXfA/dRU8oiLq+iXrC67uvYyEWQCXQOmuwBbqq4kImcC9wAXqmqRh/EcEmsjMKZpSkxMZNiwYfzpT3/yNxLn5OTQrl07YmJimDlzJhs2bKhxH6eccgqTJ08G4Mcff2T58uWA04V1ixYtSElJYdu2bXz2WUWlR1JSEnv37g26rw8//JD8/Hzy8vL44IMPOPnkk+vq5QblZdXQQqCniPQANgNjgEsDVxCRY4H/A4ar6nYPYzlk1kZgTNM1duxYRo0a5b+C6LLLLuOCCy4gPT2dAQMGcNRRNV8efu2113LllVfSv39/BgwYwODBgwE45phjOPbYY+nbt+9+XViPGzeOESNG0LFjx0rtBAMHDuSKK67w7+Pqq6/m2GOPrbNqoGCkpmLIIe9c5FzgCSAaeFlVHxKRCUCGqk4Vka+Ao4Esd5ONqnphTftMT0/XA12f64VyLef+mfdz3XHX+Qe0N8YcmlWrVtG7d+9wh9HkBDuvIrJIVdODre/pncWqOg2YVmXe/QHPz/Ty+HUpSqL4++l/D3cYxhhT5+zOYmOMiXCWCIwxYeVl9XQkqs35tERgjAmb+Ph4srOzLRnUEVUlOzub+PjQxkbxsd5HjTFh06VLFzIzM9mxY0e4Q2ky4uPj6dLl4DppsERgjAmbmJgYevToEe4wIp5VDRljTISzRGCMMRHOEoExxkQ4T+8s9oKI7ABq7vijem2AnXUYjhcsxrphMdaNhh5jQ48PGk6M3VU1aK+djS4RHAoRyajuFuuGwmKsGxZj3WjoMTb0+KBxxGhVQ8YYE+EsERhjTISLtETwfLgDCIHFWDcsxrrR0GNs6PFBI4gxotoIjDHG7C/SSgTGGGOqsERgjDERLmISgYgMF5HVIrJORO4MdzwAItJVRGaKyCoRWSEiN7rzW4vIlyKy1v3bKsxxRovIEhH5xJ3uISLz3fj+KyKxYY6vpYi8KyI/uedySAM8hze7/+MfReQtEYkP93kUkZdFZLuI/BgwL+h5E8dT7udnuYgMDGOM/3b/18tF5AMRaRmw7C43xtUick64YgxYdquIqIi0cafDch4PJCISgYhEA5OAEUAfYKyI9AlvVACUAreoam/gBGC8G9edwAxV7QnMcKfD6UZgVcD0v4DH3fh2A1eFJaoKTwKfq+pRwDE4sTaYcyginYEbgHRV7YczdOsYwn8eXwWGV5lX3XkbAfR0H+OAZ8MY45dAP1XtD6wB7gJwPztjgL7uNv/rfvbDESMi0hU4C9gYMDtc57FGEZEIgMHAOlX9RVWLgSnAyDDHhKpmqepi9/lenC+wzjixveau9hrwm/BECCLSBTgPeNGdFuB04F13lXDHlwycArwEoKrFqrqHBnQOXc2ABBFpBjTHGac7rOdRVWcBu6rMru68jQReV8c8oKWIdAxHjKr6haqWupPzAF+fyyOBKapapKq/AutwPvv1HqPrceB2IPCKnLCcxwOJlETQGdgUMJ3pzmswRCQNOBaYD7RX1SxwkgXQLnyR8QTOm7ncnU4F9gR8EMN9Lg8DdgCvuNVXL4pICxrQOVTVzcBEnF+GWUAOsIiGdR59qjtvDfUz9CfgM/d5g4lRRC4ENqvqsiqLGkyMgSIlEUiQeQ3mulkRSQTeA25S1dxwx+MjIucD21V1UeDsIKuG81w2AwYCz6rqsUAe4a9Kq8StZx8J9AA6AS1wqgiqajDvySAa2v8dEbkHp3p1sm9WkNXqPUYRaQ7cA9wfbHGQeWH/v0dKIsgEugZMdwG2hCmWSkQkBicJTFbV993Z23zFRffv9jCFdxJwoYisx6lOOx2nhNDSreKA8J/LTCBTVee70+/iJIaGcg4BzgR+VdUdqloCvA+cSMM6jz7VnbcG9RkSkT8C5wOXacXNUA0lxsNxkv4y97PTBVgsIh1oODFWEimJYCHQ071KIxanQWlqmGPy1be/BKxS1ccCFk0F/ug+/yPwUX3HBqCqd6lqF1VNwzlnX6vqZcBMYHS44wNQ1a3AJhHp5c46A1hJAzmHro3ACSLS3P2f+2JsMOcxQHXnbSrwB/eqlxOAHF8VUn0TkeHAHcCFqpofsGgqMEZE4kSkB06D7IL6jk9Vf1DVdqqa5n52MoGB7nu1wZzHSlQ1Ih7AuThXGPwM3BPueNyYhuIUC5cDS93HuTj18DOAte7f1g0g1mHAJ+7zw3A+YOuAd4C4MMc2AMhwz+OHQKuGdg6BB4GfgB+BN4C4cJ9H4C2cNosSnC+rq6o7bzhVGpPcz88POFdAhSvGdTj17L7PzHMB69/jxrgaGBGuGKssXw+0Ced5PNDDupgwxpgIFylVQ8YYY6phicAYYyKcJQJjjIlwlgiMMSbCWSIwxpgIZ4nAmCpEpExElgY86uxOZRFJC9ZLpTHh1OzAqxgTcQpUdUC4gzCmvliJwJgQich6EfmXiCxwH0e487uLyAy3f/kZItLNnd/e7S9/mfs40d1VtIi8IM74BF+ISELYXpQxWCIwJpiEKlVDlwQsy1XVwcAzOP0u4T5/XZ3+8ScDT7nznwK+VdVjcPo/WuHO7wlMUtW+wB7gYo9fjzE1sjuLjalCRPapamKQ+euB01X1F7ezwK2qmioiO4GOqlrizs9S1TYisgPooqpFAftIA75UZ+AXROQOIEZV/+79KzMmOCsRGHNwtJrn1a0TTFHA8zKsrc6EmSUCYw7OJQF/57rP5+D0zgpwGTDbfT4DuBb84z4n11eQxhwM+yVizP4SRGRpwPTnquq7hDRORObj/Iga6867AXhZRG7DGS3tSnf+jcDzInIVzi//a3F6qTSmQbE2AmNC5LYRpKvqznDHYkxdsqohY4yJcFYiMMaYCGclAmOMiXCWCIwxJsJZIjDGmAhnicAYYyKcJQJjjIlw/x81nH8Q0ZZ9bwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# output = classifier.predict_generator(test_set, steps=1)\n",
    "# print(test_set.class_indices)\n",
    "# print(output)\n",
    "size = y_test[:,-1]\n",
    "print(size.size)\n",
    "\n",
    "\n",
    "# predict 10 random hand-writing data\n",
    "y_predicted = model.predict(x_test)\n",
    "for x in range(0,size.size):\n",
    "    \n",
    "    print(\"index:\", x,\n",
    "          \" actual y:\", np.argmax(y_test[x]),\n",
    "          \" answer y:\", np.argmax(y_predicted[x]),\n",
    "            \" prediction:\", np.array(y_predicted[x]))\n",
    "\n",
    "_loss, _acc, _precision, _recall, _f1score = model.evaluate(x_test, y_test)\n",
    "print('loss: {:.3f}, accuracy: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _precision, _recall, _f1score))\n",
    "# print('loss: ', evaluation[0])\n",
    "# print('accuracy', evaluation[1])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 손실 그래프\n",
    "def plot_loss(history):\n",
    "   # 선 그리기\n",
    "    plt.plot(history.history['loss'], 'y', label='train loss')\n",
    "    plt.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "   # 그래프 제목\n",
    "    plt.title('Model Loss')\n",
    "   # x,y축 이름 표시\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "   # 각 라인 표식 표시\n",
    "    plt.legend(['Train','Validation'],loc=0)\n",
    "\n",
    "# 정확도 그래프\n",
    "def plot_acc(history):\n",
    "  # dir(history.history)\n",
    "    plt.plot(history.history['accuracy'], 'b', label='train accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], 'g', label='val accuracy')\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc=0)\n",
    "\n",
    "plot_loss(history)\n",
    "plt.show()\n",
    "plot_acc(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = [512,1024]\n",
    "# learning_rate = [0.001,0.0001,0.00001,0.000001]\n",
    "# for  batch_size, learning_rate in product(batch_size,learning_rate):\n",
    "#     print(f'batchSIZE is {batch_size}, Learning Rate is {learning_rate}')\n",
    "#     train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "#                                    shear_range = 0.2,\n",
    "#                                    zoom_range = 0.2,\n",
    "#                                    horizontal_flip = True)\n",
    "\n",
    "#     test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "#     categories = ['dog','cat','bear','hamster','horse']\n",
    "\n",
    "#     training_set = train_datagen.flow_from_directory(train_img_dir, target_size=(128,128), \n",
    "#                                                  classes=categories, \n",
    "#                                                  batch_size=batch_size)\n",
    "\n",
    "#     test_set = test_datagen.flow_from_directory(test_img_dir,\n",
    "#                                             target_size=(128,128), \n",
    "#                                             classes=categories, \n",
    "#                                             batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "#     x_train, y_train = next(training_set)\n",
    "#     x_test, y_test = next(test_set)\n",
    "#     model = mobile_net()\n",
    "#     ## learning rate scheduing\n",
    "#     lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,\n",
    "#                                                               decay_steps=training_epochs*10,\n",
    "#                                                               decay_rate=0.4,\n",
    "#                                                               staircase=True)\n",
    "#     ## optimizer는 Adam, loss는 sparse categorical crossentropy 사용\n",
    "#     ## label이 ont-hot으로 encoding 안 된 경우에 sparse categorical corssentropy 및 sparse categorical accuracy 사용\n",
    "#     model.compile(keras.optimizers.Adam(lr_schedule), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#     ## Train!\n",
    "#     model.fit(x_train, y_train, steps_per_epoch=training_epochs,\n",
    "#              epochs=20)\n",
    "#     # output = classifier.predict_generator(test_set, steps=1)\n",
    "#     # print(test_set.class_indices)\n",
    "#     # print(output)\n",
    "#     size = y_test[:,-1]\n",
    "#     print(size.size)\n",
    "\n",
    "\n",
    "#     # predict 10 random hand-writing data\n",
    "#     y_predicted = model.predict(x_test)\n",
    "#     for x in range(0,size.size):\n",
    "\n",
    "#         print(\"index:\", x,\n",
    "#               \" actual y:\", np.argmax(y_test[x]),\n",
    "#               \" answer y:\", np.argmax(y_predicted[x]),\n",
    "#                 \" prediction:\", np.array(y_predicted[x]))\n",
    "\n",
    "#     evaluation = model.evaluate(x_test, y_test)\n",
    "#     print('loss: ', evaluation[0])\n",
    "#     print('accuracy', evaluation[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
