{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchSIZE is 512, Learning Rate is 0.001\n",
      "Found 806 images belonging to 6 classes.\n",
      "Found 104 images belonging to 6 classes.\n",
      "Found 288 images belonging to 6 classes.\n",
      "2.4.3\n",
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import os # miscellaneous operating system interfaces\n",
    "import shutil # high-level file operations\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import decimal\n",
    "import random\n",
    "from itertools import product\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D \n",
    "from keras.layers import MaxPooling2D \n",
    "from keras.layers import Flatten \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.applications import MobileNetV2, Xception, DenseNet121,ResNet50V2,NASNetMobile\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "from keras.layers import  Input, Conv2D, Conv2DTranspose, ReLU,AveragePooling2D, MaxPooling2D, Dense, BatchNormalization, GlobalAveragePooling2D, Concatenate\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "base_dir = r'C:\\Users\\1217s\\Desktop\\capstone deeplearning\\images\\woman'\n",
    "\n",
    "train_img_dir = r'C:\\Users\\1217s\\Desktop\\capstone deeplearning\\images\\woman\\train'\n",
    "\n",
    "test_img_dir = r'C:\\Users\\1217s\\Desktop\\capstone deeplearning\\images\\woman\\test'\n",
    "\n",
    "val_img_dir = r'C:\\Users\\1217s\\Desktop\\capstone deeplearning\\images\\woman\\val'\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10\n",
    "batch_size = 512\n",
    "validation_steps = 20\n",
    "\n",
    "\n",
    "\n",
    "print(f'batchSIZE is {batch_size}, Learning Rate is {learning_rate}')\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "categories = ['dog','cat','rabbit','squirrel','deer','fox']\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(train_img_dir, target_size=(128,128), \n",
    "                                             classes=categories, \n",
    "                                             batch_size=batch_size)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(test_img_dir,\n",
    "                                        target_size=(128,128), \n",
    "                                        classes=categories, \n",
    "                                        batch_size=batch_size)\n",
    "\n",
    "val_set = test_datagen.flow_from_directory(val_img_dir,\n",
    "                                        target_size=(128,128), \n",
    "                                        classes=categories, \n",
    "                                        batch_size=batch_size)\n",
    "\n",
    "x_train, y_train = next(training_set)\n",
    "x_test, y_test = next(test_set)\n",
    "x_val,y_val = next(val_set)   \n",
    "    \n",
    "print(keras.__version__)\n",
    "print(tf.__version__)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = Input(shape=(128, 128, 3))\n",
    "    \n",
    "\n",
    "    conv2_1 = Conv2D(32, 3, 1, 'SAME')(inputs)\n",
    "    conv2_2 = Conv2D(32, 3, 1, 'SAME')(conv2_1)\n",
    "    pool2_3 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv2_2)\n",
    "    br1 = BatchNormalization()(pool2_3)\n",
    "    \n",
    "    conv2_1 = Conv2D(32, 3, 1, 'SAME')(br1)\n",
    "    conv2_2 = Conv2D(32, 3, 1, 'SAME')(conv2_1)\n",
    "    pool2_3 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv2_2)\n",
    "    br1 = BatchNormalization()(pool2_3)\n",
    "    \n",
    "    \n",
    "    conv3_1 = Conv2D(64, 3, 1, 'SAME')(br1)\n",
    "    conv3_2 = Conv2D(64, 3, 1, 'SAME')(conv3_1)\n",
    "    pool3_2 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv3_2)\n",
    "    br2 = BatchNormalization()(pool3_2)\n",
    "    \n",
    "    conv3_1 = Conv2D(64, 3, 1, 'SAME')(br2)\n",
    "    conv3_2 = Conv2D(64, 3, 1, 'SAME')(conv3_1)\n",
    "    pool3_2 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv3_2)\n",
    "    br2 = BatchNormalization()(pool3_2)\n",
    "    \n",
    "    \n",
    "    conv4_1 = Conv2D(128, 3, 1, 'SAME')(br2)\n",
    "    conv4_2 = Conv2D(128, 3, 1, 'SAME')(conv4_1)\n",
    "    pool4_2 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv4_2)\n",
    "    br3 = BatchNormalization()(pool4_2)\n",
    "    \n",
    "    conv4_1 = Conv2D(128, 3, 1, 'SAME')(br3)\n",
    "    conv4_2 = Conv2D(128, 3, 1, 'SAME')(conv4_1)\n",
    "    pool4_2 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv4_2)\n",
    "    br3 = BatchNormalization()(pool4_2)\n",
    "    \n",
    "    flatten1 = Flatten()(pool4_2)\n",
    "    dense1 = Dense(units = 512, activation = 'relu')(flatten1)\n",
    "    dense2 = Dense(units = 1024, activation = 'relu')(dense1)\n",
    "    dr1 = Dropout(0.7)(dense2)\n",
    "    dense3 = Dense(units = 5, activation = 'sigmoid')(dr1)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=dense3) \n",
    "\n",
    "def vgg16():\n",
    "    inputs = Input(shape=(128, 128, 3))\n",
    "    \n",
    "\n",
    "    conv1_1 = Conv2D(3, 3, 1, 'SAME',activation = 'relu')(inputs)\n",
    "    conv1_2 = Conv2D(64, 3, 1, 'SAME',activation = 'relu')(conv1_1)\n",
    "    conv1_3 = Conv2D(64, 3, 1, 'SAME',activation = 'relu')(conv1_2)\n",
    "    pool1 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv1_3)\n",
    "    \n",
    "    conv2_1 = Conv2D(128, 3, 1, 'SAME',activation = 'relu')(pool1)\n",
    "    conv2_2 = Conv2D(128, 3, 1, 'SAME',activation = 'relu')(conv2_1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv2_2)\n",
    "    \n",
    "    \n",
    "    conv3_1 = Conv2D(256, 3, 1, 'SAME',activation = 'relu')(pool2)\n",
    "    conv3_2 = Conv2D(256, 3, 1, 'SAME',activation = 'relu')(conv3_1)\n",
    "    conv3_3 = Conv2D(256, 3, 1, 'SAME',activation = 'relu')(conv3_2)\n",
    "    pool3 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv3_3)\n",
    "\n",
    "    \n",
    "    conv4_1 = Conv2D(512, 3, 1, 'SAME',activation = 'relu')(pool3)\n",
    "    conv4_2 = Conv2D(512, 3, 1, 'SAME',activation = 'relu')(conv4_1)\n",
    "    conv4_3 = Conv2D(512, 3, 1, 'SAME',activation = 'relu')(conv4_2)\n",
    "    pool4 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv4_3)\n",
    "    \n",
    "    conv5_1 = Conv2D(512, 3, 1, 'SAME',activation = 'relu')(pool4)\n",
    "    conv5_2 = Conv2D(512, 3, 1, 'SAME',activation = 'relu')(conv5_1)\n",
    "    conv5_3 = Conv2D(512, 3, 1, 'SAME',activation = 'relu')(conv5_2)\n",
    "    pool5 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv5_3)\n",
    "    \n",
    "    flatten1 = Flatten()(pool5)\n",
    "    dense1 = Dense(units = 4096)(flatten1)\n",
    "    dense2 = Dense(units = 4096)(dense1)\n",
    "    dense3 = Dense(units = 5, activation = 'sigmoid')(dense2)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=dense3) \n",
    "\n",
    "def mobile_net():\n",
    "    inputs = Input(shape=(128, 128, 3))\n",
    "    mobileNet = MobileNetV2(weights = \"imagenet\", include_top=False,input_shape = (128,128,3)\n",
    "                            ,input_tensor = inputs)\n",
    "    for layer in mobileNet.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    output = mobileNet.output\n",
    "    pooling = AveragePooling2D(pool_size=(4,4),padding='SAME')(output)\n",
    "    \n",
    "    flatten1 = Flatten()(pooling)\n",
    "    dense1 = Dense(units = 512, activation = 'relu')(flatten1)\n",
    "    dense2 = Dense(units = 1024, activation = 'relu')(dense1)\n",
    "    dr1 = Dropout(0.7)(dense2)\n",
    "    dense3 = Dense(units = 6, activation = 'sigmoid')(dr1)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=dense3)\n",
    "\n",
    "def xception():\n",
    "    inputs = Input(shape=(128, 128, 3))\n",
    "    xception = Xception(weights = \"imagenet\", include_top=False,input_shape = (128,128,3)\n",
    "                            ,input_tensor = inputs)\n",
    "    for layer in xception.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    output = xception.output\n",
    "    pooling = AveragePooling2D(pool_size=(4,4),padding='SAME')(output)\n",
    "    \n",
    "    flatten1 = Flatten()(pooling)\n",
    "    dense1 = Dense(units = 512, activation = 'relu')(flatten1)\n",
    "    dense2 = Dense(units = 1024, activation = 'relu')(dense1)\n",
    "    dr1 = Dropout(0.7)(dense2)\n",
    "    dense3 = Dense(units = 6, activation = 'sigmoid')(dr1)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=dense3)\n",
    "\n",
    "def resnet():\n",
    "    inputs = Input(shape=(128, 128, 3))\n",
    "    resnet = ResNet50V2 (weights = \"imagenet\", include_top=False,input_shape = (128,128,3)\n",
    "                            ,input_tensor = inputs)\n",
    "    for layer in resnet.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    output = resnet.output\n",
    "    pooling = AveragePooling2D(pool_size=(4,4),padding='SAME')(output)\n",
    "    \n",
    "    flatten1 = Flatten()(pooling)\n",
    "    dense1 = Dense(units = 512, activation = 'relu')(flatten1)\n",
    "    dense2 = Dense(units = 1024, activation = 'relu')(dense1)\n",
    "    dr1 = Dropout(0.7)(dense2)\n",
    "    dense3 = Dense(units = 5, activation = 'sigmoid')(dr1)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=dense3)\n",
    "\n",
    "def densenet():\n",
    "    inputs = Input(shape=(128, 128, 3))\n",
    "    densenet = DenseNet121(weights = \"imagenet\", include_top=False,input_shape = (128,128,3)\n",
    "                            ,input_tensor = inputs)\n",
    "    for layer in densenet.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    output = densenet.output\n",
    "    pooling = AveragePooling2D(pool_size=(4,4),padding='SAME')(output)\n",
    "    \n",
    "    flatten1 = Flatten()(pooling)\n",
    "    dense1 = Dense(units = 512, activation = 'relu')(flatten1)\n",
    "    dense2 = Dense(units = 1024, activation = 'relu')(dense1)\n",
    "    dr1 = Dropout(0.7)(dense2)\n",
    "    dense3 = Dense(units = 6, activation = 'sigmoid')(dr1)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=dense3)\n",
    "\n",
    "class ResidualUnit(tf.keras.Model):\n",
    "    def __init__(self, filter_in, filter_out, kernel_size):\n",
    "        super(ResidualUnit, self).__init__()\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filter_out, kernel_size, padding='same')\n",
    "        \n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filter_out, kernel_size, padding='same')\n",
    "        \n",
    "        if filter_in == filter_out:\n",
    "            self.identity = lambda x: x\n",
    "        else:\n",
    "            self.identity = tf.keras.layers.Conv2D(filter_out, (1,1), padding='same')\n",
    "\n",
    "    def call(self, x, training=False, mask=None):\n",
    "        h = self.bn1(x, training=training)\n",
    "        h = tf.nn.relu(h)\n",
    "        h = self.conv1(h)\n",
    "        \n",
    "        h = self.bn2(h, training=training)\n",
    "        h = tf.nn.relu(h)\n",
    "        h = self.conv2(h)\n",
    "        return self.identity(x) + h\n",
    "    \n",
    "class ResnetLayer(tf.keras.Model):\n",
    "    def __init__(self, filter_in, filters, kernel_size):\n",
    "        super(ResnetLayer, self).__init__()\n",
    "        self.sequence = list()\n",
    "        for f_in, f_out in zip([filter_in] + list(filters), filters):\n",
    "            self.sequence.append(ResidualUnit(f_in, f_out, kernel_size))\n",
    "\n",
    "    def call(self, x, training=False, mask=None):\n",
    "        for unit in self.sequence:\n",
    "            x = unit(x, training=training)\n",
    "        return x\n",
    "    \n",
    "class ResNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu') # 28x28x8\n",
    "        \n",
    "        self.res1 = ResnetLayer(64, (16, 16), (3, 3)) # 28x28x16\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D((2, 2)) # 14x14x16\n",
    "        \n",
    "        self.res2 = ResnetLayer(128, (32, 32), (3, 3)) # 14x14x32\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D((2, 2)) # 7x7x32\n",
    "        \n",
    "        \n",
    "        self.res3 = ResnetLayer(256, (64, 64), (3, 3)) # 7x7x64\n",
    "        self.pool = tf.keras.layers.MaxPool2D((2, 2)) # 7x7x32\n",
    "\n",
    "        \n",
    "        self.res4 = ResnetLayer(512, (64, 64), (3, 3)) # 7x7x64\n",
    "        self.pool = tf.keras.layers.MaxPool2D((2, 2)) # 7x7x32\n",
    "\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = Dense(units = 1024, activation = 'relu')\n",
    "        self.dense2 = Dense(units = 1024, activation = 'relu')\n",
    "        self.dense3 = tf.keras.layers.Dense(5, activation='softmax')\n",
    "        \n",
    "    def call(self, x, training=False, mask=None):\n",
    "        x = self.conv1(x)\n",
    "        x = self.res1(x, training=training)\n",
    "        x = self.pool1(x)\n",
    "        x = self.res2(x, training=training)\n",
    "        x = self.pool2(x)\n",
    "        x = self.res3(x, training=training)\n",
    "        x = self.pool2(x)\n",
    "        x = self.res4(x, training=training)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "10/10 [==============================] - 52s 5s/step - loss: 0.5554 - accuracy: 0.2031 - precision: 0.2265 - recall: 0.1213 - f1score: 0.1177 - val_loss: 0.7819 - val_accuracy: 0.1562 - val_precision: 0.1668 - val_recall: 0.1300 - val_f1score: 0.1457\n",
      "Epoch 2/60\n",
      "10/10 [==============================] - 50s 5s/step - loss: 0.4026 - accuracy: 0.4062 - precision: 0.5546 - recall: 0.1500 - f1score: 0.2322 - val_loss: 0.8012 - val_accuracy: 0.1493 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: 0.0000e+00\n",
      "Epoch 3/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 0.2822 - accuracy: 0.6445 - precision: 0.7436 - recall: 0.4647 - f1score: 0.5645 - val_loss: 0.7956 - val_accuracy: 0.1597 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: 0.0000e+00\n",
      "Epoch 4/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 0.1698 - accuracy: 0.8203 - precision: 0.8485 - recall: 0.7645 - f1score: 0.8023 - val_loss: 1.1535 - val_accuracy: 0.2743 - val_precision: 0.3404 - val_recall: 0.1400 - val_f1score: 0.1942\n",
      "Epoch 5/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 0.1421 - accuracy: 0.8438 - precision: 0.8557 - recall: 0.8103 - f1score: 0.8322 - val_loss: 1.1027 - val_accuracy: 0.2882 - val_precision: 0.3873 - val_recall: 0.1467 - val_f1score: 0.2087\n",
      "Epoch 6/60\n",
      "10/10 [==============================] - 50s 5s/step - loss: 0.1197 - accuracy: 0.8809 - precision: 0.9100 - recall: 0.8280 - f1score: 0.8666 - val_loss: 0.7140 - val_accuracy: 0.3958 - val_precision: 0.4411 - val_recall: 0.3400 - val_f1score: 0.3825\n",
      "Epoch 7/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 0.0458 - accuracy: 0.9648 - precision: 0.9625 - recall: 0.9538 - f1score: 0.9579 - val_loss: 2.6805 - val_accuracy: 0.2292 - val_precision: 0.2190 - val_recall: 0.2000 - val_f1score: 0.2087\n",
      "Epoch 8/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 0.0702 - accuracy: 0.9395 - precision: 0.9423 - recall: 0.9222 - f1score: 0.9321 - val_loss: 2.3616 - val_accuracy: 0.1944 - val_precision: 0.2009 - val_recall: 0.2100 - val_f1score: 0.2051\n",
      "Epoch 9/60\n",
      "10/10 [==============================] - 50s 5s/step - loss: 0.0801 - accuracy: 0.9141 - precision: 0.9322 - recall: 0.9086 - f1score: 0.9200 - val_loss: 1.7734 - val_accuracy: 0.2257 - val_precision: 0.2310 - val_recall: 0.2233 - val_f1score: 0.2264\n",
      "Epoch 10/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 0.0769 - accuracy: 0.9238 - precision: 0.9302 - recall: 0.9152 - f1score: 0.9226 - val_loss: 4.3026 - val_accuracy: 0.1528 - val_precision: 0.1600 - val_recall: 0.1600 - val_f1score: 0.1600\n",
      "Epoch 11/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 0.0373 - accuracy: 0.9668 - precision: 0.9666 - recall: 0.9573 - f1score: 0.9618 - val_loss: 2.9511 - val_accuracy: 0.2014 - val_precision: 0.2068 - val_recall: 0.2033 - val_f1score: 0.2050\n",
      "Epoch 12/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 0.0304 - accuracy: 0.9688 - precision: 0.9716 - recall: 0.9705 - f1score: 0.9709 - val_loss: 1.5180 - val_accuracy: 0.3889 - val_precision: 0.4087 - val_recall: 0.4000 - val_f1score: 0.4041\n",
      "Epoch 13/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 0.0142 - accuracy: 0.9863 - precision: 0.9866 - recall: 0.9885 - f1score: 0.9875 - val_loss: 0.8749 - val_accuracy: 0.5243 - val_precision: 0.5303 - val_recall: 0.5133 - val_f1score: 0.5209\n",
      "Epoch 14/60\n",
      "10/10 [==============================] - 52s 5s/step - loss: 0.0104 - accuracy: 0.9922 - precision: 0.9922 - recall: 0.9865 - f1score: 0.9894 - val_loss: 0.8340 - val_accuracy: 0.5556 - val_precision: 0.5660 - val_recall: 0.5567 - val_f1score: 0.5605\n",
      "Epoch 15/60\n",
      "10/10 [==============================] - 56s 6s/step - loss: 0.0035 - accuracy: 0.9980 - precision: 1.0000 - recall: 0.9981 - f1score: 0.9990 - val_loss: 1.3846 - val_accuracy: 0.4028 - val_precision: 0.4066 - val_recall: 0.4000 - val_f1score: 0.4031\n",
      "Epoch 16/60\n",
      "10/10 [==============================] - 53s 5s/step - loss: 0.0062 - accuracy: 0.9961 - precision: 0.9943 - recall: 0.9981 - f1score: 0.9962 - val_loss: 0.9375 - val_accuracy: 0.4618 - val_precision: 0.4651 - val_recall: 0.4533 - val_f1score: 0.4586\n",
      "Epoch 17/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 0.0044 - accuracy: 0.9961 - precision: 0.9962 - recall: 0.9962 - f1score: 0.9962 - val_loss: 0.6557 - val_accuracy: 0.5417 - val_precision: 0.5710 - val_recall: 0.5033 - val_f1score: 0.5325\n",
      "Epoch 18/60\n",
      "10/10 [==============================] - 55s 5s/step - loss: 0.0048 - accuracy: 0.9980 - precision: 0.9962 - recall: 0.9962 - f1score: 0.9962 - val_loss: 0.8023 - val_accuracy: 0.5174 - val_precision: 0.5381 - val_recall: 0.5067 - val_f1score: 0.5214\n",
      "Epoch 19/60\n",
      "10/10 [==============================] - 54s 5s/step - loss: 0.0029 - accuracy: 1.0000 - precision: 0.9959 - recall: 1.0000 - f1score: 0.9979 - val_loss: 0.7628 - val_accuracy: 0.5660 - val_precision: 0.5842 - val_recall: 0.5533 - val_f1score: 0.5676\n",
      "Epoch 20/60\n",
      "10/10 [==============================] - 56s 6s/step - loss: 0.0037 - accuracy: 0.9961 - precision: 0.9962 - recall: 0.9981 - f1score: 0.9971 - val_loss: 0.7363 - val_accuracy: 0.5972 - val_precision: 0.5709 - val_recall: 0.5600 - val_f1score: 0.5650\n",
      "Epoch 21/60\n",
      "10/10 [==============================] - 54s 5s/step - loss: 0.0018 - accuracy: 1.0000 - precision: 0.9981 - recall: 1.0000 - f1score: 0.9990 - val_loss: 0.6488 - val_accuracy: 0.6042 - val_precision: 0.5909 - val_recall: 0.5767 - val_f1score: 0.5834\n",
      "Epoch 22/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 0.0015 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9981 - f1score: 0.9990 - val_loss: 0.5617 - val_accuracy: 0.6528 - val_precision: 0.6441 - val_recall: 0.6400 - val_f1score: 0.6410\n",
      "Epoch 23/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 0.0016 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9981 - f1score: 0.9990 - val_loss: 0.4496 - val_accuracy: 0.7049 - val_precision: 0.7075 - val_recall: 0.6967 - val_f1score: 0.7014\n",
      "Epoch 24/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 7.7293e-04 - accuracy: 1.0000 - precision: 0.9981 - recall: 1.0000 - f1score: 0.9990 - val_loss: 0.4239 - val_accuracy: 0.7188 - val_precision: 0.7225 - val_recall: 0.6900 - val_f1score: 0.7047\n",
      "Epoch 25/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 6.5329e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4105 - val_accuracy: 0.7083 - val_precision: 0.7177 - val_recall: 0.6933 - val_f1score: 0.7043\n",
      "Epoch 26/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 8.3752e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3870 - val_accuracy: 0.7083 - val_precision: 0.7280 - val_recall: 0.6933 - val_f1score: 0.7095\n",
      "Epoch 27/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 5.4638e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3252 - val_accuracy: 0.7361 - val_precision: 0.7577 - val_recall: 0.7200 - val_f1score: 0.7377\n",
      "Epoch 28/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 3.7410e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.7465 - val_precision: 0.7753 - val_recall: 0.7300 - val_f1score: 0.7509\n",
      "Epoch 29/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 4.6702e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2775 - val_accuracy: 0.7674 - val_precision: 0.7895 - val_recall: 0.7467 - val_f1score: 0.7665\n",
      "Epoch 30/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 2.2151e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.7882 - val_precision: 0.8076 - val_recall: 0.7500 - val_f1score: 0.7763\n",
      "Epoch 31/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 8.5999e-04 - accuracy: 1.0000 - precision: 0.9981 - recall: 1.0000 - f1score: 0.9990 - val_loss: 0.2486 - val_accuracy: 0.8090 - val_precision: 0.8226 - val_recall: 0.7867 - val_f1score: 0.8036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 3.2265e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.8125 - val_precision: 0.8259 - val_recall: 0.7867 - val_f1score: 0.8052\n",
      "Epoch 33/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 3.0665e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2341 - val_accuracy: 0.8194 - val_precision: 0.8263 - val_recall: 0.7933 - val_f1score: 0.8092\n",
      "Epoch 34/60\n",
      "10/10 [==============================] - 52s 5s/step - loss: 1.8005e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.8229 - val_precision: 0.8368 - val_recall: 0.8267 - val_f1score: 0.8304\n",
      "Epoch 35/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 2.4542e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.8264 - val_precision: 0.8395 - val_recall: 0.8233 - val_f1score: 0.8298\n",
      "Epoch 36/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 2.1064e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.8299 - val_precision: 0.8614 - val_recall: 0.8233 - val_f1score: 0.8412\n",
      "Epoch 37/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 3.2936e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.8299 - val_precision: 0.8621 - val_recall: 0.8200 - val_f1score: 0.8394\n",
      "Epoch 38/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 2.3884e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.8333 - val_precision: 0.8621 - val_recall: 0.8200 - val_f1score: 0.8394\n",
      "Epoch 39/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 1.8523e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.8333 - val_precision: 0.8618 - val_recall: 0.8200 - val_f1score: 0.8394\n",
      "Epoch 40/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 3.4345e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.8299 - val_precision: 0.8578 - val_recall: 0.8200 - val_f1score: 0.8376\n",
      "Epoch 41/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 1.9864e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.8368 - val_precision: 0.8568 - val_recall: 0.8167 - val_f1score: 0.8356\n",
      "Epoch 42/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 1.6432e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.8333 - val_precision: 0.8593 - val_recall: 0.8133 - val_f1score: 0.8350\n",
      "Epoch 43/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 1.7606e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.8333 - val_precision: 0.8591 - val_recall: 0.8100 - val_f1score: 0.8331\n",
      "Epoch 44/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 1.9837e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.8333 - val_precision: 0.8639 - val_recall: 0.8033 - val_f1score: 0.8315\n",
      "Epoch 45/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 1.3927e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.8299 - val_precision: 0.8630 - val_recall: 0.7967 - val_f1score: 0.8273\n",
      "Epoch 46/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 3.1318e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.8229 - val_precision: 0.8650 - val_recall: 0.7967 - val_f1score: 0.8279\n",
      "Epoch 47/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 1.3667e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.8194 - val_precision: 0.8623 - val_recall: 0.7967 - val_f1score: 0.8264\n",
      "Epoch 48/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 3.7119e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.8229 - val_precision: 0.8689 - val_recall: 0.8033 - val_f1score: 0.8331\n",
      "Epoch 49/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 5.6583e-04 - accuracy: 1.0000 - precision: 0.9978 - recall: 1.0000 - f1score: 0.9989 - val_loss: 0.1968 - val_accuracy: 0.8333 - val_precision: 0.8718 - val_recall: 0.8033 - val_f1score: 0.8343\n",
      "Epoch 50/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 1.8680e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.8333 - val_precision: 0.8830 - val_recall: 0.8067 - val_f1score: 0.8401\n",
      "Epoch 51/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 1.8490e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.8299 - val_precision: 0.8798 - val_recall: 0.8133 - val_f1score: 0.8426\n",
      "Epoch 52/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 1.3971e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.8333 - val_precision: 0.8767 - val_recall: 0.8100 - val_f1score: 0.8393\n",
      "Epoch 53/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 2.0101e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.8333 - val_precision: 0.8729 - val_recall: 0.8100 - val_f1score: 0.8379\n",
      "Epoch 54/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 2.7088e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.8333 - val_precision: 0.8725 - val_recall: 0.8067 - val_f1score: 0.8361\n",
      "Epoch 55/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 2.1717e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.8299 - val_precision: 0.8728 - val_recall: 0.8100 - val_f1score: 0.8382\n",
      "Epoch 56/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 2.6670e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.8299 - val_precision: 0.8696 - val_recall: 0.8100 - val_f1score: 0.8369\n",
      "Epoch 57/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 1.3538e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.8299 - val_precision: 0.8696 - val_recall: 0.8100 - val_f1score: 0.8369\n",
      "Epoch 58/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 1.8919e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.8299 - val_precision: 0.8684 - val_recall: 0.8100 - val_f1score: 0.8369\n",
      "Epoch 59/60\n",
      "10/10 [==============================] - 50s 5s/step - loss: 1.3243e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.8299 - val_precision: 0.8651 - val_recall: 0.8100 - val_f1score: 0.8354\n",
      "Epoch 60/60\n",
      "10/10 [==============================] - 51s 5s/step - loss: 1.7354e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.8299 - val_precision: 0.8651 - val_recall: 0.8100 - val_f1score: 0.8354\n"
     ]
    }
   ],
   "source": [
    "def recall(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
    "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
    "\n",
    "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n",
    "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
    "\n",
    "    # Precision = (True Positive) / (True Positive + False Positive)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1score(y_target, y_pred):\n",
    "    _recall = recall(y_target, y_pred)\n",
    "    _precision = precision(y_target, y_pred)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
    "    \n",
    "    # return a single tensor value\n",
    "    return _f1score\n",
    "\n",
    "\n",
    "#model = create_model()\n",
    "#model = ResNet()\n",
    "#model = mobile_net()\n",
    "#model = xception()\n",
    "model = densenet()\n",
    "#model = resnet()\n",
    "\n",
    "## learning rate scheduing\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,\n",
    "                                                          decay_steps=training_epochs*10,\n",
    "                                                          decay_rate=0.5,\n",
    "                                                          staircase=True)\n",
    "## optimizer는 Adam, loss는 sparse categorical crossentropy 사용\n",
    "## label이 ont-hot으로 encoding 안 된 경우에 sparse categorical corssentropy 및 sparse categorical accuracy 사용\n",
    "model.compile(keras.optimizers.Adam(lr_schedule), loss = 'binary_crossentropy', metrics=['accuracy', precision, recall, f1score])\n",
    "\n",
    "## Train!\n",
    "## Train!\n",
    "history = model.fit(x_train, y_train, steps_per_epoch=training_epochs,\n",
    "         epochs=60, validation_data = (x_val,y_val),validation_steps=validation_steps)\n",
    "\n",
    "model.save('animal_model_woman.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "index: 0  actual y: 4  answer y: 4  prediction: [1.2276066e-08 8.4637062e-09 9.1913854e-09 6.5989001e-09 1.0000000e+00\n",
      " 1.3515836e-08]\n",
      "index: 1  actual y: 3  answer y: 3  prediction: [3.1174211e-05 1.7217808e-05 3.9000559e-05 9.8104733e-01 1.3662845e-02\n",
      " 1.0698736e-03]\n",
      "index: 2  actual y: 0  answer y: 5  prediction: [2.5323647e-01 1.9419193e-04 3.9395690e-03 5.7497233e-02 2.7798712e-03\n",
      " 2.5850803e-01]\n",
      "index: 3  actual y: 3  answer y: 3  prediction: [1.1694321e-05 3.4831664e-06 4.9835371e-06 9.9995792e-01 1.1609077e-06\n",
      " 1.8244700e-06]\n",
      "index: 4  actual y: 5  answer y: 5  prediction: [1.3035536e-04 3.0085519e-05 5.5052129e-05 6.9799527e-05 2.9399858e-05\n",
      " 9.9966818e-01]\n",
      "index: 5  actual y: 0  answer y: 0  prediction: [0.2913828  0.01032415 0.19577262 0.02964094 0.03903925 0.071944  ]\n",
      "index: 6  actual y: 1  answer y: 1  prediction: [1.1151082e-04 9.9906504e-01 2.1073222e-04 4.5489858e-05 4.2888522e-04\n",
      " 1.0755359e-05]\n",
      "index: 7  actual y: 3  answer y: 3  prediction: [1.8557906e-04 1.3631582e-04 1.2760758e-03 5.8356130e-01 4.5322886e-01\n",
      " 2.0506978e-04]\n",
      "index: 8  actual y: 1  answer y: 1  prediction: [1.8796959e-06 9.9997020e-01 3.1158561e-06 1.6528866e-06 8.0734271e-06\n",
      " 1.8570014e-06]\n",
      "index: 9  actual y: 5  answer y: 5  prediction: [1.4514620e-05 3.9185306e-06 2.0664670e-06 9.7273478e-06 4.4672056e-06\n",
      " 9.9997389e-01]\n",
      "index: 10  actual y: 5  answer y: 5  prediction: [1.6719103e-04 3.5142899e-04 2.2825599e-04 2.9394031e-04 1.1120141e-03\n",
      " 9.9835014e-01]\n",
      "index: 11  actual y: 1  answer y: 1  prediction: [3.9672568e-07 9.9999535e-01 1.3853288e-07 1.7411888e-06 2.8788844e-07\n",
      " 2.1209998e-07]\n",
      "index: 12  actual y: 4  answer y: 4  prediction: [0.01374197 0.00118113 0.0072858  0.07431707 0.7898258  0.01052672]\n",
      "index: 13  actual y: 0  answer y: 0  prediction: [9.9999899e-01 3.3803320e-07 3.3703003e-08 3.6549687e-07 2.2460334e-08\n",
      " 4.0230411e-08]\n",
      "index: 14  actual y: 3  answer y: 2  prediction: [0.0141612  0.01125056 0.8576795  0.01160529 0.04251844 0.00346273]\n",
      "index: 15  actual y: 3  answer y: 3  prediction: [1.8102184e-06 2.2702854e-07 9.2312592e-07 9.9998939e-01 1.0982011e-06\n",
      " 4.1190910e-07]\n",
      "index: 16  actual y: 3  answer y: 3  prediction: [3.3781071e-06 7.9093746e-07 3.7463160e-06 9.9996418e-01 6.2633767e-06\n",
      " 2.9585026e-06]\n",
      "index: 17  actual y: 0  answer y: 0  prediction: [9.9985993e-01 7.9661313e-06 1.5158934e-06 3.1813979e-04 1.5764360e-06\n",
      " 5.5232213e-06]\n",
      "index: 18  actual y: 2  answer y: 2  prediction: [5.2815676e-04 3.3333898e-04 9.9188769e-01 4.8161745e-03 1.7620921e-03\n",
      " 1.7511845e-04]\n",
      "index: 19  actual y: 2  answer y: 2  prediction: [2.7725101e-04 7.5447559e-04 9.9157214e-01 2.7641654e-04 1.2546182e-03\n",
      " 3.8072765e-03]\n",
      "index: 20  actual y: 5  answer y: 5  prediction: [1.0354387e-04 9.9164248e-04 5.8857811e-05 2.6270747e-04 1.3831258e-04\n",
      " 9.9882323e-01]\n",
      "index: 21  actual y: 3  answer y: 3  prediction: [8.0084341e-05 1.5297532e-04 1.3792515e-04 9.9698734e-01 4.2669504e-05\n",
      " 1.1079311e-03]\n",
      "index: 22  actual y: 5  answer y: 5  prediction: [1.9274426e-05 6.0859302e-06 2.9307269e-06 8.0903471e-03 4.1902204e-06\n",
      " 9.9679118e-01]\n",
      "index: 23  actual y: 4  answer y: 4  prediction: [2.1367852e-05 7.1184753e-05 1.4777933e-05 1.2697238e-05 9.9990469e-01\n",
      " 1.2163453e-05]\n",
      "index: 24  actual y: 4  answer y: 4  prediction: [1.2966007e-02 2.9242039e-04 6.1646879e-02 4.5245886e-04 7.7663660e-01\n",
      " 3.5925210e-03]\n",
      "index: 25  actual y: 2  answer y: 2  prediction: [6.79154709e-06 1.16696665e-05 9.99904752e-01 2.36236178e-06\n",
      " 1.24990940e-04 5.12817678e-06]\n",
      "index: 26  actual y: 4  answer y: 4  prediction: [1.8980801e-03 3.4087896e-04 4.2119622e-04 2.5542063e-01 7.6531231e-01\n",
      " 1.5952289e-03]\n",
      "index: 27  actual y: 5  answer y: 5  prediction: [9.1217546e-05 2.4166073e-05 3.8203383e-05 7.1171446e-05 9.9172779e-05\n",
      " 9.9973774e-01]\n",
      "index: 28  actual y: 3  answer y: 3  prediction: [1.5953183e-04 5.9512095e-05 1.5106797e-04 9.9928272e-01 9.8940101e-05\n",
      " 6.7185174e-05]\n",
      "index: 29  actual y: 0  answer y: 0  prediction: [9.9999988e-01 2.7739413e-08 1.1643997e-09 8.4284949e-08 3.6876029e-09\n",
      " 8.5181053e-09]\n",
      "index: 30  actual y: 4  answer y: 4  prediction: [3.40998173e-04 1.44720078e-04 2.58210301e-03 6.51913579e-05\n",
      " 9.97862458e-01 1.18977034e-04]\n",
      "index: 31  actual y: 0  answer y: 0  prediction: [9.9174726e-01 2.5546551e-04 1.7940104e-03 7.6594949e-04 7.3662400e-04\n",
      " 1.5100837e-04]\n",
      "index: 32  actual y: 4  answer y: 4  prediction: [2.1631546e-05 2.8903673e-05 1.8052851e-05 5.1163868e-05 9.9988538e-01\n",
      " 2.6046757e-05]\n",
      "index: 33  actual y: 1  answer y: 1  prediction: [3.2134812e-05 9.9920094e-01 4.7540665e-04 1.5681982e-04 1.2573600e-04\n",
      " 4.2684034e-05]\n",
      "index: 34  actual y: 4  answer y: 4  prediction: [6.1690283e-05 5.1382049e-05 8.7978086e-05 1.3259053e-04 9.9950325e-01\n",
      " 2.3049116e-04]\n",
      "index: 35  actual y: 1  answer y: 1  prediction: [2.0185617e-07 9.9999774e-01 6.8351525e-08 2.0444469e-07 2.4758933e-07\n",
      " 1.5522036e-07]\n",
      "index: 36  actual y: 0  answer y: 0  prediction: [9.9879372e-01 5.5101514e-04 8.0003272e-05 2.4673343e-04 4.4417381e-04\n",
      " 6.2642583e-05]\n",
      "index: 37  actual y: 4  answer y: 4  prediction: [1.8694997e-04 3.7801266e-04 3.2660365e-04 1.5074313e-03 9.9493563e-01\n",
      " 3.1597316e-03]\n",
      "index: 38  actual y: 2  answer y: 3  prediction: [0.02146423 0.01610744 0.24263924 0.52467847 0.00330833 0.01754817]\n",
      "index: 39  actual y: 0  answer y: 0  prediction: [4.9302557e-01 1.7217696e-03 4.9591690e-02 4.4324994e-04 1.0692042e-01\n",
      " 1.3271570e-03]\n",
      "index: 40  actual y: 0  answer y: 0  prediction: [9.9998838e-01 3.9538240e-06 1.7976177e-07 6.5149252e-06 5.7978025e-07\n",
      " 2.7276127e-07]\n",
      "index: 41  actual y: 3  answer y: 3  prediction: [1.1990666e-03 1.7237663e-04 5.6347251e-04 9.9524695e-01 6.5984728e-05\n",
      " 9.2160702e-04]\n",
      "index: 42  actual y: 2  answer y: 2  prediction: [3.5698086e-02 1.2265162e-04 6.3302910e-01 2.3972988e-04 1.1762083e-03\n",
      " 6.9155574e-02]\n",
      "index: 43  actual y: 2  answer y: 2  prediction: [1.8587708e-04 2.4694204e-04 9.9836177e-01 4.5201182e-04 8.4304810e-04\n",
      " 1.3577938e-04]\n",
      "index: 44  actual y: 0  answer y: 0  prediction: [9.9677116e-01 5.0170536e-05 8.3763502e-05 5.3661988e-05 7.6836348e-04\n",
      " 2.8511882e-04]\n",
      "index: 45  actual y: 3  answer y: 1  prediction: [0.00060803 0.41561064 0.00151813 0.37214333 0.00355521 0.00218034]\n",
      "index: 46  actual y: 3  answer y: 3  prediction: [4.1016936e-04 3.8301945e-04 5.6597590e-04 9.9792355e-01 1.6731024e-04\n",
      " 2.6342273e-04]\n",
      "index: 47  actual y: 1  answer y: 4  prediction: [0.00463498 0.01797506 0.01324338 0.03103954 0.86271274 0.02639475]\n",
      "index: 48  actual y: 5  answer y: 5  prediction: [6.3607097e-04 9.5009804e-04 2.8724074e-03 2.4654481e-01 1.3579428e-03\n",
      " 6.5872437e-01]\n",
      "index: 49  actual y: 0  answer y: 0  prediction: [9.7421908e-01 5.7627763e-05 1.0672510e-02 1.9538403e-03 1.2776256e-04\n",
      " 9.8556280e-04]\n",
      "index: 50  actual y: 5  answer y: 5  prediction: [1.22044876e-04 1.06262800e-04 2.92181969e-04 1.02022290e-03\n",
      " 8.93265133e-06 9.96554792e-01]\n",
      "index: 51  actual y: 1  answer y: 1  prediction: [2.2098422e-04 9.8993397e-01 3.5488605e-04 1.2159377e-02 3.1116605e-04\n",
      " 1.8584728e-04]\n",
      "index: 52  actual y: 2  answer y: 2  prediction: [8.1865609e-02 2.1290779e-04 9.4842374e-01 9.8112025e-05 2.6204969e-05\n",
      " 6.8514069e-05]\n",
      "index: 53  actual y: 1  answer y: 1  prediction: [6.3315034e-04 8.8355529e-01 5.0830841e-04 7.1671546e-02 1.1512069e-04\n",
      " 6.4989030e-03]\n",
      "index: 54  actual y: 2  answer y: 5  prediction: [5.9083104e-04 3.3849478e-04 2.9977560e-03 4.3767691e-04 1.5233457e-03\n",
      " 9.9128407e-01]\n",
      "index: 55  actual y: 1  answer y: 1  prediction: [0.00512582 0.39959744 0.26215008 0.01800042 0.00461298 0.02982709]\n",
      "index: 56  actual y: 1  answer y: 1  prediction: [0.00370476 0.89600086 0.07074776 0.0089114  0.00924537 0.00466177]\n",
      "index: 57  actual y: 3  answer y: 3  prediction: [7.4278810e-09 2.0987938e-09 5.5860863e-09 1.0000000e+00 1.6865439e-09\n",
      " 2.4851639e-09]\n",
      "index: 58  actual y: 5  answer y: 5  prediction: [1.9682453e-05 3.0040378e-06 2.3822345e-06 2.0941694e-05 3.4275497e-06\n",
      " 9.9996102e-01]\n",
      "index: 59  actual y: 3  answer y: 3  prediction: [5.1950603e-05 4.2272815e-05 4.0408428e-05 9.9327767e-01 5.8836820e-05\n",
      " 6.5874755e-03]\n",
      "index: 60  actual y: 2  answer y: 2  prediction: [1.1611581e-03 1.5041232e-04 9.9851662e-01 2.4469666e-05 1.0630791e-04\n",
      " 3.3815897e-05]\n",
      "index: 61  actual y: 4  answer y: 2  prediction: [5.8664813e-05 6.5412940e-05 9.9976408e-01 4.4116612e-05 1.1992459e-04\n",
      " 1.7106464e-05]\n",
      "index: 62  actual y: 4  answer y: 4  prediction: [4.0535950e-05 1.6938993e-05 1.8528452e-05 9.5419564e-05 9.9987137e-01\n",
      " 2.1110169e-05]\n",
      "index: 63  actual y: 5  answer y: 5  prediction: [2.3010373e-04 2.5084615e-04 1.9088387e-04 2.1911263e-03 3.3634901e-04\n",
      " 9.9722588e-01]\n",
      "index: 64  actual y: 3  answer y: 3  prediction: [4.2624319e-07 3.7572840e-07 2.3753528e-07 9.9999666e-01 4.0340211e-08\n",
      " 7.1466658e-08]\n",
      "index: 65  actual y: 1  answer y: 1  prediction: [4.9733604e-05 9.9934304e-01 4.2608877e-05 5.4852462e-05 1.7181039e-04\n",
      " 1.8972158e-04]\n",
      "index: 66  actual y: 2  answer y: 2  prediction: [6.4960492e-05 4.5734644e-04 9.9945986e-01 5.6722642e-05 2.3606221e-05\n",
      " 6.0498813e-05]\n",
      "index: 67  actual y: 1  answer y: 1  prediction: [5.5930916e-05 9.9927759e-01 1.1958248e-05 3.2027212e-05 1.3761484e-05\n",
      " 4.0465593e-04]\n",
      "index: 68  actual y: 3  answer y: 3  prediction: [1.9269352e-07 6.4385937e-08 1.1060763e-07 9.9999857e-01 4.2477438e-08\n",
      " 6.1948882e-08]\n",
      "index: 69  actual y: 4  answer y: 4  prediction: [1.3255592e-06 3.1107197e-06 9.1327917e-07 5.0253954e-07 9.9999315e-01\n",
      " 2.8073412e-06]\n",
      "index: 70  actual y: 3  answer y: 3  prediction: [1.5444102e-05 5.5373854e-05 3.5302513e-05 9.9971652e-01 2.3167437e-05\n",
      " 1.1242877e-05]\n",
      "index: 71  actual y: 4  answer y: 4  prediction: [3.0524433e-03 2.7628541e-03 8.3152056e-03 5.3164363e-04 9.8072338e-01\n",
      " 4.0861666e-03]\n",
      "index: 72  actual y: 2  answer y: 2  prediction: [1.4618039e-04 5.5252262e-05 9.6412325e-01 1.5212268e-02 8.1115961e-04\n",
      " 1.3846755e-03]\n",
      "index: 73  actual y: 5  answer y: 5  prediction: [1.8820167e-04 1.3044477e-04 3.9508939e-04 4.0253997e-04 1.9928813e-04\n",
      " 9.9840653e-01]\n",
      "index: 74  actual y: 0  answer y: 0  prediction: [9.9997056e-01 5.7416974e-06 4.0176810e-06 9.0470967e-06 4.2938373e-06\n",
      " 1.1324698e-06]\n",
      "index: 75  actual y: 1  answer y: 4  prediction: [5.4303408e-03 5.3593516e-04 6.9113225e-02 1.7315149e-04 9.2095083e-01\n",
      " 1.4492869e-04]\n",
      "index: 76  actual y: 2  answer y: 2  prediction: [4.5957986e-06 1.4436271e-06 9.9998963e-01 1.4132779e-06 1.6525210e-06\n",
      " 7.0424426e-07]\n",
      "index: 77  actual y: 0  answer y: 0  prediction: [9.99858737e-01 3.77123833e-05 1.00649395e-05 8.31030920e-05\n",
      " 9.54987172e-06 1.31986453e-05]\n",
      "index: 78  actual y: 5  answer y: 5  prediction: [7.7226758e-04 1.2961328e-03 1.3172626e-04 1.1118281e-01 3.3310950e-03\n",
      " 8.5714805e-01]\n",
      "index: 79  actual y: 0  answer y: 0  prediction: [9.9535751e-01 2.6792288e-04 4.0054321e-04 1.6716719e-03 4.9743056e-04\n",
      " 1.8331707e-03]\n",
      "index: 80  actual y: 5  answer y: 5  prediction: [2.4636267e-05 1.3380130e-05 7.1698564e-06 6.3504725e-05 1.0846359e-04\n",
      " 9.9982214e-01]\n",
      "index: 81  actual y: 3  answer y: 3  prediction: [0.05252248 0.05428499 0.10706457 0.32413733 0.00226483 0.02572989]\n",
      "index: 82  actual y: 0  answer y: 0  prediction: [9.7760671e-01 3.6293268e-04 1.3745725e-03 2.3829937e-04 3.3462942e-03\n",
      " 1.9586086e-03]\n",
      "index: 83  actual y: 2  answer y: 2  prediction: [7.9315901e-04 4.1948450e-05 9.9908632e-01 1.2761354e-04 2.0735175e-05\n",
      " 8.0314094e-05]\n",
      "index: 84  actual y: 2  answer y: 2  prediction: [3.579557e-04 1.036644e-03 9.732952e-01 5.846414e-05 4.065627e-02\n",
      " 5.909860e-05]\n",
      "index: 85  actual y: 5  answer y: 5  prediction: [3.5691261e-04 2.5036931e-04 1.3360381e-04 4.9933493e-03 2.3877621e-04\n",
      " 9.9578810e-01]\n",
      "index: 86  actual y: 4  answer y: 4  prediction: [3.40998173e-04 1.44720078e-04 2.58216262e-03 6.51913579e-05\n",
      " 9.97862458e-01 1.18977034e-04]\n",
      "index: 87  actual y: 5  answer y: 5  prediction: [4.1061640e-04 8.7150931e-04 8.2436204e-04 6.8607926e-04 2.3871660e-03\n",
      " 9.9501854e-01]\n",
      "index: 88  actual y: 5  answer y: 5  prediction: [4.3243395e-05 1.6376709e-05 8.7078542e-06 5.1564366e-05 9.0365247e-06\n",
      " 9.9990094e-01]\n",
      "index: 89  actual y: 3  answer y: 3  prediction: [6.3848495e-04 2.1797419e-04 7.3966384e-04 9.3614042e-01 5.0640106e-04\n",
      " 5.3150147e-02]\n",
      "index: 90  actual y: 4  answer y: 4  prediction: [5.0911307e-04 1.4394522e-04 4.0772557e-04 4.6613038e-02 9.7078931e-01\n",
      " 6.9233775e-04]\n",
      "index: 91  actual y: 2  answer y: 2  prediction: [3.4865737e-04 7.9432248e-05 9.9875581e-01 4.9161911e-04 1.9538403e-04\n",
      " 2.2831559e-04]\n",
      "index: 92  actual y: 4  answer y: 1  prediction: [2.5796890e-04 5.2673054e-01 1.0978281e-03 3.8635135e-03 4.9289578e-01\n",
      " 5.3885579e-04]\n",
      "index: 93  actual y: 0  answer y: 2  prediction: [1.3754100e-02 3.9346160e-05 9.4097424e-01 2.6214791e-05 4.2328238e-04\n",
      " 1.3906062e-03]\n",
      "index: 94  actual y: 1  answer y: 1  prediction: [3.8846025e-07 9.9999499e-01 5.9313720e-07 5.8512273e-07 4.0179933e-07\n",
      " 3.5641199e-07]\n",
      "index: 95  actual y: 3  answer y: 4  prediction: [0.02262324 0.00442711 0.00687909 0.07225835 0.81429625 0.00714692]\n",
      "index: 96  actual y: 2  answer y: 2  prediction: [2.0727010e-05 2.8791839e-05 9.9985611e-01 3.8313829e-05 4.4070861e-05\n",
      " 1.6601814e-05]\n",
      "index: 97  actual y: 0  answer y: 0  prediction: [9.9998868e-01 2.9052032e-06 1.8904346e-07 9.3623921e-06 5.3527663e-07\n",
      " 1.2698333e-06]\n",
      "index: 98  actual y: 1  answer y: 1  prediction: [3.3695965e-06 9.9996710e-01 2.7749045e-06 6.6537050e-06 3.2014950e-06\n",
      " 4.6821447e-06]\n",
      "index: 99  actual y: 3  answer y: 3  prediction: [1.9019230e-07 5.5529878e-08 1.1461124e-07 9.9999833e-01 5.3936297e-08\n",
      " 4.9551971e-08]\n",
      "index: 100  actual y: 0  answer y: 0  prediction: [9.8956537e-01 3.1641126e-04 5.9235692e-03 7.5813579e-05 5.1873922e-04\n",
      " 8.9058027e-05]\n",
      "index: 101  actual y: 4  answer y: 4  prediction: [9.8738968e-03 1.4861524e-03 4.0403008e-04 6.2507391e-04 9.7529125e-01\n",
      " 6.5368414e-03]\n",
      "index: 102  actual y: 5  answer y: 5  prediction: [1.3726950e-04 1.2834308e-05 2.9278508e-05 1.2333761e-05 2.5749207e-04\n",
      " 9.9951518e-01]\n",
      "index: 103  actual y: 4  answer y: 4  prediction: [2.18434107e-05 1.42287918e-05 1.89350740e-05 7.94953394e-06\n",
      " 9.99957800e-01 1.16216215e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 354ms/step - loss: 0.1273 - accuracy: 0.8942 - precision: 0.9249 - recall: 0.8828 - f1score: 0.9031\n",
      "loss: 0.127, accuracy: 0.894, precision: 0.925, recall: 0.883, f1score: 0.903\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# output = classifier.predict_generator(test_set, steps=1)\n",
    "# print(test_set.class_indices)\n",
    "# print(output)\n",
    "size = y_test[:,-1]\n",
    "print(size.size)\n",
    "\n",
    "\n",
    "# predict 10 random hand-writing data\n",
    "y_predicted = model.predict(x_test)\n",
    "for x in range(0,size.size):\n",
    "    \n",
    "    print(\"index:\", x,\n",
    "          \" actual y:\", np.argmax(y_test[x]),\n",
    "          \" answer y:\", np.argmax(y_predicted[x]),\n",
    "            \" prediction:\", np.array(y_predicted[x]))\n",
    "\n",
    "_loss, _acc, _precision, _recall, _f1score = model.evaluate(x_test, y_test)\n",
    "print('loss: {:.3f}, accuracy: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _precision, _recall, _f1score))\n",
    "# print('loss: ', evaluation[0])\n",
    "# print('accuracy', evaluation[1])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 손실 그래프\n",
    "def plot_loss(history):\n",
    "   # 선 그리기\n",
    "    plt.plot(history.history['loss'], 'y', label='train loss')\n",
    "    plt.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "   # 그래프 제목\n",
    "    plt.title('Model Loss')\n",
    "   # x,y축 이름 표시\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "   # 각 라인 표식 표시\n",
    "    plt.legend(['Train','Validation'],loc=0)\n",
    "\n",
    "# 정확도 그래프\n",
    "def plot_acc(history):\n",
    "  # dir(history.history)\n",
    "    plt.plot(history.history['accuracy'], 'b', label='train accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], 'g', label='val accuracy')\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc=0)\n",
    "\n",
    "plot_loss(history)\n",
    "plt.show()\n",
    "plot_acc(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = [32,64,128,256,512,1024]\n",
    "# learning_rate = [0.00001,0.0001,0.001]\n",
    "# for  batch_size, learning_rate in product(batch_size,learning_rate):\n",
    "#     print(f'batchSIZE is {batch_size}, Learning Rate is {learning_rate}')\n",
    "#     train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "#                                    shear_range = 0.2,\n",
    "#                                    zoom_range = 0.2,\n",
    "#                                    horizontal_flip = True)\n",
    "\n",
    "#     test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "#     categories = ['dog','cat','rabbit','squirrel','deer']\n",
    "\n",
    "#     training_set = train_datagen.flow_from_directory(train_img_dir, target_size=(128,128), \n",
    "#                                                  classes=categories, \n",
    "#                                                  batch_size=batch_size)\n",
    "\n",
    "#     test_set = test_datagen.flow_from_directory(test_img_dir,\n",
    "#                                             target_size=(128,128), \n",
    "#                                             classes=categories, \n",
    "#                                             batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "#     x_train, y_train = next(training_set)\n",
    "#     x_test, y_test = next(test_set)\n",
    "#     model = create_model()\n",
    "#     ## learning rate scheduing\n",
    "#     lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,\n",
    "#                                                               decay_steps=training_epochs*10,\n",
    "#                                                               decay_rate=0.4,\n",
    "#                                                               staircase=True)\n",
    "#     ## optimizer는 Adam, loss는 sparse categorical crossentropy 사용\n",
    "#     ## label이 ont-hot으로 encoding 안 된 경우에 sparse categorical corssentropy 및 sparse categorical accuracy 사용\n",
    "#     model.compile(keras.optimizers.Adam(lr_schedule), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#     ## Train!\n",
    "#     history = model.fit(x_train, y_train, #steps_per_epoch=training_epochs,\n",
    "#          epochs=40, validation_data = (x_val,y_val))\n",
    "#     # output = classifier.predict_generator(test_set, steps=1)\n",
    "#     # print(test_set.class_indices)\n",
    "#     # print(output)\n",
    "#     size = y_test[:,-1]\n",
    "#     print(size.size)\n",
    "\n",
    "\n",
    "#     # predict 10 random hand-writing data\n",
    "#     y_predicted = model.predict(x_test)\n",
    "#     for x in range(0,size.size):\n",
    "\n",
    "#         print(\"index:\", x,\n",
    "#               \" actual y:\", np.argmax(y_test[x]),\n",
    "#               \" answer y:\", np.argmax(y_predicted[x]),\n",
    "#                 \" prediction:\", np.array(y_predicted[x]))\n",
    "\n",
    "#     evaluation = model.evaluate(x_test, y_test)\n",
    "#     print('loss: ', evaluation[0])\n",
    "#     print('accuracy', evaluation[1])\n",
    "\n",
    "#     plot_loss(history)\n",
    "#     plt.show()\n",
    "#     plot_acc(history)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
