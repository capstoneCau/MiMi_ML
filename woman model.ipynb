{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchSIZE is 512, Learning Rate is 0.001\n",
      "Found 676 images belonging to 5 classes.\n",
      "Found 87 images belonging to 5 classes.\n",
      "Found 245 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "import os # miscellaneous operating system interfaces\n",
    "import shutil # high-level file operations\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import decimal\n",
    "import random\n",
    "from itertools import product\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D \n",
    "from keras.layers import MaxPooling2D \n",
    "from keras.layers import Flatten \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.applications import MobileNetV2, ResNet50\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "from keras.layers import  Input, Conv2D, Conv2DTranspose, ReLU,AveragePooling2D, MaxPooling2D, Dense, BatchNormalization, GlobalAveragePooling2D, Concatenate\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "base_dir = r'C:\\Users\\1217s\\Desktop\\capstone deeplearning\\images\\woman'\n",
    "\n",
    "train_img_dir = r'C:\\Users\\1217s\\Desktop\\capstone deeplearning\\images\\woman\\train'\n",
    "\n",
    "test_img_dir = r'C:\\Users\\1217s\\Desktop\\capstone deeplearning\\images\\woman\\test'\n",
    "\n",
    "val_img_dir = r'C:\\Users\\1217s\\Desktop\\capstone deeplearning\\images\\woman\\val'\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "batch_size = 512\n",
    "\n",
    "\n",
    "\n",
    "print(f'batchSIZE is {batch_size}, Learning Rate is {learning_rate}')\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,)\n",
    "#                                shear_range = 0.2,\n",
    "#                                zoom_range = 0.2,\n",
    "#                                horizontal_flip = True)\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "categories = ['dog','cat','rabbit','squirrel','deer']\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(train_img_dir, target_size=(128,128), \n",
    "                                             classes=categories, \n",
    "                                             batch_size=batch_size)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(test_img_dir,\n",
    "                                        target_size=(128,128), \n",
    "                                        classes=categories, \n",
    "                                        batch_size=batch_size)\n",
    "\n",
    "val_set = test_datagen.flow_from_directory(val_img_dir,\n",
    "                                        target_size=(128,128), \n",
    "                                        classes=categories, \n",
    "                                        batch_size=batch_size)\n",
    "\n",
    "x_train, y_train = next(training_set)\n",
    "x_test, y_test = next(test_set)\n",
    "x_val,y_val = next(val_set)   \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = Input(shape=(128, 128, 3))\n",
    "    \n",
    "\n",
    "    conv2_1 = Conv2D(32, 3, 1, 'SAME')(inputs)\n",
    "    conv2_2 = Conv2D(32, 3, 1, 'SAME')(conv2_1)\n",
    "    pool2_3 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv2_2)\n",
    "    br1 = BatchNormalization()(pool2_3)\n",
    "    \n",
    "    conv2_1 = Conv2D(32, 3, 1, 'SAME')(br1)\n",
    "    conv2_2 = Conv2D(32, 3, 1, 'SAME')(conv2_1)\n",
    "    pool2_3 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv2_2)\n",
    "    br1 = BatchNormalization()(pool2_3)\n",
    "    \n",
    "    \n",
    "    conv3_1 = Conv2D(64, 3, 1, 'SAME')(br1)\n",
    "    conv3_2 = Conv2D(64, 3, 1, 'SAME')(conv3_1)\n",
    "    pool3_2 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv3_2)\n",
    "    br2 = BatchNormalization()(pool3_2)\n",
    "    \n",
    "    conv3_1 = Conv2D(64, 3, 1, 'SAME')(br2)\n",
    "    conv3_2 = Conv2D(64, 3, 1, 'SAME')(conv3_1)\n",
    "    pool3_2 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv3_2)\n",
    "    br2 = BatchNormalization()(pool3_2)\n",
    "    \n",
    "    \n",
    "    conv4_1 = Conv2D(128, 3, 1, 'SAME')(br2)\n",
    "    conv4_2 = Conv2D(128, 3, 1, 'SAME')(conv4_1)\n",
    "    pool4_2 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv4_2)\n",
    "    br3 = BatchNormalization()(pool4_2)\n",
    "    \n",
    "    conv4_1 = Conv2D(128, 3, 1, 'SAME')(br3)\n",
    "    conv4_2 = Conv2D(128, 3, 1, 'SAME')(conv4_1)\n",
    "    pool4_2 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv4_2)\n",
    "    br3 = BatchNormalization()(pool4_2)\n",
    "    \n",
    "    flatten1 = Flatten()(pool4_2)\n",
    "    dense1 = Dense(units = 512, activation = 'relu')(flatten1)\n",
    "    dense2 = Dense(units = 1024, activation = 'relu')(dense1)\n",
    "    dr1 = Dropout(0.7)(dense2)\n",
    "    dense3 = Dense(units = 5, activation = 'sigmoid')(dr1)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=dense3) \n",
    "\n",
    "def vgg16():\n",
    "    inputs = Input(shape=(128, 128, 3))\n",
    "    \n",
    "\n",
    "    conv1_1 = Conv2D(3, 3, 1, 'SAME',activation = 'relu')(inputs)\n",
    "    conv1_2 = Conv2D(64, 3, 1, 'SAME',activation = 'relu')(conv1_1)\n",
    "    conv1_3 = Conv2D(64, 3, 1, 'SAME',activation = 'relu')(conv1_2)\n",
    "    pool1 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv1_3)\n",
    "    \n",
    "    conv2_1 = Conv2D(128, 3, 1, 'SAME',activation = 'relu')(pool1)\n",
    "    conv2_2 = Conv2D(128, 3, 1, 'SAME',activation = 'relu')(conv2_1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv2_2)\n",
    "    \n",
    "    \n",
    "    conv3_1 = Conv2D(256, 3, 1, 'SAME',activation = 'relu')(pool2)\n",
    "    conv3_2 = Conv2D(256, 3, 1, 'SAME',activation = 'relu')(conv3_1)\n",
    "    conv3_3 = Conv2D(256, 3, 1, 'SAME',activation = 'relu')(conv3_2)\n",
    "    pool3 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv3_3)\n",
    "\n",
    "    \n",
    "    conv4_1 = Conv2D(512, 3, 1, 'SAME',activation = 'relu')(pool3)\n",
    "    conv4_2 = Conv2D(512, 3, 1, 'SAME',activation = 'relu')(conv4_1)\n",
    "    conv4_3 = Conv2D(512, 3, 1, 'SAME',activation = 'relu')(conv4_2)\n",
    "    pool4 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv4_3)\n",
    "    \n",
    "    conv5_1 = Conv2D(512, 3, 1, 'SAME',activation = 'relu')(pool4)\n",
    "    conv5_2 = Conv2D(512, 3, 1, 'SAME',activation = 'relu')(conv5_1)\n",
    "    conv5_3 = Conv2D(512, 3, 1, 'SAME',activation = 'relu')(conv5_2)\n",
    "    pool5 = MaxPooling2D(pool_size=(2,2),padding='SAME')(conv5_3)\n",
    "    \n",
    "    flatten1 = Flatten()(pool5)\n",
    "    dense1 = Dense(units = 4096)(flatten1)\n",
    "    dense2 = Dense(units = 4096)(dense1)\n",
    "    dense3 = Dense(units = 5, activation = 'sigmoid')(dense2)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=dense3) \n",
    "\n",
    "def mobile_net():\n",
    "    inputs = Input(shape=(128, 128, 3))\n",
    "    mobileNet = MobileNetV2(weights = \"imagenet\", include_top=False,input_shape = (128,128,3)\n",
    "                            ,input_tensor = inputs)\n",
    "#     for layer in mobileNet.layers:\n",
    "#         layer.trainable = True\n",
    "        \n",
    "    output = mobileNet.output\n",
    "    pooling = AveragePooling2D(pool_size=(4,4),padding='SAME')(output)\n",
    "    \n",
    "    flatten1 = Flatten()(pooling)\n",
    "    dense1 = Dense(units = 512, activation = 'relu')(flatten1)\n",
    "    dense2 = Dense(units = 1024, activation = 'relu')(dense1)\n",
    "    dr1 = Dropout(0.7)(dense2)\n",
    "    dense3 = Dense(units = 5, activation = 'sigmoid')(dr1)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=dense3)\n",
    "\n",
    "def resnet50():\n",
    "    inputs = Input(shape=(128, 128, 3))\n",
    "    resnet = ResNet50(weights = \"imagenet\", include_top=False,input_shape = (128,128,3)\n",
    "                            ,input_tensor = inputs)\n",
    "   \n",
    "    output = resnet.output\n",
    "    pooling = AveragePooling2D(pool_size=(4,4),padding='SAME')(output)\n",
    "    \n",
    "    flatten1 = Flatten()(pooling)\n",
    "    dense1 = Dense(units = 512, activation = 'relu')(flatten1)\n",
    "    dense2 = Dense(units = 1024, activation = 'relu')(dense1)\n",
    "    dr1 = Dropout(0.7)(dense2)\n",
    "    dense3 = Dense(units = 5, activation = 'sigmoid')(dr1)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=dense3)\n",
    "\n",
    "class ResidualUnit(tf.keras.Model):\n",
    "    def __init__(self, filter_in, filter_out, kernel_size):\n",
    "        super(ResidualUnit, self).__init__()\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filter_out, kernel_size, padding='same')\n",
    "        \n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filter_out, kernel_size, padding='same')\n",
    "        \n",
    "        if filter_in == filter_out:\n",
    "            self.identity = lambda x: x\n",
    "        else:\n",
    "            self.identity = tf.keras.layers.Conv2D(filter_out, (1,1), padding='same')\n",
    "\n",
    "    def call(self, x, training=False, mask=None):\n",
    "        h = self.bn1(x, training=training)\n",
    "        h = tf.nn.relu(h)\n",
    "        h = self.conv1(h)\n",
    "        \n",
    "        h = self.bn2(h, training=training)\n",
    "        h = tf.nn.relu(h)\n",
    "        h = self.conv2(h)\n",
    "        return self.identity(x) + h\n",
    "    \n",
    "class ResnetLayer(tf.keras.Model):\n",
    "    def __init__(self, filter_in, filters, kernel_size):\n",
    "        super(ResnetLayer, self).__init__()\n",
    "        self.sequence = list()\n",
    "        for f_in, f_out in zip([filter_in] + list(filters), filters):\n",
    "            self.sequence.append(ResidualUnit(f_in, f_out, kernel_size))\n",
    "\n",
    "    def call(self, x, training=False, mask=None):\n",
    "        for unit in self.sequence:\n",
    "            x = unit(x, training=training)\n",
    "        return x\n",
    "    \n",
    "class ResNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu') # 28x28x8\n",
    "        \n",
    "        self.res1 = ResnetLayer(64, (16, 16), (3, 3)) # 28x28x16\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D((2, 2)) # 14x14x16\n",
    "        \n",
    "        self.res2 = ResnetLayer(128, (32, 32), (3, 3)) # 14x14x32\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D((2, 2)) # 7x7x32\n",
    "        \n",
    "        \n",
    "        self.res3 = ResnetLayer(256, (64, 64), (3, 3)) # 7x7x64\n",
    "        self.pool = tf.keras.layers.MaxPool2D((2, 2)) # 7x7x32\n",
    "\n",
    "        \n",
    "        self.res4 = ResnetLayer(512, (64, 64), (3, 3)) # 7x7x64\n",
    "        self.pool = tf.keras.layers.MaxPool2D((2, 2)) # 7x7x32\n",
    "\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = Dense(units = 1024, activation = 'relu')\n",
    "        self.dense2 = Dense(units = 1024, activation = 'relu')\n",
    "        self.dense3 = tf.keras.layers.Dense(5, activation='softmax')\n",
    "        \n",
    "    def call(self, x, training=False, mask=None):\n",
    "        x = self.conv1(x)\n",
    "        x = self.res1(x, training=training)\n",
    "        x = self.pool1(x)\n",
    "        x = self.res2(x, training=training)\n",
    "        x = self.pool2(x)\n",
    "        x = self.res3(x, training=training)\n",
    "        x = self.pool2(x)\n",
    "        x = self.res4(x, training=training)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "20/20 [==============================] - 16s 813ms/step - loss: 0.5346 - accuracy: 0.3262 - precision: 0.4255 - recall: 0.1517 - f1score: 0.1971 - val_loss: 0.8657 - val_accuracy: 0.1959 - val_precision: 0.3435 - val_recall: 0.0586 - val_f1score: 0.0993\n",
      "Epoch 2/150\n",
      "20/20 [==============================] - 16s 775ms/step - loss: 0.3449 - accuracy: 0.6055 - precision: 0.6802 - recall: 0.5259 - f1score: 0.5877 - val_loss: 1.0364 - val_accuracy: 0.3143 - val_precision: 0.4700 - val_recall: 0.1291 - val_f1score: 0.2009\n",
      "Epoch 3/150\n",
      "20/20 [==============================] - 16s 800ms/step - loss: 0.1828 - accuracy: 0.8379 - precision: 0.8480 - recall: 0.7889 - f1score: 0.8165 - val_loss: 0.9316 - val_accuracy: 0.3429 - val_precision: 0.5089 - val_recall: 0.1388 - val_f1score: 0.2148\n",
      "Epoch 4/150\n",
      "20/20 [==============================] - 16s 808ms/step - loss: 0.2230 - accuracy: 0.8164 - precision: 0.8275 - recall: 0.7793 - f1score: 0.8017 - val_loss: 1.1276 - val_accuracy: 0.2980 - val_precision: 0.3446 - val_recall: 0.2228 - val_f1score: 0.2700\n",
      "Epoch 5/150\n",
      "20/20 [==============================] - 16s 822ms/step - loss: 0.2139 - accuracy: 0.8242 - precision: 0.8555 - recall: 0.7652 - f1score: 0.8069 - val_loss: 3.2766 - val_accuracy: 0.1796 - val_precision: 0.1755 - val_recall: 0.1739 - val_f1score: 0.1747\n",
      "Epoch 6/150\n",
      "20/20 [==============================] - 16s 783ms/step - loss: 0.1854 - accuracy: 0.8457 - precision: 0.8531 - recall: 0.8162 - f1score: 0.8329 - val_loss: 2.1983 - val_accuracy: 0.2980 - val_precision: 0.3417 - val_recall: 0.2638 - val_f1score: 0.2974\n",
      "Epoch 7/150\n",
      "20/20 [==============================] - 16s 784ms/step - loss: 0.1565 - accuracy: 0.8652 - precision: 0.8811 - recall: 0.8436 - f1score: 0.8614 - val_loss: 1.5352 - val_accuracy: 0.3551 - val_precision: 0.3969 - val_recall: 0.2504 - val_f1score: 0.3052\n",
      "Epoch 8/150\n",
      "20/20 [==============================] - 16s 784ms/step - loss: 0.0989 - accuracy: 0.9277 - precision: 0.9310 - recall: 0.9098 - f1score: 0.9198 - val_loss: 2.7086 - val_accuracy: 0.3184 - val_precision: 0.3089 - val_recall: 0.2520 - val_f1score: 0.2774\n",
      "Epoch 9/150\n",
      "20/20 [==============================] - 16s 779ms/step - loss: 0.1024 - accuracy: 0.9160 - precision: 0.9257 - recall: 0.9088 - f1score: 0.9169 - val_loss: 3.5448 - val_accuracy: 0.3184 - val_precision: 0.3023 - val_recall: 0.3127 - val_f1score: 0.3073\n",
      "Epoch 10/150\n",
      "20/20 [==============================] - 16s 779ms/step - loss: 0.0620 - accuracy: 0.9492 - precision: 0.9568 - recall: 0.9308 - f1score: 0.9432 - val_loss: 2.7661 - val_accuracy: 0.3673 - val_precision: 0.3620 - val_recall: 0.3478 - val_f1score: 0.3546\n",
      "Epoch 11/150\n",
      "20/20 [==============================] - 16s 780ms/step - loss: 0.0425 - accuracy: 0.9648 - precision: 0.9655 - recall: 0.9607 - f1score: 0.9630 - val_loss: 3.4694 - val_accuracy: 0.3592 - val_precision: 0.3523 - val_recall: 0.3478 - val_f1score: 0.3500\n",
      "Epoch 12/150\n",
      "20/20 [==============================] - 16s 780ms/step - loss: 0.0150 - accuracy: 0.9922 - precision: 0.9942 - recall: 0.9885 - f1score: 0.9912 - val_loss: 1.9058 - val_accuracy: 0.4694 - val_precision: 0.4746 - val_recall: 0.4262 - val_f1score: 0.4488\n",
      "Epoch 13/150\n",
      "20/20 [==============================] - 16s 786ms/step - loss: 0.0180 - accuracy: 0.9844 - precision: 0.9838 - recall: 0.9857 - f1score: 0.9847 - val_loss: 3.0137 - val_accuracy: 0.3184 - val_precision: 0.3203 - val_recall: 0.3166 - val_f1score: 0.3184\n",
      "Epoch 14/150\n",
      "20/20 [==============================] - 16s 781ms/step - loss: 0.0148 - accuracy: 0.9902 - precision: 0.9895 - recall: 0.9895 - f1score: 0.9895 - val_loss: 3.0157 - val_accuracy: 0.3714 - val_precision: 0.3592 - val_recall: 0.3579 - val_f1score: 0.3584\n",
      "Epoch 15/150\n",
      "20/20 [==============================] - 16s 783ms/step - loss: 0.0129 - accuracy: 0.9902 - precision: 0.9926 - recall: 0.9942 - f1score: 0.9933 - val_loss: 1.8906 - val_accuracy: 0.5143 - val_precision: 0.5311 - val_recall: 0.4987 - val_f1score: 0.5136\n",
      "Epoch 16/150\n",
      "20/20 [==============================] - 16s 778ms/step - loss: 0.0056 - accuracy: 0.9961 - precision: 0.9981 - recall: 0.9962 - f1score: 0.9971 - val_loss: 2.0667 - val_accuracy: 0.5143 - val_precision: 0.5262 - val_recall: 0.4909 - val_f1score: 0.5072\n",
      "Epoch 17/150\n",
      "20/20 [==============================] - 16s 781ms/step - loss: 0.0081 - accuracy: 0.9941 - precision: 0.9934 - recall: 0.9915 - f1score: 0.9924 - val_loss: 1.3911 - val_accuracy: 0.5959 - val_precision: 0.6077 - val_recall: 0.5791 - val_f1score: 0.5926\n",
      "Epoch 18/150\n",
      "20/20 [==============================] - 16s 781ms/step - loss: 0.0236 - accuracy: 0.9805 - precision: 0.9835 - recall: 0.9780 - f1score: 0.9807 - val_loss: 2.8754 - val_accuracy: 0.4776 - val_precision: 0.4953 - val_recall: 0.4695 - val_f1score: 0.4818\n",
      "Epoch 19/150\n",
      "20/20 [==============================] - 16s 782ms/step - loss: 0.0469 - accuracy: 0.9746 - precision: 0.9741 - recall: 0.9741 - f1score: 0.9741 - val_loss: 2.7714 - val_accuracy: 0.4612 - val_precision: 0.4641 - val_recall: 0.4187 - val_f1score: 0.4401\n",
      "Epoch 20/150\n",
      "20/20 [==============================] - 16s 781ms/step - loss: 0.0089 - accuracy: 0.9941 - precision: 0.9943 - recall: 0.9923 - f1score: 0.9932 - val_loss: 1.9690 - val_accuracy: 0.5306 - val_precision: 0.5411 - val_recall: 0.5126 - val_f1score: 0.5262\n",
      "Epoch 21/150\n",
      "20/20 [==============================] - 16s 776ms/step - loss: 0.0077 - accuracy: 0.9941 - precision: 0.9942 - recall: 0.9942 - f1score: 0.9942 - val_loss: 1.8827 - val_accuracy: 0.5347 - val_precision: 0.5444 - val_recall: 0.5145 - val_f1score: 0.5288\n",
      "Epoch 22/150\n",
      "20/20 [==============================] - 16s 782ms/step - loss: 0.0023 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 1.8341 - val_accuracy: 0.5551 - val_precision: 0.5636 - val_recall: 0.5262 - val_f1score: 0.5442\n",
      "Epoch 23/150\n",
      "20/20 [==============================] - 16s 780ms/step - loss: 0.0061 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 1.7574 - val_accuracy: 0.5592 - val_precision: 0.5679 - val_recall: 0.5400 - val_f1score: 0.5535\n",
      "Epoch 24/150\n",
      "20/20 [==============================] - 16s 783ms/step - loss: 0.0035 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 1.6517 - val_accuracy: 0.5469 - val_precision: 0.5596 - val_recall: 0.5246 - val_f1score: 0.5411\n",
      "Epoch 25/150\n",
      "20/20 [==============================] - 16s 780ms/step - loss: 0.0035 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 1.4249 - val_accuracy: 0.5755 - val_precision: 0.6133 - val_recall: 0.5716 - val_f1score: 0.5915\n",
      "Epoch 26/150\n",
      "20/20 [==============================] - 16s 783ms/step - loss: 0.0095 - accuracy: 0.9922 - precision: 0.9907 - recall: 0.9942 - f1score: 0.9924 - val_loss: 1.7929 - val_accuracy: 0.5469 - val_precision: 0.5725 - val_recall: 0.5404 - val_f1score: 0.5557\n",
      "Epoch 27/150\n",
      "20/20 [==============================] - 16s 779ms/step - loss: 0.0098 - accuracy: 0.9941 - precision: 0.9922 - recall: 0.9897 - f1score: 0.9909 - val_loss: 1.8183 - val_accuracy: 0.5469 - val_precision: 0.5777 - val_recall: 0.5482 - val_f1score: 0.5622\n",
      "Epoch 28/150\n",
      "20/20 [==============================] - 16s 783ms/step - loss: 0.0030 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9962 - f1score: 0.9971 - val_loss: 1.6710 - val_accuracy: 0.5878 - val_precision: 0.5947 - val_recall: 0.5636 - val_f1score: 0.5785\n",
      "Epoch 29/150\n",
      "20/20 [==============================] - 16s 778ms/step - loss: 0.0058 - accuracy: 0.9941 - precision: 0.9942 - recall: 0.9923 - f1score: 0.9933 - val_loss: 1.5937 - val_accuracy: 0.5918 - val_precision: 0.6115 - val_recall: 0.5794 - val_f1score: 0.5947\n",
      "Epoch 30/150\n",
      "20/20 [==============================] - 16s 778ms/step - loss: 0.0164 - accuracy: 0.9941 - precision: 0.9898 - recall: 0.9917 - f1score: 0.9907 - val_loss: 1.6389 - val_accuracy: 0.5796 - val_precision: 0.5964 - val_recall: 0.5638 - val_f1score: 0.5795\n",
      "Epoch 31/150\n",
      "20/20 [==============================] - 16s 777ms/step - loss: 0.0014 - accuracy: 1.0000 - precision: 0.9981 - recall: 1.0000 - f1score: 0.9991 - val_loss: 1.6379 - val_accuracy: 0.5633 - val_precision: 0.5857 - val_recall: 0.5599 - val_f1score: 0.5723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/150\n",
      "20/20 [==============================] - 16s 779ms/step - loss: 0.0016 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 1.6019 - val_accuracy: 0.5796 - val_precision: 0.5890 - val_recall: 0.5755 - val_f1score: 0.5820\n",
      "Epoch 33/150\n",
      "20/20 [==============================] - 16s 781ms/step - loss: 0.0017 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 1.5659 - val_accuracy: 0.5878 - val_precision: 0.5902 - val_recall: 0.5716 - val_f1score: 0.5805\n",
      "Epoch 34/150\n",
      "20/20 [==============================] - 16s 777ms/step - loss: 0.0013 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 1.5491 - val_accuracy: 0.5837 - val_precision: 0.5834 - val_recall: 0.5677 - val_f1score: 0.5753\n",
      "Epoch 35/150\n",
      "20/20 [==============================] - 16s 782ms/step - loss: 0.0013 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 1.5333 - val_accuracy: 0.5837 - val_precision: 0.5927 - val_recall: 0.5716 - val_f1score: 0.5817\n",
      "Epoch 36/150\n",
      "20/20 [==============================] - 16s 785ms/step - loss: 0.0019 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9981 - f1score: 0.9990 - val_loss: 1.4801 - val_accuracy: 0.5918 - val_precision: 0.5979 - val_recall: 0.5833 - val_f1score: 0.5904\n",
      "Epoch 37/150\n",
      "20/20 [==============================] - 16s 789ms/step - loss: 0.0011 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 1.4304 - val_accuracy: 0.5918 - val_precision: 0.6059 - val_recall: 0.5911 - val_f1score: 0.5984\n",
      "Epoch 38/150\n",
      "20/20 [==============================] - 16s 806ms/step - loss: 0.0011 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 1.3573 - val_accuracy: 0.5959 - val_precision: 0.6049 - val_recall: 0.5951 - val_f1score: 0.5999\n",
      "Epoch 39/150\n",
      "20/20 [==============================] - 16s 796ms/step - loss: 0.0015 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 1.3014 - val_accuracy: 0.6122 - val_precision: 0.6244 - val_recall: 0.6068 - val_f1score: 0.6153\n",
      "Epoch 40/150\n",
      "20/20 [==============================] - 16s 781ms/step - loss: 5.3196e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 1.2545 - val_accuracy: 0.6082 - val_precision: 0.6317 - val_recall: 0.6185 - val_f1score: 0.6248\n",
      "Epoch 41/150\n",
      "20/20 [==============================] - 15s 769ms/step - loss: 8.2328e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 1.2133 - val_accuracy: 0.6327 - val_precision: 0.6440 - val_recall: 0.6362 - val_f1score: 0.6396\n",
      "Epoch 42/150\n",
      "20/20 [==============================] - 15s 768ms/step - loss: 0.0012 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 1.1498 - val_accuracy: 0.6449 - val_precision: 0.6584 - val_recall: 0.6479 - val_f1score: 0.6528\n",
      "Epoch 43/150\n",
      "20/20 [==============================] - 15s 763ms/step - loss: 0.0019 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 1.1040 - val_accuracy: 0.6694 - val_precision: 0.6856 - val_recall: 0.6654 - val_f1score: 0.6752\n",
      "Epoch 44/150\n",
      "20/20 [==============================] - 15s 762ms/step - loss: 0.0095 - accuracy: 0.9922 - precision: 0.9907 - recall: 0.9942 - f1score: 0.9924 - val_loss: 1.0720 - val_accuracy: 0.6816 - val_precision: 0.6861 - val_recall: 0.6615 - val_f1score: 0.6733\n",
      "Epoch 45/150\n",
      "20/20 [==============================] - 15s 761ms/step - loss: 0.0013 - accuracy: 0.9980 - precision: 1.0000 - recall: 0.9972 - f1score: 0.9986 - val_loss: 1.0569 - val_accuracy: 0.6898 - val_precision: 0.6865 - val_recall: 0.6693 - val_f1score: 0.6776\n",
      "Epoch 46/150\n",
      "20/20 [==============================] - 15s 762ms/step - loss: 0.0012 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 1.0191 - val_accuracy: 0.6939 - val_precision: 0.7009 - val_recall: 0.6791 - val_f1score: 0.6897\n",
      "Epoch 47/150\n",
      "20/20 [==============================] - 15s 762ms/step - loss: 0.0013 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.9952 - val_accuracy: 0.6980 - val_precision: 0.7031 - val_recall: 0.6830 - val_f1score: 0.6926\n",
      "Epoch 48/150\n",
      "20/20 [==============================] - 15s 763ms/step - loss: 0.0015 - accuracy: 1.0000 - precision: 0.9974 - recall: 1.0000 - f1score: 0.9986 - val_loss: 0.9689 - val_accuracy: 0.6980 - val_precision: 0.7021 - val_recall: 0.6908 - val_f1score: 0.6962\n",
      "Epoch 49/150\n",
      "20/20 [==============================] - 15s 763ms/step - loss: 5.4782e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.9415 - val_accuracy: 0.7020 - val_precision: 0.7038 - val_recall: 0.6888 - val_f1score: 0.6960\n",
      "Epoch 50/150\n",
      "20/20 [==============================] - 15s 765ms/step - loss: 0.0011 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.9122 - val_accuracy: 0.7061 - val_precision: 0.7165 - val_recall: 0.6927 - val_f1score: 0.7040\n",
      "Epoch 51/150\n",
      "20/20 [==============================] - 15s 763ms/step - loss: 5.5760e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.8914 - val_accuracy: 0.7061 - val_precision: 0.7220 - val_recall: 0.6927 - val_f1score: 0.7068\n",
      "Epoch 52/150\n",
      "20/20 [==============================] - 15s 764ms/step - loss: 6.1852e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.8699 - val_accuracy: 0.7061 - val_precision: 0.7197 - val_recall: 0.6927 - val_f1score: 0.7056\n",
      "Epoch 53/150\n",
      "20/20 [==============================] - 15s 762ms/step - loss: 5.9050e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.8496 - val_accuracy: 0.7184 - val_precision: 0.7169 - val_recall: 0.6927 - val_f1score: 0.7043\n",
      "Epoch 54/150\n",
      "20/20 [==============================] - 15s 768ms/step - loss: 9.1764e-04 - accuracy: 1.0000 - precision: 0.9974 - recall: 1.0000 - f1score: 0.9986 - val_loss: 0.8305 - val_accuracy: 0.7143 - val_precision: 0.7221 - val_recall: 0.7026 - val_f1score: 0.7120\n",
      "Epoch 55/150\n",
      "20/20 [==============================] - 15s 764ms/step - loss: 5.9270e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.8127 - val_accuracy: 0.7102 - val_precision: 0.7316 - val_recall: 0.7026 - val_f1score: 0.7165\n",
      "Epoch 56/150\n",
      "20/20 [==============================] - 15s 762ms/step - loss: 0.0052 - accuracy: 0.9961 - precision: 0.9945 - recall: 0.9981 - f1score: 0.9962 - val_loss: 0.7945 - val_accuracy: 0.7102 - val_precision: 0.7299 - val_recall: 0.6987 - val_f1score: 0.7138\n",
      "Epoch 57/150\n",
      "20/20 [==============================] - 15s 771ms/step - loss: 8.0197e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9981 - f1score: 0.9990 - val_loss: 0.7757 - val_accuracy: 0.7184 - val_precision: 0.7350 - val_recall: 0.7065 - val_f1score: 0.7202\n",
      "Epoch 58/150\n",
      "20/20 [==============================] - 15s 759ms/step - loss: 0.0014 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.7608 - val_accuracy: 0.7184 - val_precision: 0.7395 - val_recall: 0.7143 - val_f1score: 0.7265\n",
      "Epoch 59/150\n",
      "20/20 [==============================] - 15s 763ms/step - loss: 0.0018 - accuracy: 0.9980 - precision: 1.0000 - recall: 0.9981 - f1score: 0.9990 - val_loss: 0.7449 - val_accuracy: 0.7224 - val_precision: 0.7427 - val_recall: 0.7143 - val_f1score: 0.7279\n",
      "Epoch 60/150\n",
      "20/20 [==============================] - 16s 804ms/step - loss: 8.5103e-04 - accuracy: 1.0000 - precision: 0.9981 - recall: 1.0000 - f1score: 0.9991 - val_loss: 0.7275 - val_accuracy: 0.7265 - val_precision: 0.7399 - val_recall: 0.7143 - val_f1score: 0.7266\n",
      "Epoch 61/150\n",
      "20/20 [==============================] - 15s 763ms/step - loss: 3.2219e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.7128 - val_accuracy: 0.7306 - val_precision: 0.7458 - val_recall: 0.7143 - val_f1score: 0.7293\n",
      "Epoch 62/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 15s 764ms/step - loss: 0.0018 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 0.6977 - val_accuracy: 0.7306 - val_precision: 0.7443 - val_recall: 0.7182 - val_f1score: 0.7307\n",
      "Epoch 63/150\n",
      "20/20 [==============================] - 15s 763ms/step - loss: 4.7304e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.6834 - val_accuracy: 0.7388 - val_precision: 0.7386 - val_recall: 0.7143 - val_f1score: 0.7257\n",
      "Epoch 64/150\n",
      "20/20 [==============================] - 15s 765ms/step - loss: 0.0028 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 0.6708 - val_accuracy: 0.7388 - val_precision: 0.7396 - val_recall: 0.7182 - val_f1score: 0.7281\n",
      "Epoch 65/150\n",
      "20/20 [==============================] - 15s 761ms/step - loss: 2.2345e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.6592 - val_accuracy: 0.7347 - val_precision: 0.7421 - val_recall: 0.7182 - val_f1score: 0.7295\n",
      "Epoch 66/150\n",
      "20/20 [==============================] - 15s 765ms/step - loss: 6.1047e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.6474 - val_accuracy: 0.7388 - val_precision: 0.7443 - val_recall: 0.7182 - val_f1score: 0.7306\n",
      "Epoch 67/150\n",
      "20/20 [==============================] - 15s 763ms/step - loss: 0.0036 - accuracy: 0.9941 - precision: 0.9903 - recall: 0.9944 - f1score: 0.9923 - val_loss: 0.6353 - val_accuracy: 0.7388 - val_precision: 0.7511 - val_recall: 0.7221 - val_f1score: 0.7361\n",
      "Epoch 68/150\n",
      "20/20 [==============================] - 15s 760ms/step - loss: 3.6051e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.6192 - val_accuracy: 0.7388 - val_precision: 0.7540 - val_recall: 0.7221 - val_f1score: 0.7375\n",
      "Epoch 69/150\n",
      "20/20 [==============================] - 15s 760ms/step - loss: 0.0038 - accuracy: 0.9980 - precision: 0.9962 - recall: 0.9962 - f1score: 0.9962 - val_loss: 0.6081 - val_accuracy: 0.7429 - val_precision: 0.7549 - val_recall: 0.7221 - val_f1score: 0.7379\n",
      "Epoch 70/150\n",
      "20/20 [==============================] - 15s 764ms/step - loss: 4.4330e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.5972 - val_accuracy: 0.7469 - val_precision: 0.7611 - val_recall: 0.7320 - val_f1score: 0.7459\n",
      "Epoch 71/150\n",
      "20/20 [==============================] - 15s 761ms/step - loss: 0.0043 - accuracy: 0.9961 - precision: 0.9962 - recall: 0.9962 - f1score: 0.9962 - val_loss: 0.5905 - val_accuracy: 0.7551 - val_precision: 0.7599 - val_recall: 0.7398 - val_f1score: 0.7494\n",
      "Epoch 72/150\n",
      "20/20 [==============================] - 15s 764ms/step - loss: 0.0028 - accuracy: 0.9980 - precision: 0.9954 - recall: 0.9972 - f1score: 0.9963 - val_loss: 0.5838 - val_accuracy: 0.7592 - val_precision: 0.7652 - val_recall: 0.7437 - val_f1score: 0.7539\n",
      "Epoch 73/150\n",
      "20/20 [==============================] - 15s 762ms/step - loss: 4.1093e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.5725 - val_accuracy: 0.7633 - val_precision: 0.7688 - val_recall: 0.7437 - val_f1score: 0.7555\n",
      "Epoch 74/150\n",
      "20/20 [==============================] - 15s 764ms/step - loss: 0.0043 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 0.5637 - val_accuracy: 0.7551 - val_precision: 0.7757 - val_recall: 0.7554 - val_f1score: 0.7650\n",
      "Epoch 75/150\n",
      "20/20 [==============================] - 15s 762ms/step - loss: 0.0069 - accuracy: 0.9961 - precision: 0.9962 - recall: 0.9962 - f1score: 0.9962 - val_loss: 0.5556 - val_accuracy: 0.7510 - val_precision: 0.7757 - val_recall: 0.7554 - val_f1score: 0.7650\n",
      "Epoch 76/150\n",
      "20/20 [==============================] - 15s 761ms/step - loss: 0.0013 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.5482 - val_accuracy: 0.7469 - val_precision: 0.7776 - val_recall: 0.7515 - val_f1score: 0.7640\n",
      "Epoch 77/150\n",
      "20/20 [==============================] - 15s 763ms/step - loss: 3.3112e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.5409 - val_accuracy: 0.7469 - val_precision: 0.7820 - val_recall: 0.7476 - val_f1score: 0.7642\n",
      "Epoch 78/150\n",
      "20/20 [==============================] - 15s 761ms/step - loss: 5.3347e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.5339 - val_accuracy: 0.7510 - val_precision: 0.7791 - val_recall: 0.7398 - val_f1score: 0.7588\n",
      "Epoch 79/150\n",
      "20/20 [==============================] - 15s 762ms/step - loss: 4.0082e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.5268 - val_accuracy: 0.7510 - val_precision: 0.7740 - val_recall: 0.7359 - val_f1score: 0.7544\n",
      "Epoch 80/150\n",
      "20/20 [==============================] - 15s 760ms/step - loss: 0.0011 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.5196 - val_accuracy: 0.7510 - val_precision: 0.7749 - val_recall: 0.7398 - val_f1score: 0.7568\n",
      "Epoch 81/150\n",
      "20/20 [==============================] - 15s 762ms/step - loss: 0.0022 - accuracy: 1.0000 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 0.5140 - val_accuracy: 0.7510 - val_precision: 0.7757 - val_recall: 0.7437 - val_f1score: 0.7591\n",
      "Epoch 82/150\n",
      "20/20 [==============================] - 15s 761ms/step - loss: 3.5242e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.7673 - val_precision: 0.7807 - val_recall: 0.7398 - val_f1score: 0.7593\n",
      "Epoch 83/150\n",
      "20/20 [==============================] - 15s 761ms/step - loss: 0.0011 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.5021 - val_accuracy: 0.7714 - val_precision: 0.7873 - val_recall: 0.7457 - val_f1score: 0.7656\n",
      "Epoch 84/150\n",
      "20/20 [==============================] - 15s 759ms/step - loss: 0.0011 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4962 - val_accuracy: 0.7714 - val_precision: 0.7834 - val_recall: 0.7457 - val_f1score: 0.7638\n",
      "Epoch 85/150\n",
      "20/20 [==============================] - 16s 778ms/step - loss: 4.6022e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4902 - val_accuracy: 0.7755 - val_precision: 0.7882 - val_recall: 0.7496 - val_f1score: 0.7682\n",
      "Epoch 86/150\n",
      "20/20 [==============================] - 15s 771ms/step - loss: 8.3740e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9981 - f1score: 0.9990 - val_loss: 0.4845 - val_accuracy: 0.7755 - val_precision: 0.7887 - val_recall: 0.7535 - val_f1score: 0.7704\n",
      "Epoch 87/150\n",
      "20/20 [==============================] - 15s 763ms/step - loss: 4.7101e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4791 - val_accuracy: 0.7796 - val_precision: 0.7894 - val_recall: 0.7595 - val_f1score: 0.7739\n",
      "Epoch 88/150\n",
      "20/20 [==============================] - 15s 761ms/step - loss: 4.8862e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4738 - val_accuracy: 0.7796 - val_precision: 0.7927 - val_recall: 0.7595 - val_f1score: 0.7755\n",
      "Epoch 89/150\n",
      "20/20 [==============================] - 15s 763ms/step - loss: 0.0012 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 0.4693 - val_accuracy: 0.7755 - val_precision: 0.7950 - val_recall: 0.7595 - val_f1score: 0.7766\n",
      "Epoch 90/150\n",
      "20/20 [==============================] - 15s 763ms/step - loss: 3.7819e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4646 - val_accuracy: 0.7755 - val_precision: 0.7950 - val_recall: 0.7595 - val_f1score: 0.7766\n",
      "Epoch 91/150\n",
      "20/20 [==============================] - 15s 762ms/step - loss: 2.9546e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4598 - val_accuracy: 0.7755 - val_precision: 0.7950 - val_recall: 0.7595 - val_f1score: 0.7766\n",
      "Epoch 92/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 15s 763ms/step - loss: 6.8525e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4553 - val_accuracy: 0.7755 - val_precision: 0.7974 - val_recall: 0.7595 - val_f1score: 0.7778\n",
      "Epoch 93/150\n",
      "20/20 [==============================] - 16s 784ms/step - loss: 4.3283e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4508 - val_accuracy: 0.7755 - val_precision: 0.7947 - val_recall: 0.7654 - val_f1score: 0.7795\n",
      "Epoch 94/150\n",
      "20/20 [==============================] - 16s 780ms/step - loss: 0.0016 - accuracy: 1.0000 - precision: 0.9981 - recall: 1.0000 - f1score: 0.9991 - val_loss: 0.4463 - val_accuracy: 0.7796 - val_precision: 0.7947 - val_recall: 0.7654 - val_f1score: 0.7795\n",
      "Epoch 95/150\n",
      "20/20 [==============================] - 16s 779ms/step - loss: 6.1906e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4419 - val_accuracy: 0.7796 - val_precision: 0.7954 - val_recall: 0.7693 - val_f1score: 0.7819\n",
      "Epoch 96/150\n",
      "20/20 [==============================] - 16s 778ms/step - loss: 6.2288e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4376 - val_accuracy: 0.7796 - val_precision: 0.7954 - val_recall: 0.7693 - val_f1score: 0.7819\n",
      "Epoch 97/150\n",
      "20/20 [==============================] - 16s 778ms/step - loss: 3.9857e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4332 - val_accuracy: 0.7796 - val_precision: 0.7954 - val_recall: 0.7693 - val_f1score: 0.7819\n",
      "Epoch 98/150\n",
      "20/20 [==============================] - 16s 781ms/step - loss: 0.0020 - accuracy: 0.9980 - precision: 0.9963 - recall: 1.0000 - f1score: 0.9981 - val_loss: 0.4291 - val_accuracy: 0.7796 - val_precision: 0.7954 - val_recall: 0.7693 - val_f1score: 0.7819\n",
      "Epoch 99/150\n",
      "20/20 [==============================] - 16s 778ms/step - loss: 0.0010 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9981 - f1score: 0.9990 - val_loss: 0.4250 - val_accuracy: 0.7796 - val_precision: 0.7964 - val_recall: 0.7733 - val_f1score: 0.7845\n",
      "Epoch 100/150\n",
      "20/20 [==============================] - 16s 784ms/step - loss: 0.0018 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 0.4211 - val_accuracy: 0.7796 - val_precision: 0.7964 - val_recall: 0.7733 - val_f1score: 0.7845\n",
      "Epoch 101/150\n",
      "20/20 [==============================] - 16s 777ms/step - loss: 4.8987e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4172 - val_accuracy: 0.7796 - val_precision: 0.7964 - val_recall: 0.7733 - val_f1score: 0.7845\n",
      "Epoch 102/150\n",
      "20/20 [==============================] - 16s 783ms/step - loss: 9.8930e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4135 - val_accuracy: 0.7837 - val_precision: 0.7964 - val_recall: 0.7733 - val_f1score: 0.7845\n",
      "Epoch 103/150\n",
      "20/20 [==============================] - 16s 781ms/step - loss: 4.3651e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4098 - val_accuracy: 0.7796 - val_precision: 0.8009 - val_recall: 0.7772 - val_f1score: 0.7886\n",
      "Epoch 104/150\n",
      "20/20 [==============================] - 16s 781ms/step - loss: 2.6614e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4062 - val_accuracy: 0.7796 - val_precision: 0.8009 - val_recall: 0.7772 - val_f1score: 0.7886\n",
      "Epoch 105/150\n",
      "20/20 [==============================] - 16s 783ms/step - loss: 8.8780e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.4027 - val_accuracy: 0.7796 - val_precision: 0.7934 - val_recall: 0.7772 - val_f1score: 0.7848\n",
      "Epoch 106/150\n",
      "20/20 [==============================] - 16s 778ms/step - loss: 2.7270e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3993 - val_accuracy: 0.7796 - val_precision: 0.7934 - val_recall: 0.7751 - val_f1score: 0.7840\n",
      "Epoch 107/150\n",
      "20/20 [==============================] - 16s 781ms/step - loss: 8.3465e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3961 - val_accuracy: 0.7796 - val_precision: 0.7934 - val_recall: 0.7751 - val_f1score: 0.7840\n",
      "Epoch 108/150\n",
      "20/20 [==============================] - 16s 780ms/step - loss: 0.0018 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 0.3930 - val_accuracy: 0.7755 - val_precision: 0.7929 - val_recall: 0.7712 - val_f1score: 0.7818\n",
      "Epoch 109/150\n",
      "20/20 [==============================] - 16s 778ms/step - loss: 4.8060e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3900 - val_accuracy: 0.7755 - val_precision: 0.7864 - val_recall: 0.7712 - val_f1score: 0.7785\n",
      "Epoch 110/150\n",
      "20/20 [==============================] - 16s 781ms/step - loss: 4.8397e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3871 - val_accuracy: 0.7755 - val_precision: 0.7895 - val_recall: 0.7712 - val_f1score: 0.7801\n",
      "Epoch 111/150\n",
      "20/20 [==============================] - 16s 784ms/step - loss: 8.1400e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3843 - val_accuracy: 0.7755 - val_precision: 0.7928 - val_recall: 0.7712 - val_f1score: 0.7817\n",
      "Epoch 112/150\n",
      "20/20 [==============================] - 16s 785ms/step - loss: 2.8209e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3814 - val_accuracy: 0.7755 - val_precision: 0.7928 - val_recall: 0.7712 - val_f1score: 0.7817\n",
      "Epoch 113/150\n",
      "20/20 [==============================] - 16s 779ms/step - loss: 4.5921e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3786 - val_accuracy: 0.7755 - val_precision: 0.7928 - val_recall: 0.7712 - val_f1score: 0.7817\n",
      "Epoch 114/150\n",
      "20/20 [==============================] - 16s 783ms/step - loss: 5.4172e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3759 - val_accuracy: 0.7755 - val_precision: 0.7905 - val_recall: 0.7712 - val_f1score: 0.7806\n",
      "Epoch 115/150\n",
      "20/20 [==============================] - 16s 782ms/step - loss: 0.0057 - accuracy: 0.9961 - precision: 0.9962 - recall: 0.9942 - f1score: 0.9952 - val_loss: 0.3733 - val_accuracy: 0.7755 - val_precision: 0.7935 - val_recall: 0.7712 - val_f1score: 0.7820\n",
      "Epoch 116/150\n",
      "20/20 [==============================] - 16s 783ms/step - loss: 3.3607e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3706 - val_accuracy: 0.7755 - val_precision: 0.7935 - val_recall: 0.7712 - val_f1score: 0.7820\n",
      "Epoch 117/150\n",
      "20/20 [==============================] - 16s 785ms/step - loss: 7.5858e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3681 - val_accuracy: 0.7714 - val_precision: 0.7896 - val_recall: 0.7673 - val_f1score: 0.7781\n",
      "Epoch 118/150\n",
      "20/20 [==============================] - 16s 783ms/step - loss: 8.2218e-04 - accuracy: 1.0000 - precision: 0.9981 - recall: 1.0000 - f1score: 0.9991 - val_loss: 0.3656 - val_accuracy: 0.7714 - val_precision: 0.7896 - val_recall: 0.7673 - val_f1score: 0.7781\n",
      "Epoch 119/150\n",
      "20/20 [==============================] - 16s 796ms/step - loss: 6.8154e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3631 - val_accuracy: 0.7714 - val_precision: 0.7896 - val_recall: 0.7673 - val_f1score: 0.7781\n",
      "Epoch 120/150\n",
      "20/20 [==============================] - 16s 787ms/step - loss: 2.4411e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3607 - val_accuracy: 0.7714 - val_precision: 0.7896 - val_recall: 0.7673 - val_f1score: 0.7781\n",
      "Epoch 121/150\n",
      "20/20 [==============================] - 16s 784ms/step - loss: 7.0997e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3584 - val_accuracy: 0.7755 - val_precision: 0.7896 - val_recall: 0.7673 - val_f1score: 0.7781\n",
      "Epoch 122/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 16s 786ms/step - loss: 5.2619e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3562 - val_accuracy: 0.7755 - val_precision: 0.7931 - val_recall: 0.7673 - val_f1score: 0.7798\n",
      "Epoch 123/150\n",
      "20/20 [==============================] - 16s 777ms/step - loss: 7.7282e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3540 - val_accuracy: 0.7755 - val_precision: 0.7968 - val_recall: 0.7673 - val_f1score: 0.7815\n",
      "Epoch 124/150\n",
      "20/20 [==============================] - 15s 772ms/step - loss: 7.9128e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3519 - val_accuracy: 0.7755 - val_precision: 0.7968 - val_recall: 0.7673 - val_f1score: 0.7815\n",
      "Epoch 125/150\n",
      "20/20 [==============================] - 16s 778ms/step - loss: 4.3425e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3498 - val_accuracy: 0.7755 - val_precision: 0.7968 - val_recall: 0.7673 - val_f1score: 0.7815\n",
      "Epoch 126/150\n",
      "20/20 [==============================] - 16s 781ms/step - loss: 5.2359e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3478 - val_accuracy: 0.7755 - val_precision: 0.7968 - val_recall: 0.7673 - val_f1score: 0.7815\n",
      "Epoch 127/150\n",
      "20/20 [==============================] - 16s 781ms/step - loss: 3.0804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3457 - val_accuracy: 0.7755 - val_precision: 0.7968 - val_recall: 0.7673 - val_f1score: 0.7815\n",
      "Epoch 128/150\n",
      "20/20 [==============================] - 16s 778ms/step - loss: 6.7029e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3438 - val_accuracy: 0.7755 - val_precision: 0.7968 - val_recall: 0.7673 - val_f1score: 0.7815\n",
      "Epoch 129/150\n",
      "20/20 [==============================] - 16s 781ms/step - loss: 0.0012 - accuracy: 0.9980 - precision: 0.9981 - recall: 1.0000 - f1score: 0.9991 - val_loss: 0.3419 - val_accuracy: 0.7755 - val_precision: 0.8006 - val_recall: 0.7712 - val_f1score: 0.7855\n",
      "Epoch 130/150\n",
      "20/20 [==============================] - 16s 779ms/step - loss: 3.3116e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3400 - val_accuracy: 0.7755 - val_precision: 0.8006 - val_recall: 0.7712 - val_f1score: 0.7855\n",
      "Epoch 131/150\n",
      "20/20 [==============================] - 16s 781ms/step - loss: 3.4196e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3382 - val_accuracy: 0.7755 - val_precision: 0.8012 - val_recall: 0.7751 - val_f1score: 0.7877\n",
      "Epoch 132/150\n",
      "20/20 [==============================] - 16s 779ms/step - loss: 0.0019 - accuracy: 1.0000 - precision: 0.9981 - recall: 1.0000 - f1score: 0.9991 - val_loss: 0.3366 - val_accuracy: 0.7837 - val_precision: 0.8012 - val_recall: 0.7751 - val_f1score: 0.7877\n",
      "Epoch 133/150\n",
      "20/20 [==============================] - 16s 778ms/step - loss: 5.8656e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.7837 - val_precision: 0.8047 - val_recall: 0.7751 - val_f1score: 0.7894\n",
      "Epoch 134/150\n",
      "20/20 [==============================] - 16s 779ms/step - loss: 2.8439e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3331 - val_accuracy: 0.7837 - val_precision: 0.8047 - val_recall: 0.7751 - val_f1score: 0.7894\n",
      "Epoch 135/150\n",
      "20/20 [==============================] - 16s 779ms/step - loss: 8.3172e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3315 - val_accuracy: 0.7878 - val_precision: 0.8078 - val_recall: 0.7751 - val_f1score: 0.7909\n",
      "Epoch 136/150\n",
      "20/20 [==============================] - 16s 778ms/step - loss: 6.9686e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3299 - val_accuracy: 0.7878 - val_precision: 0.8078 - val_recall: 0.7751 - val_f1score: 0.7909\n",
      "Epoch 137/150\n",
      "20/20 [==============================] - 16s 780ms/step - loss: 9.4614e-04 - accuracy: 1.0000 - precision: 0.9974 - recall: 1.0000 - f1score: 0.9986 - val_loss: 0.3284 - val_accuracy: 0.7878 - val_precision: 0.8078 - val_recall: 0.7751 - val_f1score: 0.7909\n",
      "Epoch 138/150\n",
      "20/20 [==============================] - 16s 780ms/step - loss: 0.0027 - accuracy: 0.9980 - precision: 0.9981 - recall: 0.9981 - f1score: 0.9981 - val_loss: 0.3269 - val_accuracy: 0.7878 - val_precision: 0.8078 - val_recall: 0.7751 - val_f1score: 0.7909\n",
      "Epoch 139/150\n",
      "20/20 [==============================] - 16s 778ms/step - loss: 0.0020 - accuracy: 0.9980 - precision: 0.9972 - recall: 0.9972 - f1score: 0.9972 - val_loss: 0.3255 - val_accuracy: 0.7878 - val_precision: 0.8150 - val_recall: 0.7751 - val_f1score: 0.7943\n",
      "Epoch 140/150\n",
      "20/20 [==============================] - 16s 788ms/step - loss: 6.0251e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3240 - val_accuracy: 0.7878 - val_precision: 0.8150 - val_recall: 0.7751 - val_f1score: 0.7943\n",
      "Epoch 141/150\n",
      "20/20 [==============================] - 16s 796ms/step - loss: 0.0014 - accuracy: 1.0000 - precision: 0.9981 - recall: 1.0000 - f1score: 0.9991 - val_loss: 0.3228 - val_accuracy: 0.7918 - val_precision: 0.8154 - val_recall: 0.7790 - val_f1score: 0.7965\n",
      "Epoch 142/150\n",
      "20/20 [==============================] - 16s 788ms/step - loss: 0.0012 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3214 - val_accuracy: 0.7959 - val_precision: 0.8154 - val_recall: 0.7790 - val_f1score: 0.7965\n",
      "Epoch 143/150\n",
      "20/20 [==============================] - 16s 779ms/step - loss: 4.1386e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3202 - val_accuracy: 0.7959 - val_precision: 0.8160 - val_recall: 0.7829 - val_f1score: 0.7988\n",
      "Epoch 144/150\n",
      "20/20 [==============================] - 16s 783ms/step - loss: 5.5457e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3190 - val_accuracy: 0.7959 - val_precision: 0.8160 - val_recall: 0.7829 - val_f1score: 0.7988\n",
      "Epoch 145/150\n",
      "20/20 [==============================] - 16s 785ms/step - loss: 6.1902e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3178 - val_accuracy: 0.7959 - val_precision: 0.8160 - val_recall: 0.7829 - val_f1score: 0.7988\n",
      "Epoch 146/150\n",
      "20/20 [==============================] - 16s 782ms/step - loss: 0.0010 - accuracy: 1.0000 - precision: 0.9981 - recall: 1.0000 - f1score: 0.9991 - val_loss: 0.3167 - val_accuracy: 0.7959 - val_precision: 0.8160 - val_recall: 0.7829 - val_f1score: 0.7988\n",
      "Epoch 147/150\n",
      "20/20 [==============================] - 16s 794ms/step - loss: 7.6558e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3156 - val_accuracy: 0.7959 - val_precision: 0.8160 - val_recall: 0.7829 - val_f1score: 0.7988\n",
      "Epoch 148/150\n",
      "20/20 [==============================] - 16s 803ms/step - loss: 4.4674e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3145 - val_accuracy: 0.7959 - val_precision: 0.8128 - val_recall: 0.7829 - val_f1score: 0.7971\n",
      "Epoch 149/150\n",
      "20/20 [==============================] - 16s 780ms/step - loss: 8.3564e-04 - accuracy: 1.0000 - precision: 0.9974 - recall: 1.0000 - f1score: 0.9986 - val_loss: 0.3136 - val_accuracy: 0.7959 - val_precision: 0.8128 - val_recall: 0.7829 - val_f1score: 0.7971\n",
      "Epoch 150/150\n",
      "20/20 [==============================] - 15s 775ms/step - loss: 7.7131e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - val_loss: 0.3126 - val_accuracy: 0.7959 - val_precision: 0.8128 - val_recall: 0.7829 - val_f1score: 0.7971\n"
     ]
    }
   ],
   "source": [
    "def recall(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
    "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
    "\n",
    "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n",
    "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
    "\n",
    "    # Precision = (True Positive) / (True Positive + False Positive)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1score(y_target, y_pred):\n",
    "    _recall = recall(y_target, y_pred)\n",
    "    _precision = precision(y_target, y_pred)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
    "    \n",
    "    # return a single tensor value\n",
    "    return _f1score\n",
    "\n",
    "\n",
    "#model = create_model()\n",
    "#model = vgg16()\n",
    "#model = ResNet()\n",
    "model = mobile_net()\n",
    "#model = resnet50()\n",
    "\n",
    "## learning rate scheduing\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,\n",
    "                                                          decay_steps=training_epochs*10,\n",
    "                                                          decay_rate=0.4,\n",
    "                                                          staircase=True)\n",
    "## optimizer는 Adam, loss는 sparse categorical crossentropy 사용\n",
    "## label이 ont-hot으로 encoding 안 된 경우에 sparse categorical corssentropy 및 sparse categorical accuracy 사용\n",
    "model.compile(keras.optimizers.Adam(lr_schedule), loss = 'binary_crossentropy', metrics=['accuracy', precision, recall, f1score])\n",
    "\n",
    "## Train!\n",
    "## Train!\n",
    "history = model.fit(x_train, y_train, steps_per_epoch=training_epochs,\n",
    "         epochs=150, validation_data = (x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "index: 0  actual y: 3  answer y: 3  prediction: [1.01442813e-04 1.22068275e-04 3.28600407e-04 9.99062300e-01\n",
      " 2.89320946e-04]\n",
      "index: 1  actual y: 1  answer y: 1  prediction: [4.9898028e-04 9.8956025e-01 1.3439953e-03 1.6094744e-03 4.3214560e-03]\n",
      "index: 2  actual y: 2  answer y: 2  prediction: [2.0271048e-06 3.2858632e-06 9.9996805e-01 8.5536440e-06 1.9413512e-06]\n",
      "index: 3  actual y: 0  answer y: 0  prediction: [9.9994361e-01 8.8742845e-06 1.4179741e-05 2.6140983e-06 4.6170167e-06]\n",
      "index: 4  actual y: 0  answer y: 0  prediction: [1.0000000e+00 8.6943155e-09 6.7086630e-09 9.6974890e-09 1.4464962e-08]\n",
      "index: 5  actual y: 3  answer y: 3  prediction: [2.2702411e-06 3.4093944e-06 1.2894743e-05 9.9997246e-01 4.3430928e-06]\n",
      "index: 6  actual y: 4  answer y: 4  prediction: [6.8699912e-10 2.8754215e-09 4.2481851e-10 1.8054055e-09 1.0000000e+00]\n",
      "index: 7  actual y: 1  answer y: 1  prediction: [1.4362761e-06 9.9996096e-01 2.2623328e-06 1.5722899e-05 4.8033371e-06]\n",
      "index: 8  actual y: 0  answer y: 0  prediction: [1.0000000e+00 3.2620664e-09 5.9854792e-09 4.4774646e-09 3.3883993e-08]\n",
      "index: 9  actual y: 0  answer y: 2  prediction: [5.41322291e-01 1.15358955e-04 7.35033393e-01 7.65790719e-06\n",
      " 2.63224392e-05]\n",
      "index: 10  actual y: 2  answer y: 2  prediction: [6.3306093e-04 1.0799170e-03 9.5916104e-01 3.9741397e-04 2.8788418e-02]\n",
      "index: 11  actual y: 1  answer y: 1  prediction: [7.4502182e-08 9.9999416e-01 3.2671477e-07 2.7760279e-07 9.8231476e-07]\n",
      "index: 12  actual y: 2  answer y: 2  prediction: [0.0017401  0.00119999 0.62323576 0.5357705  0.00080287]\n",
      "index: 13  actual y: 0  answer y: 0  prediction: [1.0000000e+00 1.7663977e-09 3.4551684e-09 8.2334295e-10 5.4699396e-09]\n",
      "index: 14  actual y: 3  answer y: 3  prediction: [2.9935162e-08 3.9842867e-08 2.4838585e-07 9.9999952e-01 1.9891353e-08]\n",
      "index: 15  actual y: 0  answer y: 0  prediction: [9.99999881e-01 7.22213844e-09 8.25637780e-09 1.25773045e-08\n",
      " 8.85772025e-08]\n",
      "index: 16  actual y: 2  answer y: 2  prediction: [2.9454764e-06 6.8729737e-06 9.9996775e-01 2.0226864e-06 7.8474716e-07]\n",
      "index: 17  actual y: 0  answer y: 0  prediction: [9.9975586e-01 6.2753647e-06 2.1716952e-04 6.4880096e-06 6.1563537e-06]\n",
      "index: 18  actual y: 3  answer y: 3  prediction: [7.5445482e-06 5.9507951e-05 4.5593442e-05 9.9988860e-01 1.7298984e-05]\n",
      "index: 19  actual y: 1  answer y: 1  prediction: [0.00171718 0.6534686  0.00640213 0.02312893 0.12180951]\n",
      "index: 20  actual y: 4  answer y: 4  prediction: [1.4641249e-08 4.7470685e-08 1.5082577e-08 4.2672738e-08 9.9999964e-01]\n",
      "index: 21  actual y: 2  answer y: 2  prediction: [4.0978193e-04 2.1061063e-05 9.9958503e-01 6.5848349e-06 1.8064115e-05]\n",
      "index: 22  actual y: 3  answer y: 3  prediction: [1.2436509e-04 2.5865436e-04 3.1646476e-05 9.9933076e-01 1.2988691e-05]\n",
      "index: 23  actual y: 3  answer y: 0  prediction: [0.8234904  0.00096127 0.00827515 0.01916468 0.00833836]\n",
      "index: 24  actual y: 4  answer y: 4  prediction: [8.14537273e-08 2.53760497e-08 4.90956698e-09 1.14195275e-08\n",
      " 9.99999523e-01]\n",
      "index: 25  actual y: 1  answer y: 2  prediction: [0.00442976 0.0074209  0.5124895  0.0017418  0.36792457]\n",
      "index: 26  actual y: 3  answer y: 3  prediction: [2.0911396e-03 5.7684206e-06 4.2691140e-06 9.9821043e-01 1.0367983e-06]\n",
      "index: 27  actual y: 3  answer y: 3  prediction: [2.5988098e-07 2.5226416e-07 1.2082633e-06 9.9999583e-01 3.0448197e-07]\n",
      "index: 28  actual y: 0  answer y: 0  prediction: [9.9998224e-01 2.4953593e-07 6.8951640e-06 4.2571912e-07 2.7976421e-06]\n",
      "index: 29  actual y: 4  answer y: 4  prediction: [1.8638372e-04 6.0224533e-04 1.1142114e-01 1.7741412e-02 6.7636669e-01]\n",
      "index: 30  actual y: 3  answer y: 3  prediction: [2.5694058e-10 5.2378502e-10 4.1805865e-09 1.0000000e+00 3.5429307e-10]\n",
      "index: 31  actual y: 2  answer y: 4  prediction: [4.7801848e-05 2.8933706e-05 3.7324429e-04 2.9984178e-05 9.9945438e-01]\n",
      "index: 32  actual y: 1  answer y: 3  prediction: [1.3488531e-04 8.7997317e-04 4.6035647e-04 9.9776137e-01 1.4609098e-04]\n",
      "index: 33  actual y: 3  answer y: 3  prediction: [5.7615757e-06 6.9978314e-06 1.1826022e-05 9.9995714e-01 2.0399139e-06]\n",
      "index: 34  actual y: 3  answer y: 0  prediction: [9.7391474e-01 4.9084274e-06 7.2769681e-06 4.0877700e-02 3.2796863e-06]\n",
      "index: 35  actual y: 4  answer y: 4  prediction: [2.0425618e-03 7.0601702e-04 8.3711035e-05 2.1678209e-04 9.9227256e-01]\n",
      "index: 36  actual y: 2  answer y: 2  prediction: [1.4120340e-04 1.4120340e-04 9.9888909e-01 4.7519803e-04 3.0084515e-05]\n",
      "index: 37  actual y: 3  answer y: 3  prediction: [6.0917625e-07 1.2044046e-06 3.4322077e-06 9.9999255e-01 4.3909512e-07]\n",
      "index: 38  actual y: 1  answer y: 1  prediction: [2.3477620e-01 3.3157033e-01 1.5630305e-02 4.5010448e-04 1.3333559e-04]\n",
      "index: 39  actual y: 4  answer y: 4  prediction: [2.4861088e-06 7.6793576e-06 6.3384800e-07 2.1427754e-06 9.9997187e-01]\n",
      "index: 40  actual y: 0  answer y: 0  prediction: [9.99934077e-01 3.46474940e-06 1.35166165e-05 8.46759860e-07\n",
      " 2.14511347e-05]\n",
      "index: 41  actual y: 3  answer y: 4  prediction: [0.00676888 0.00271776 0.00094494 0.04680505 0.8392484 ]\n",
      "index: 42  actual y: 4  answer y: 4  prediction: [0.28299546 0.00268564 0.00221834 0.00739142 0.58421767]\n",
      "index: 43  actual y: 2  answer y: 2  prediction: [2.0322204e-04 3.2025576e-04 9.9753004e-01 5.9026480e-04 3.6242604e-04]\n",
      "index: 44  actual y: 0  answer y: 0  prediction: [9.9999017e-01 2.9412308e-07 3.4449806e-06 2.6491469e-07 1.9653089e-06]\n",
      "index: 45  actual y: 4  answer y: 4  prediction: [6.5480092e-09 3.5290746e-08 2.2471131e-08 2.8165820e-08 9.9999976e-01]\n",
      "index: 46  actual y: 3  answer y: 3  prediction: [1.0748854e-04 1.8767556e-05 7.9452853e-05 9.9926525e-01 7.9997320e-05]\n",
      "index: 47  actual y: 4  answer y: 4  prediction: [9.1648417e-10 2.9828451e-09 1.2490017e-09 1.2299362e-08 1.0000000e+00]\n",
      "index: 48  actual y: 4  answer y: 4  prediction: [5.7697462e-06 9.9293293e-06 1.4015791e-06 2.8446323e-06 9.9996072e-01]\n",
      "index: 49  actual y: 0  answer y: 0  prediction: [9.9996591e-01 8.2639326e-07 5.9638592e-06 9.6877375e-07 1.5883314e-05]\n",
      "index: 50  actual y: 4  answer y: 4  prediction: [1.0728836e-03 3.6653876e-04 9.9718003e-05 6.7904592e-04 9.9612564e-01]\n",
      "index: 51  actual y: 2  answer y: 2  prediction: [3.5715020e-06 7.8584544e-06 9.9982381e-01 9.2194223e-06 4.6937577e-05]\n",
      "index: 52  actual y: 3  answer y: 3  prediction: [3.8260936e-08 6.7372746e-08 3.3767913e-07 9.9999869e-01 1.5398672e-07]\n",
      "index: 53  actual y: 1  answer y: 1  prediction: [1.7653554e-07 9.9999720e-01 2.9425044e-07 3.3329434e-07 2.6182934e-07]\n",
      "index: 54  actual y: 4  answer y: 4  prediction: [8.14537273e-08 2.53760497e-08 4.90956698e-09 1.14195275e-08\n",
      " 9.99999523e-01]\n",
      "index: 55  actual y: 3  answer y: 3  prediction: [3.3620000e-04 3.4901500e-04 2.0357966e-04 9.9846613e-01 7.5261123e-05]\n",
      "index: 56  actual y: 4  answer y: 4  prediction: [2.3872937e-05 1.2142787e-05 3.2215837e-06 1.8865750e-05 9.9987125e-01]\n",
      "index: 57  actual y: 4  answer y: 4  prediction: [5.6781828e-06 2.2134736e-06 5.3675194e-07 2.4652966e-06 9.9996358e-01]\n",
      "index: 58  actual y: 0  answer y: 0  prediction: [7.3581934e-01 2.5142355e-05 6.0737234e-01 4.5850293e-06 3.4675180e-05]\n",
      "index: 59  actual y: 3  answer y: 3  prediction: [3.0409444e-06 6.4934011e-06 1.3852563e-05 9.9996889e-01 3.1605111e-06]\n",
      "index: 60  actual y: 1  answer y: 1  prediction: [9.7519159e-04 9.8910165e-01 2.3410916e-03 1.8248856e-03 2.8898120e-03]\n",
      "index: 61  actual y: 1  answer y: 1  prediction: [3.8816339e-08 9.9999797e-01 7.3732721e-08 1.7114263e-07 3.5342327e-07]\n",
      "index: 62  actual y: 0  answer y: 0  prediction: [1.0000000e+00 3.6249728e-09 4.9662172e-09 4.8430948e-09 3.7704556e-08]\n",
      "index: 63  actual y: 3  answer y: 3  prediction: [1.4577280e-05 4.0410332e-06 2.6749709e-05 9.9989003e-01 4.3225441e-06]\n",
      "index: 64  actual y: 4  answer y: 4  prediction: [1.3789535e-04 1.8155575e-04 3.9388811e-05 1.3348460e-04 9.9923497e-01]\n",
      "index: 65  actual y: 4  answer y: 4  prediction: [4.1783389e-07 2.4115734e-06 6.6568748e-07 7.3710544e-07 9.9999362e-01]\n",
      "index: 66  actual y: 0  answer y: 0  prediction: [9.9999523e-01 2.8474781e-07 1.6506829e-06 7.2203377e-08 3.5093220e-07]\n",
      "index: 67  actual y: 0  answer y: 0  prediction: [9.9998182e-01 3.7852905e-07 4.8227716e-06 2.5504090e-07 8.9517198e-06]\n",
      "index: 68  actual y: 2  answer y: 2  prediction: [0.00249365 0.0018833  0.70539826 0.00084859 0.28669494]\n",
      "index: 69  actual y: 0  answer y: 3  prediction: [0.07781452 0.00306422 0.0020557  0.8655315  0.00120708]\n",
      "index: 70  actual y: 1  answer y: 1  prediction: [2.7214092e-08 9.9999917e-01 4.4581142e-08 9.0012776e-08 9.2572975e-08]\n",
      "index: 71  actual y: 2  answer y: 2  prediction: [2.8622784e-05 6.6070243e-05 6.3590825e-01 4.8473463e-05 4.8283392e-01]\n",
      "index: 72  actual y: 1  answer y: 1  prediction: [5.5837631e-04 9.8871768e-01 4.4393539e-04 1.3564229e-03 6.1973631e-03]\n",
      "index: 73  actual y: 4  answer y: 4  prediction: [2.6698403e-09 1.8108278e-08 5.8665419e-09 2.7599611e-08 9.9999988e-01]\n",
      "index: 74  actual y: 0  answer y: 0  prediction: [9.9634552e-01 4.9945712e-04 4.1410327e-04 1.1723042e-03 5.8597326e-04]\n",
      "index: 75  actual y: 1  answer y: 1  prediction: [2.0923449e-05 9.9982703e-01 1.4110848e-05 4.6626345e-05 3.9384791e-05]\n",
      "index: 76  actual y: 2  answer y: 2  prediction: [2.8507211e-06 9.7497486e-06 9.9996078e-01 2.1044509e-06 1.4699718e-06]\n",
      "index: 77  actual y: 2  answer y: 2  prediction: [5.4140035e-09 8.9008516e-09 9.9999976e-01 3.2261120e-08 1.7155654e-09]\n",
      "index: 78  actual y: 2  answer y: 2  prediction: [2.2201523e-06 9.5832308e-07 9.9998569e-01 2.0623640e-06 5.6289059e-07]\n",
      "index: 79  actual y: 3  answer y: 3  prediction: [5.5748174e-08 2.2212355e-07 2.5564580e-07 9.9999863e-01 5.8697797e-08]\n",
      "index: 80  actual y: 1  answer y: 1  prediction: [1.9421188e-07 9.9998695e-01 8.5745643e-07 1.1677064e-06 3.9240804e-06]\n",
      "index: 81  actual y: 0  answer y: 0  prediction: [9.9999928e-01 3.1921839e-08 3.5057593e-07 3.2951235e-08 1.2356507e-07]\n",
      "index: 82  actual y: 2  answer y: 2  prediction: [9.4795227e-04 1.1406839e-03 9.7559071e-01 6.6061020e-03 7.6661706e-03]\n",
      "index: 83  actual y: 2  answer y: 0  prediction: [0.98550725 0.00547716 0.00494769 0.00142762 0.00192308]\n",
      "index: 84  actual y: 1  answer y: 1  prediction: [5.5046137e-09 9.9999970e-01 1.3678678e-08 4.5571031e-08 1.6543941e-08]\n",
      "index: 85  actual y: 4  answer y: 4  prediction: [2.0057957e-08 6.1560542e-08 2.3240492e-08 1.3246701e-07 9.9999934e-01]\n",
      "index: 86  actual y: 3  answer y: 3  prediction: [1.5282920e-05 2.1558437e-05 1.8143690e-05 9.9985373e-01 1.3374415e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1748 - accuracy: 0.8966 - precision: 0.8803 - recall: 0.8981 - f1score: 0.8889\n",
      "loss: 0.175, accuracy: 0.897, precision: 0.880, recall: 0.898, f1score: 0.889\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# output = classifier.predict_generator(test_set, steps=1)\n",
    "# print(test_set.class_indices)\n",
    "# print(output)\n",
    "size = y_test[:,-1]\n",
    "print(size.size)\n",
    "\n",
    "\n",
    "# predict 10 random hand-writing data\n",
    "y_predicted = model.predict(x_test)\n",
    "for x in range(0,size.size):\n",
    "    \n",
    "    print(\"index:\", x,\n",
    "          \" actual y:\", np.argmax(y_test[x]),\n",
    "          \" answer y:\", np.argmax(y_predicted[x]),\n",
    "            \" prediction:\", np.array(y_predicted[x]))\n",
    "\n",
    "_loss, _acc, _precision, _recall, _f1score = model.evaluate(x_test, y_test)\n",
    "print('loss: {:.3f}, accuracy: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _precision, _recall, _f1score))\n",
    "# print('loss: ', evaluation[0])\n",
    "# print('accuracy', evaluation[1])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 손실 그래프\n",
    "def plot_loss(history):\n",
    "   # 선 그리기\n",
    "    plt.plot(history.history['loss'], 'y', label='train loss')\n",
    "    plt.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "   # 그래프 제목\n",
    "    plt.title('Model Loss')\n",
    "   # x,y축 이름 표시\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "   # 각 라인 표식 표시\n",
    "    plt.legend(['Train','Validation'],loc=0)\n",
    "\n",
    "# 정확도 그래프\n",
    "def plot_acc(history):\n",
    "  # dir(history.history)\n",
    "    plt.plot(history.history['accuracy'], 'b', label='train accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], 'g', label='val accuracy')\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc=0)\n",
    "\n",
    "plot_loss(history)\n",
    "plt.show()\n",
    "plot_acc(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = [32,64,128,256,512,1024]\n",
    "# learning_rate = [0.00001,0.0001,0.001]\n",
    "# for  batch_size, learning_rate in product(batch_size,learning_rate):\n",
    "#     print(f'batchSIZE is {batch_size}, Learning Rate is {learning_rate}')\n",
    "#     train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "#                                    shear_range = 0.2,\n",
    "#                                    zoom_range = 0.2,\n",
    "#                                    horizontal_flip = True)\n",
    "\n",
    "#     test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "#     categories = ['dog','cat','rabbit','squirrel','deer']\n",
    "\n",
    "#     training_set = train_datagen.flow_from_directory(train_img_dir, target_size=(128,128), \n",
    "#                                                  classes=categories, \n",
    "#                                                  batch_size=batch_size)\n",
    "\n",
    "#     test_set = test_datagen.flow_from_directory(test_img_dir,\n",
    "#                                             target_size=(128,128), \n",
    "#                                             classes=categories, \n",
    "#                                             batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "#     x_train, y_train = next(training_set)\n",
    "#     x_test, y_test = next(test_set)\n",
    "#     model = create_model()\n",
    "#     ## learning rate scheduing\n",
    "#     lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,\n",
    "#                                                               decay_steps=training_epochs*10,\n",
    "#                                                               decay_rate=0.4,\n",
    "#                                                               staircase=True)\n",
    "#     ## optimizer는 Adam, loss는 sparse categorical crossentropy 사용\n",
    "#     ## label이 ont-hot으로 encoding 안 된 경우에 sparse categorical corssentropy 및 sparse categorical accuracy 사용\n",
    "#     model.compile(keras.optimizers.Adam(lr_schedule), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#     ## Train!\n",
    "#     history = model.fit(x_train, y_train, #steps_per_epoch=training_epochs,\n",
    "#          epochs=40, validation_data = (x_val,y_val))\n",
    "#     # output = classifier.predict_generator(test_set, steps=1)\n",
    "#     # print(test_set.class_indices)\n",
    "#     # print(output)\n",
    "#     size = y_test[:,-1]\n",
    "#     print(size.size)\n",
    "\n",
    "\n",
    "#     # predict 10 random hand-writing data\n",
    "#     y_predicted = model.predict(x_test)\n",
    "#     for x in range(0,size.size):\n",
    "\n",
    "#         print(\"index:\", x,\n",
    "#               \" actual y:\", np.argmax(y_test[x]),\n",
    "#               \" answer y:\", np.argmax(y_predicted[x]),\n",
    "#                 \" prediction:\", np.array(y_predicted[x]))\n",
    "\n",
    "#     evaluation = model.evaluate(x_test, y_test)\n",
    "#     print('loss: ', evaluation[0])\n",
    "#     print('accuracy', evaluation[1])\n",
    "\n",
    "#     plot_loss(history)\n",
    "#     plt.show()\n",
    "#     plot_acc(history)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
